[2025-08-10 19:23:39 base_config.py line 213]=>INFO: Initializing main logger ...
[2025-08-10 19:23:39 base_config.py line 217]=>INFO: Setting fixed seed: 131
[2025-08-10 19:23:39 base_config.py line 258]=>INFO: Collecting system info ...
[2025-08-10 19:23:39 base_config.py line 259]=>INFO: Project configuration:
DATALOADER:
  NUM_WORKERS: 0
  TEST:
    BATCH_SIZE: 1
  TRAIN:
    BATCH_SIZE: 1
DATASET:
  AUDIO_PATH: wav
  NAME: Vocaset
  READ_AUDIO: True
  ROOT: ./data/
  SPLIT:
    BIWI:
      TEST: [37, 38, 39, 40]
      TRAIN: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]
      VAL: [33, 34, 35, 36]
    VOCASET:
      TEST: [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]
      TRAIN: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]
      VAL: [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]
  TEMPLATE_FILE: templates.pkl
  TEST_SUBJECTS: ['FaceTalk_170809_00138_TA', 'FaceTalk_170731_00024_TA']
  TRAIN_SUBJECTS: ['FaceTalk_170728_03272_TA', 'FaceTalk_170904_00128_TA', 'FaceTalk_170725_00137_TA', 'FaceTalk_170915_00223_TA', 'FaceTalk_170811_03274_TA', 'FaceTalk_170913_03279_TA', 'FaceTalk_170904_03276_TA', 'FaceTalk_170912_03278_TA']
  VAL_PERCENT: 0.1
  VAL_SUBJECTS: ['FaceTalk_170811_03275_TA', 'FaceTalk_170908_03277_TA']
  VERTICES_PATH: vertices_npy
ENV:
  DESCRIPTION: Train the model of stage 1 on the vocaset dataset.
  GPU: 0
  NAME: train
  OUTPUT_DIR: ./output
  RESUME: 
  SEED: 131
  USE_CUDA: True
  VERBOSE: True
  VERSION: 1
INPUT:
  GN_MEAN: 0.0
  GN_STD: 0.15
  NO_TRANSFORM: False
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
LOSS:
  NAME: VQLoss
  QUANT_LOSS_WEIGHT: 1.0
MODEL:
  BACKBONE:
    FACE_QUAN_NUM: 16
    HIDDEN_SIZE: 1024
    INAFFINE: False
    INTERMEDIATE_SIZE: 1536
    IN_DIM: 15069
    NAME: stage1_vocaset
    NEG: 0.2
    NUM_ATTENTION_HEADS: 8
    NUM_HIDDEN_LAYERS: 6
    PRETRAINED: True
    QUANT_FACTOR: 0
    WINDOW_SIZE: 1
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
    N_EMBED: 256
    ZQUANT_DIM: 64
  INIT_WEIGHTS: 
  NAME: 
  WAV2VEC2_PATH: facebook/wav2vec2-base-960h
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  ADAPTIVE_LR: False
  BASE_LR_MULT: 0.1
  FACTOR: 0.3
  GAMMA: 0.5
  LR: 0.0001
  LR_SCHEDULER: single_step
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: adam
  NEW_LAYERS: ()
  PATIENCE: 3
  POLY_LR: False
  POWER: 0.9
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: True
  STAGED_LR: False
  START_EPOCH: 0
  STEP_LR: True
  STEP_SIZE: 20
  THRESHOLD: 0.0001
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_STEPS: 1
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.002
TEST:
  EVALUATOR: CodeTalkerEvaluator
  FINAL_MODEL: last_step
  NO_TEST: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 1
  EVALUATE: True
  EVAL_FREQ: 10
  PRINT_FREQ: 5
  SAVE_FREQ: 1
  SYNC_BN: False
  USE_SGD: False
TRAINER:
  NAME: CodeTalkerTrainer
[2025-08-10 19:23:39 base_config.py line 260]=>INFO: Collecting env info ...
[2025-08-10 19:23:46 base_config.py line 261]=>INFO: Env information:
PyTorch version: 1.12.1
Is debug build: False
CUDA used to build PyTorch: 11.3
ROCM used to build PyTorch: N/A

OS: Microsoft Windows 11 ×¨Òµ°æ
GCC version: (x86_64-win32-seh-rev0, Built by MinGW-Builds project) 15.1.0
Clang version: Could not collect
CMake version: version 3.31.5
Libc version: N/A

Python version: 3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)] (64-bit runtime)
Python platform: Windows-10-10.0.26100-SP0
Is CUDA available: True
CUDA runtime version: 11.3.58
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 4090 D
Nvidia driver version: 560.94
cuDNN version: D:\00MyWorkplace\00apps\02CUDAs\cuda\Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\bin\cudnn_ops_train64_8.dll
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] facenet-pytorch==2.3.0
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.0
[pip3] pytorch3d==0.7.2
[pip3] torch==1.12.1
[pip3] torchaudio==0.12.1
[pip3] torchvision==0.13.1
[conda] blas                      1.0                         mkl    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
[conda] cudatoolkit               11.3.1               h59b6b97_2    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
[conda] mkl                       2023.1.0         h6b88ed4_46358    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
[conda] mkl-service               2.4.0            py39h827c3e9_2    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
[conda] mkl_fft                   1.3.11           py39h827c3e9_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
[conda] mkl_random                1.2.8            py39hc64d2fc_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
[conda] numpy                     1.23.0                   pypi_0    pypi
[conda] numpy-base                1.26.4           py39h65a83cf_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
[conda] pytorch                   1.12.1          py3.9_cuda11.3_cudnn8_0    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] pytorch3d                 0.7.2                    pypi_0    pypi
[conda] torchaudio                0.12.1               py39_cu113    pytorch
[conda] torchvision               0.13.1               py39_cu113    pytorch
[2025-08-10 19:23:46 base_trainer.py line 21]=>INFO: Loading trainer: CodeTalkerTrainer
[2025-08-10 19:23:46 base_dataset.py line 17]=>INFO: Loading dataset: Vocaset
[2025-08-10 19:23:58 base_datamanager.py line 93]=>INFO: Dataset summary:
-------  -------
Dataset  Vocaset
# train  314
# val    40
# test   39
-------  -------
[2025-08-10 19:23:58 codetalker.py line 53]=>INFO: Building model  ...
[2025-08-10 19:23:59 codetalker.py line 58]=>INFO: Params: 131,653,341
[2025-08-10 19:23:59 codetalker.py line 59]=>INFO: Model Structure:
VQAutoEncoder(
  (encoder): TransformerEncoder(
    (vertice_mapping): Sequential(
      (0): Linear(in_features=15069, out_features=1024, bias=True)
      (1): LeakyReLU(negative_slope=0.2, inplace=True)
    )
    (squasher): Sequential(
      (0): Sequential(
        (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,), padding_mode=replicate)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
        (2): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (encoder_transformer): Transformer(
      (net): Sequential(
        (0): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (1): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
        (2): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (3): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
        (4): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (5): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
        (6): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (7): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
        (8): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (9): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
        (10): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (11): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
      )
    )
    (encoder_pos_embedding): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder_linear_embedding): LinearEmbedding(
      (net): Linear(in_features=1024, out_features=1024, bias=True)
    )
  )
  (decoder): TransformerDecoder(
    (expander): ModuleList(
      (0): Sequential(
        (0): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,), padding_mode=replicate)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
        (2): InstanceNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (decoder_transformer): Transformer(
      (net): Sequential(
        (0): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (1): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
        (2): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (3): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
        (4): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (5): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
        (6): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (7): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
        (8): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (9): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
        (10): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): Attention(
              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)
              (to_out): Linear(in_features=1024, out_features=1024, bias=True)
              (rearrange_qkv): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)
              (rearrange_out): Rearrange('b h n d -> b n (h d)')
            )
          )
        )
        (11): Residual(
          (fn): Norm(
            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fn): MLP(
              (l1): Linear(in_features=1024, out_features=1536, bias=True)
              (l2): Linear(in_features=1536, out_features=1024, bias=True)
            )
          )
        )
      )
    )
    (decoder_pos_embedding): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (decoder_linear_embedding): LinearEmbedding(
      (net): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (vertice_map_reverse): Linear(in_features=1024, out_features=15069, bias=True)
  )
  (quantize): VectorQuantizer(
    (embedding): Embedding(256, 64)
  )
)
[2025-08-10 19:23:59 codetalker.py line 61]=>INFO: Building optimizer ...
[2025-08-10 19:23:59 base_evaluator.py line 10]=>INFO: Loading evaluator: CodeTalkerEvaluator
[2025-08-10 19:23:59 base_trainer.py line 180]=>INFO: Using VQ loss function for metrics ...
[2025-08-10 19:23:59 base_trainer.py line 656]=>INFO: Found checkpoint at ./output (will resume training)
[2025-08-10 19:23:59 base_trainer.py line 690]=>INFO: Loading checkpoint from "./output\model\model.pth.tar-19"
[2025-08-10 19:24:01 base_trainer.py line 693]=>INFO: Loaded model weights
[2025-08-10 19:24:01 base_trainer.py line 697]=>INFO: Loaded optimizer
[2025-08-10 19:24:01 base_trainer.py line 701]=>INFO: Loaded scheduler
[2025-08-10 19:24:01 base_trainer.py line 704]=>INFO: Previous epoch: 19
[2025-08-10 19:24:01 base_trainer.py line 100]=>INFO: Initialize tensorboard (log_dir=./output\tensorboard)
[2025-08-10 19:24:04 codetalker.py line 151]=>INFO: epoch [20/200] batch [5/314] time 0.077 (0.729) data 0.001 (0.008) loss 0.0013 lr 1.0000e-04 eta 11:30:55
[2025-08-10 19:24:05 codetalker.py line 151]=>INFO: epoch [20/200] batch [10/314] time 0.046 (0.402) data 0.005 (0.007) loss 0.0012 lr 1.0000e-04 eta 6:20:18
[2025-08-10 19:24:05 codetalker.py line 151]=>INFO: epoch [20/200] batch [15/314] time 0.081 (0.294) data 0.003 (0.006) loss 0.0007 lr 1.0000e-04 eta 4:38:40
[2025-08-10 19:24:06 codetalker.py line 151]=>INFO: epoch [20/200] batch [20/314] time 0.077 (0.241) data 0.003 (0.005) loss 0.0006 lr 1.0000e-04 eta 3:48:10
[2025-08-10 19:24:06 codetalker.py line 151]=>INFO: epoch [20/200] batch [25/314] time 0.076 (0.208) data 0.002 (0.005) loss 0.0008 lr 1.0000e-04 eta 3:17:08
[2025-08-10 19:24:06 codetalker.py line 151]=>INFO: epoch [20/200] batch [30/314] time 0.076 (0.185) data 0.002 (0.005) loss 0.0011 lr 1.0000e-04 eta 2:55:14
[2025-08-10 19:24:07 codetalker.py line 151]=>INFO: epoch [20/200] batch [35/314] time 0.037 (0.168) data 0.003 (0.004) loss 0.0013 lr 1.0000e-04 eta 2:39:19
[2025-08-10 19:24:07 codetalker.py line 151]=>INFO: epoch [20/200] batch [40/314] time 0.078 (0.156) data 0.004 (0.004) loss 0.0011 lr 1.0000e-04 eta 2:27:17
[2025-08-10 19:24:07 codetalker.py line 151]=>INFO: epoch [20/200] batch [45/314] time 0.041 (0.145) data 0.004 (0.004) loss 0.0008 lr 1.0000e-04 eta 2:17:31
[2025-08-10 19:24:08 codetalker.py line 151]=>INFO: epoch [20/200] batch [50/314] time 0.073 (0.136) data 0.004 (0.004) loss 0.0007 lr 1.0000e-04 eta 2:08:53
[2025-08-10 19:24:08 codetalker.py line 151]=>INFO: epoch [20/200] batch [55/314] time 0.079 (0.130) data 0.004 (0.004) loss 0.0008 lr 1.0000e-04 eta 2:03:11
[2025-08-10 19:24:08 codetalker.py line 151]=>INFO: epoch [20/200] batch [60/314] time 0.039 (0.124) data 0.006 (0.004) loss 0.0013 lr 1.0000e-04 eta 1:57:45
[2025-08-10 19:24:09 codetalker.py line 151]=>INFO: epoch [20/200] batch [65/314] time 0.047 (0.119) data 0.003 (0.004) loss 0.0015 lr 1.0000e-04 eta 1:52:49
[2025-08-10 19:24:09 codetalker.py line 151]=>INFO: epoch [20/200] batch [70/314] time 0.081 (0.115) data 0.005 (0.004) loss 0.0009 lr 1.0000e-04 eta 1:49:02
[2025-08-10 19:24:09 codetalker.py line 151]=>INFO: epoch [20/200] batch [75/314] time 0.054 (0.112) data 0.004 (0.004) loss 0.0007 lr 1.0000e-04 eta 1:45:37
[2025-08-10 19:24:10 codetalker.py line 151]=>INFO: epoch [20/200] batch [80/314] time 0.042 (0.108) data 0.004 (0.004) loss 0.0006 lr 1.0000e-04 eta 1:42:16
[2025-08-10 19:24:10 codetalker.py line 151]=>INFO: epoch [20/200] batch [85/314] time 0.041 (0.106) data 0.003 (0.004) loss 0.0009 lr 1.0000e-04 eta 1:39:59
[2025-08-10 19:24:10 codetalker.py line 151]=>INFO: epoch [20/200] batch [90/314] time 0.078 (0.103) data 0.003 (0.004) loss 0.0012 lr 1.0000e-04 eta 1:37:41
[2025-08-10 19:24:10 codetalker.py line 151]=>INFO: epoch [20/200] batch [95/314] time 0.041 (0.101) data 0.004 (0.004) loss 0.0015 lr 1.0000e-04 eta 1:35:19
[2025-08-10 19:24:11 codetalker.py line 151]=>INFO: epoch [20/200] batch [100/314] time 0.044 (0.099) data 0.008 (0.004) loss 0.0012 lr 1.0000e-04 eta 1:33:09
[2025-08-10 19:24:11 codetalker.py line 151]=>INFO: epoch [20/200] batch [105/314] time 0.040 (0.097) data 0.005 (0.004) loss 0.0006 lr 1.0000e-04 eta 1:31:31
[2025-08-10 19:24:11 codetalker.py line 151]=>INFO: epoch [20/200] batch [110/314] time 0.047 (0.095) data 0.003 (0.004) loss 0.0008 lr 1.0000e-04 eta 1:29:41
[2025-08-10 19:24:12 codetalker.py line 151]=>INFO: epoch [20/200] batch [115/314] time 0.041 (0.093) data 0.005 (0.004) loss 0.0007 lr 1.0000e-04 eta 1:28:09
[2025-08-10 19:24:12 codetalker.py line 151]=>INFO: epoch [20/200] batch [120/314] time 0.045 (0.092) data 0.003 (0.004) loss 0.0009 lr 1.0000e-04 eta 1:26:47
[2025-08-10 19:24:12 codetalker.py line 151]=>INFO: epoch [20/200] batch [125/314] time 0.037 (0.090) data 0.003 (0.004) loss 0.0010 lr 1.0000e-04 eta 1:25:12
[2025-08-10 19:24:13 codetalker.py line 151]=>INFO: epoch [20/200] batch [130/314] time 0.080 (0.089) data 0.003 (0.004) loss 0.0009 lr 1.0000e-04 eta 1:24:17
[2025-08-10 19:24:13 codetalker.py line 151]=>INFO: epoch [20/200] batch [135/314] time 0.036 (0.088) data 0.003 (0.004) loss 0.0010 lr 1.0000e-04 eta 1:23:21
[2025-08-10 19:24:13 codetalker.py line 151]=>INFO: epoch [20/200] batch [140/314] time 0.041 (0.087) data 0.003 (0.004) loss 0.0009 lr 1.0000e-04 eta 1:21:47
[2025-08-10 19:24:13 codetalker.py line 151]=>INFO: epoch [20/200] batch [145/314] time 0.040 (0.085) data 0.005 (0.004) loss 0.0008 lr 1.0000e-04 eta 1:20:21
[2025-08-10 19:24:14 codetalker.py line 151]=>INFO: epoch [20/200] batch [150/314] time 0.042 (0.084) data 0.004 (0.004) loss 0.0010 lr 1.0000e-04 eta 1:19:39
[2025-08-10 19:24:14 codetalker.py line 151]=>INFO: epoch [20/200] batch [155/314] time 0.081 (0.083) data 0.003 (0.004) loss 0.0012 lr 1.0000e-04 eta 1:18:50
[2025-08-10 19:24:14 codetalker.py line 151]=>INFO: epoch [20/200] batch [160/314] time 0.041 (0.082) data 0.007 (0.004) loss 0.0013 lr 1.0000e-04 eta 1:17:53
[2025-08-10 19:24:14 codetalker.py line 151]=>INFO: epoch [20/200] batch [165/314] time 0.035 (0.081) data 0.000 (0.004) loss 0.0009 lr 1.0000e-04 eta 1:16:53
[2025-08-10 19:24:15 codetalker.py line 151]=>INFO: epoch [20/200] batch [170/314] time 0.049 (0.081) data 0.003 (0.004) loss 0.0009 lr 1.0000e-04 eta 1:16:13
[2025-08-10 19:24:15 codetalker.py line 151]=>INFO: epoch [20/200] batch [175/314] time 0.074 (0.080) data 0.005 (0.004) loss 0.0008 lr 1.0000e-04 eta 1:15:19
[2025-08-10 19:24:15 codetalker.py line 151]=>INFO: epoch [20/200] batch [180/314] time 0.089 (0.079) data 0.003 (0.004) loss 0.0010 lr 1.0000e-04 eta 1:14:46
[2025-08-10 19:24:16 codetalker.py line 151]=>INFO: epoch [20/200] batch [185/314] time 0.038 (0.078) data 0.005 (0.004) loss 0.0012 lr 1.0000e-04 eta 1:14:05
[2025-08-10 19:24:16 codetalker.py line 151]=>INFO: epoch [20/200] batch [190/314] time 0.032 (0.077) data 0.004 (0.004) loss 0.0013 lr 1.0000e-04 eta 1:13:03
[2025-08-10 19:24:16 codetalker.py line 151]=>INFO: epoch [20/200] batch [195/314] time 0.039 (0.077) data 0.003 (0.004) loss 0.0010 lr 1.0000e-04 eta 1:12:25
[2025-08-10 19:24:16 codetalker.py line 151]=>INFO: epoch [20/200] batch [200/314] time 0.038 (0.076) data 0.004 (0.004) loss 0.0006 lr 1.0000e-04 eta 1:11:45
[2025-08-10 19:24:17 codetalker.py line 151]=>INFO: epoch [20/200] batch [205/314] time 0.037 (0.076) data 0.005 (0.004) loss 0.0008 lr 1.0000e-04 eta 1:11:17
[2025-08-10 19:24:17 codetalker.py line 151]=>INFO: epoch [20/200] batch [210/314] time 0.072 (0.075) data 0.004 (0.004) loss 0.0010 lr 1.0000e-04 eta 1:10:35
[2025-08-10 19:24:17 codetalker.py line 151]=>INFO: epoch [20/200] batch [215/314] time 0.037 (0.074) data 0.003 (0.004) loss 0.0011 lr 1.0000e-04 eta 1:09:43
[2025-08-10 19:24:17 codetalker.py line 151]=>INFO: epoch [20/200] batch [220/314] time 0.042 (0.073) data 0.000 (0.004) loss 0.0012 lr 1.0000e-04 eta 1:09:09
[2025-08-10 19:24:17 codetalker.py line 151]=>INFO: epoch [20/200] batch [225/314] time 0.080 (0.073) data 0.004 (0.004) loss 0.0011 lr 1.0000e-04 eta 1:08:43
[2025-08-10 19:24:18 codetalker.py line 151]=>INFO: epoch [20/200] batch [230/314] time 0.043 (0.072) data 0.003 (0.004) loss 0.0008 lr 1.0000e-04 eta 1:08:02
[2025-08-10 19:24:18 codetalker.py line 151]=>INFO: epoch [20/200] batch [235/314] time 0.033 (0.071) data 0.003 (0.004) loss 0.0006 lr 1.0000e-04 eta 1:07:19
[2025-08-10 19:24:18 codetalker.py line 151]=>INFO: epoch [20/200] batch [240/314] time 0.040 (0.071) data 0.003 (0.004) loss 0.0006 lr 1.0000e-04 eta 1:06:55
[2025-08-10 19:24:18 codetalker.py line 151]=>INFO: epoch [20/200] batch [245/314] time 0.085 (0.071) data 0.005 (0.004) loss 0.0012 lr 1.0000e-04 eta 1:06:31
[2025-08-10 19:24:19 codetalker.py line 151]=>INFO: epoch [20/200] batch [250/314] time 0.092 (0.070) data 0.004 (0.004) loss 0.0015 lr 1.0000e-04 eta 1:06:07
[2025-08-10 19:24:19 codetalker.py line 151]=>INFO: epoch [20/200] batch [255/314] time 0.041 (0.070) data 0.002 (0.004) loss 0.0013 lr 1.0000e-04 eta 1:05:36
[2025-08-10 19:24:19 codetalker.py line 151]=>INFO: epoch [20/200] batch [260/314] time 0.086 (0.069) data 0.005 (0.004) loss 0.0006 lr 1.0000e-04 eta 1:05:18
[2025-08-10 19:24:19 codetalker.py line 151]=>INFO: epoch [20/200] batch [265/314] time 0.030 (0.069) data 0.002 (0.004) loss 0.0007 lr 1.0000e-04 eta 1:04:51
[2025-08-10 19:24:20 codetalker.py line 151]=>INFO: epoch [20/200] batch [270/314] time 0.035 (0.068) data 0.004 (0.004) loss 0.0007 lr 1.0000e-04 eta 1:04:22
[2025-08-10 19:24:20 codetalker.py line 151]=>INFO: epoch [20/200] batch [275/314] time 0.042 (0.068) data 0.003 (0.004) loss 0.0007 lr 1.0000e-04 eta 1:03:54
[2025-08-10 19:24:20 codetalker.py line 151]=>INFO: epoch [20/200] batch [280/314] time 0.039 (0.068) data 0.004 (0.004) loss 0.0011 lr 1.0000e-04 eta 1:03:43
[2025-08-10 19:24:20 codetalker.py line 151]=>INFO: epoch [20/200] batch [285/314] time 0.039 (0.067) data 0.004 (0.004) loss 0.0016 lr 1.0000e-04 eta 1:03:16
[2025-08-10 19:24:21 codetalker.py line 151]=>INFO: epoch [20/200] batch [290/314] time 0.093 (0.067) data 0.002 (0.004) loss 0.0014 lr 1.0000e-04 eta 1:03:04
[2025-08-10 19:24:21 codetalker.py line 151]=>INFO: epoch [20/200] batch [295/314] time 0.040 (0.067) data 0.004 (0.004) loss 0.0010 lr 1.0000e-04 eta 1:02:46
[2025-08-10 19:24:21 codetalker.py line 151]=>INFO: epoch [20/200] batch [300/314] time 0.043 (0.066) data 0.003 (0.004) loss 0.0007 lr 1.0000e-04 eta 1:02:26
[2025-08-10 19:24:21 codetalker.py line 151]=>INFO: epoch [20/200] batch [305/314] time 0.027 (0.066) data 0.002 (0.004) loss 0.0007 lr 1.0000e-04 eta 1:02:07
[2025-08-10 19:24:22 codetalker.py line 151]=>INFO: epoch [20/200] batch [310/314] time 0.041 (0.066) data 0.004 (0.004) loss 0.0007 lr 1.0000e-04 eta 1:01:48
[2025-08-10 19:24:22 codetalker.py line 161]=>INFO: epoch: 20 loss_train: 0.0009711907570736756 pp_train: 11.685858437969426 
[2025-08-10 19:24:22 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:24:22 codetalker.py line 234]=>INFO: epoch: 20 loss_val: 0.0005803412903333082 pp_val: 1.0 
[2025-08-10 19:24:24 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:24:25 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-20
[2025-08-10 19:24:25 codetalker.py line 151]=>INFO: epoch [21/200] batch [5/314] time 0.036 (0.051) data 0.004 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:48:12
[2025-08-10 19:24:26 codetalker.py line 151]=>INFO: epoch [21/200] batch [10/314] time 0.042 (0.045) data 0.003 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:42:25
[2025-08-10 19:24:26 codetalker.py line 151]=>INFO: epoch [21/200] batch [15/314] time 0.037 (0.043) data 0.002 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:40:19
[2025-08-10 19:24:26 codetalker.py line 151]=>INFO: epoch [21/200] batch [20/314] time 0.038 (0.042) data 0.004 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:39:46
[2025-08-10 19:24:26 codetalker.py line 151]=>INFO: epoch [21/200] batch [25/314] time 0.039 (0.042) data 0.002 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:39:10
[2025-08-10 19:24:27 codetalker.py line 151]=>INFO: epoch [21/200] batch [30/314] time 0.058 (0.043) data 0.004 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:40:03
[2025-08-10 19:24:27 codetalker.py line 151]=>INFO: epoch [21/200] batch [35/314] time 0.031 (0.042) data 0.004 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:39:42
[2025-08-10 19:24:27 codetalker.py line 151]=>INFO: epoch [21/200] batch [40/314] time 0.034 (0.041) data 0.004 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:38:35
[2025-08-10 19:24:27 codetalker.py line 151]=>INFO: epoch [21/200] batch [45/314] time 0.033 (0.040) data 0.003 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:37:49
[2025-08-10 19:24:27 codetalker.py line 151]=>INFO: epoch [21/200] batch [50/314] time 0.040 (0.040) data 0.003 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:37:15
[2025-08-10 19:24:27 codetalker.py line 151]=>INFO: epoch [21/200] batch [55/314] time 0.034 (0.039) data 0.005 (0.003) loss 0.0009 lr 5.0000e-05 eta 0:36:38
[2025-08-10 19:24:28 codetalker.py line 151]=>INFO: epoch [21/200] batch [60/314] time 0.035 (0.038) data 0.000 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:36:11
[2025-08-10 19:24:28 codetalker.py line 151]=>INFO: epoch [21/200] batch [65/314] time 0.034 (0.038) data 0.003 (0.003) loss 0.0008 lr 5.0000e-05 eta 0:35:51
[2025-08-10 19:24:28 codetalker.py line 151]=>INFO: epoch [21/200] batch [70/314] time 0.033 (0.038) data 0.004 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:35:36
[2025-08-10 19:24:28 codetalker.py line 151]=>INFO: epoch [21/200] batch [75/314] time 0.035 (0.038) data 0.004 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:35:21
[2025-08-10 19:24:28 codetalker.py line 151]=>INFO: epoch [21/200] batch [80/314] time 0.033 (0.037) data 0.003 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:35:09
[2025-08-10 19:24:28 codetalker.py line 151]=>INFO: epoch [21/200] batch [85/314] time 0.034 (0.037) data 0.004 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:34:56
[2025-08-10 19:24:29 codetalker.py line 151]=>INFO: epoch [21/200] batch [90/314] time 0.034 (0.037) data 0.003 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:34:50
[2025-08-10 19:24:29 codetalker.py line 151]=>INFO: epoch [21/200] batch [95/314] time 0.035 (0.037) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:34:41
[2025-08-10 19:24:29 codetalker.py line 151]=>INFO: epoch [21/200] batch [100/314] time 0.032 (0.037) data 0.002 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:34:34
[2025-08-10 19:24:29 codetalker.py line 151]=>INFO: epoch [21/200] batch [105/314] time 0.036 (0.037) data 0.004 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:34:30
[2025-08-10 19:24:29 codetalker.py line 151]=>INFO: epoch [21/200] batch [110/314] time 0.034 (0.037) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:34:30
[2025-08-10 19:24:30 codetalker.py line 151]=>INFO: epoch [21/200] batch [115/314] time 0.034 (0.037) data 0.003 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:34:25
[2025-08-10 19:24:30 codetalker.py line 151]=>INFO: epoch [21/200] batch [120/314] time 0.035 (0.036) data 0.003 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:34:17
[2025-08-10 19:24:30 codetalker.py line 151]=>INFO: epoch [21/200] batch [125/314] time 0.035 (0.036) data 0.004 (0.003) loss 0.0009 lr 5.0000e-05 eta 0:34:14
[2025-08-10 19:24:30 codetalker.py line 151]=>INFO: epoch [21/200] batch [130/314] time 0.039 (0.036) data 0.005 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:34:12
[2025-08-10 19:24:30 codetalker.py line 151]=>INFO: epoch [21/200] batch [135/314] time 0.034 (0.036) data 0.004 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:34:08
[2025-08-10 19:24:30 codetalker.py line 151]=>INFO: epoch [21/200] batch [140/314] time 0.036 (0.036) data 0.003 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:34:01
[2025-08-10 19:24:31 codetalker.py line 151]=>INFO: epoch [21/200] batch [145/314] time 0.033 (0.036) data 0.002 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:56
[2025-08-10 19:24:31 codetalker.py line 151]=>INFO: epoch [21/200] batch [150/314] time 0.033 (0.036) data 0.004 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:52
[2025-08-10 19:24:31 codetalker.py line 151]=>INFO: epoch [21/200] batch [155/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:50
[2025-08-10 19:24:31 codetalker.py line 151]=>INFO: epoch [21/200] batch [160/314] time 0.036 (0.036) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:48
[2025-08-10 19:24:31 codetalker.py line 151]=>INFO: epoch [21/200] batch [165/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:48
[2025-08-10 19:24:32 codetalker.py line 151]=>INFO: epoch [21/200] batch [170/314] time 0.034 (0.036) data 0.004 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:33:44
[2025-08-10 19:24:32 codetalker.py line 151]=>INFO: epoch [21/200] batch [175/314] time 0.034 (0.036) data 0.004 (0.003) loss 0.0009 lr 5.0000e-05 eta 0:33:42
[2025-08-10 19:24:32 codetalker.py line 151]=>INFO: epoch [21/200] batch [180/314] time 0.035 (0.036) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:41
[2025-08-10 19:24:32 codetalker.py line 151]=>INFO: epoch [21/200] batch [185/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:33:37
[2025-08-10 19:24:32 codetalker.py line 151]=>INFO: epoch [21/200] batch [190/314] time 0.033 (0.036) data 0.001 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:33:36
[2025-08-10 19:24:32 codetalker.py line 151]=>INFO: epoch [21/200] batch [195/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:33:33
[2025-08-10 19:24:33 codetalker.py line 151]=>INFO: epoch [21/200] batch [200/314] time 0.035 (0.036) data 0.004 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:33:31
[2025-08-10 19:24:33 codetalker.py line 151]=>INFO: epoch [21/200] batch [205/314] time 0.039 (0.036) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:33:29
[2025-08-10 19:24:33 codetalker.py line 151]=>INFO: epoch [21/200] batch [210/314] time 0.037 (0.036) data 0.004 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:33:26
[2025-08-10 19:24:33 codetalker.py line 151]=>INFO: epoch [21/200] batch [215/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:33:23
[2025-08-10 19:24:33 codetalker.py line 151]=>INFO: epoch [21/200] batch [220/314] time 0.028 (0.036) data 0.000 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:33:18
[2025-08-10 19:24:33 codetalker.py line 151]=>INFO: epoch [21/200] batch [225/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0009 lr 5.0000e-05 eta 0:33:13
[2025-08-10 19:24:34 codetalker.py line 151]=>INFO: epoch [21/200] batch [230/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:33:11
[2025-08-10 19:24:34 codetalker.py line 151]=>INFO: epoch [21/200] batch [235/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0009 lr 5.0000e-05 eta 0:33:08
[2025-08-10 19:24:34 codetalker.py line 151]=>INFO: epoch [21/200] batch [240/314] time 0.036 (0.035) data 0.004 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:33:07
[2025-08-10 19:24:34 codetalker.py line 151]=>INFO: epoch [21/200] batch [245/314] time 0.033 (0.035) data 0.007 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:33:04
[2025-08-10 19:24:34 codetalker.py line 151]=>INFO: epoch [21/200] batch [250/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:03
[2025-08-10 19:24:35 codetalker.py line 151]=>INFO: epoch [21/200] batch [255/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:33:02
[2025-08-10 19:24:35 codetalker.py line 151]=>INFO: epoch [21/200] batch [260/314] time 0.032 (0.035) data 0.001 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:00
[2025-08-10 19:24:35 codetalker.py line 151]=>INFO: epoch [21/200] batch [265/314] time 0.039 (0.035) data 0.005 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:33:00
[2025-08-10 19:24:35 codetalker.py line 151]=>INFO: epoch [21/200] batch [270/314] time 0.047 (0.035) data 0.004 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:33:07
[2025-08-10 19:24:35 codetalker.py line 151]=>INFO: epoch [21/200] batch [275/314] time 0.044 (0.035) data 0.005 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:33:14
[2025-08-10 19:24:36 codetalker.py line 151]=>INFO: epoch [21/200] batch [280/314] time 0.032 (0.035) data 0.005 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:33:16
[2025-08-10 19:24:36 codetalker.py line 151]=>INFO: epoch [21/200] batch [285/314] time 0.040 (0.036) data 0.004 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:33:19
[2025-08-10 19:24:36 codetalker.py line 151]=>INFO: epoch [21/200] batch [290/314] time 0.042 (0.036) data 0.000 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:24
[2025-08-10 19:24:36 codetalker.py line 151]=>INFO: epoch [21/200] batch [295/314] time 0.051 (0.036) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:30
[2025-08-10 19:24:36 codetalker.py line 151]=>INFO: epoch [21/200] batch [300/314] time 0.041 (0.036) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:38
[2025-08-10 19:24:37 codetalker.py line 151]=>INFO: epoch [21/200] batch [305/314] time 0.042 (0.036) data 0.005 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:33:45
[2025-08-10 19:24:37 codetalker.py line 151]=>INFO: epoch [21/200] batch [310/314] time 0.038 (0.036) data 0.003 (0.003) loss 0.0010 lr 5.0000e-05 eta 0:33:50
[2025-08-10 19:24:37 codetalker.py line 161]=>INFO: epoch: 21 loss_train: 0.0011232272893484017 pp_train: 11.680116938937243 
[2025-08-10 19:24:37 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:24:38 codetalker.py line 234]=>INFO: epoch: 21 loss_val: 0.0008654886420117691 pp_val: 1.0 
[2025-08-10 19:24:39 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:24:40 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-21
[2025-08-10 19:24:41 codetalker.py line 151]=>INFO: epoch [22/200] batch [5/314] time 0.037 (0.047) data 0.001 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:44:25
[2025-08-10 19:24:41 codetalker.py line 151]=>INFO: epoch [22/200] batch [10/314] time 0.046 (0.047) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:43:43
[2025-08-10 19:24:41 codetalker.py line 151]=>INFO: epoch [22/200] batch [15/314] time 0.051 (0.047) data 0.002 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:44:05
[2025-08-10 19:24:41 codetalker.py line 151]=>INFO: epoch [22/200] batch [20/314] time 0.050 (0.046) data 0.002 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:43:01
[2025-08-10 19:24:42 codetalker.py line 151]=>INFO: epoch [22/200] batch [25/314] time 0.041 (0.046) data 0.002 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:42:46
[2025-08-10 19:24:42 codetalker.py line 151]=>INFO: epoch [22/200] batch [30/314] time 0.046 (0.045) data 0.000 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:41:58
[2025-08-10 19:24:42 codetalker.py line 151]=>INFO: epoch [22/200] batch [35/314] time 0.034 (0.044) data 0.000 (0.002) loss 0.0012 lr 5.0000e-05 eta 0:41:00
[2025-08-10 19:24:42 codetalker.py line 151]=>INFO: epoch [22/200] batch [40/314] time 0.033 (0.043) data 0.003 (0.002) loss 0.0013 lr 5.0000e-05 eta 0:40:05
[2025-08-10 19:24:42 codetalker.py line 151]=>INFO: epoch [22/200] batch [45/314] time 0.033 (0.042) data 0.000 (0.002) loss 0.0013 lr 5.0000e-05 eta 0:39:13
[2025-08-10 19:24:43 codetalker.py line 151]=>INFO: epoch [22/200] batch [50/314] time 0.031 (0.041) data 0.002 (0.002) loss 0.0014 lr 5.0000e-05 eta 0:38:36
[2025-08-10 19:24:43 codetalker.py line 151]=>INFO: epoch [22/200] batch [55/314] time 0.035 (0.040) data 0.004 (0.002) loss 0.0014 lr 5.0000e-05 eta 0:37:51
[2025-08-10 19:24:43 codetalker.py line 151]=>INFO: epoch [22/200] batch [60/314] time 0.032 (0.040) data 0.002 (0.002) loss 0.0012 lr 5.0000e-05 eta 0:37:14
[2025-08-10 19:24:43 codetalker.py line 151]=>INFO: epoch [22/200] batch [65/314] time 0.034 (0.040) data 0.003 (0.002) loss 0.0013 lr 5.0000e-05 eta 0:37:09
[2025-08-10 19:24:43 codetalker.py line 151]=>INFO: epoch [22/200] batch [70/314] time 0.047 (0.040) data 0.002 (0.002) loss 0.0012 lr 5.0000e-05 eta 0:37:45
[2025-08-10 19:24:44 codetalker.py line 151]=>INFO: epoch [22/200] batch [75/314] time 0.048 (0.041) data 0.005 (0.002) loss 0.0011 lr 5.0000e-05 eta 0:38:08
[2025-08-10 19:24:44 codetalker.py line 151]=>INFO: epoch [22/200] batch [80/314] time 0.038 (0.041) data 0.002 (0.002) loss 0.0012 lr 5.0000e-05 eta 0:38:12
[2025-08-10 19:24:44 codetalker.py line 151]=>INFO: epoch [22/200] batch [85/314] time 0.039 (0.041) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:16
[2025-08-10 19:24:44 codetalker.py line 151]=>INFO: epoch [22/200] batch [90/314] time 0.048 (0.041) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:11
[2025-08-10 19:24:44 codetalker.py line 151]=>INFO: epoch [22/200] batch [95/314] time 0.046 (0.041) data 0.003 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:38:12
[2025-08-10 19:24:45 codetalker.py line 151]=>INFO: epoch [22/200] batch [100/314] time 0.051 (0.041) data 0.005 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:22
[2025-08-10 19:24:45 codetalker.py line 151]=>INFO: epoch [22/200] batch [105/314] time 0.042 (0.041) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:38:22
[2025-08-10 19:24:45 codetalker.py line 151]=>INFO: epoch [22/200] batch [110/314] time 0.036 (0.041) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:13
[2025-08-10 19:24:45 codetalker.py line 151]=>INFO: epoch [22/200] batch [115/314] time 0.047 (0.041) data 0.002 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:38:13
[2025-08-10 19:24:46 codetalker.py line 151]=>INFO: epoch [22/200] batch [120/314] time 0.047 (0.041) data 0.000 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:18
[2025-08-10 19:24:46 codetalker.py line 151]=>INFO: epoch [22/200] batch [125/314] time 0.044 (0.041) data 0.003 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:38:34
[2025-08-10 19:24:46 codetalker.py line 151]=>INFO: epoch [22/200] batch [130/314] time 0.050 (0.041) data 0.000 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:42
[2025-08-10 19:24:46 codetalker.py line 151]=>INFO: epoch [22/200] batch [135/314] time 0.045 (0.041) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:35
[2025-08-10 19:24:46 codetalker.py line 151]=>INFO: epoch [22/200] batch [140/314] time 0.052 (0.041) data 0.000 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:38
[2025-08-10 19:24:47 codetalker.py line 151]=>INFO: epoch [22/200] batch [145/314] time 0.040 (0.041) data 0.002 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:38
[2025-08-10 19:24:47 codetalker.py line 151]=>INFO: epoch [22/200] batch [150/314] time 0.049 (0.041) data 0.004 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:38
[2025-08-10 19:24:47 codetalker.py line 151]=>INFO: epoch [22/200] batch [155/314] time 0.038 (0.041) data 0.004 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:38:31
[2025-08-10 19:24:47 codetalker.py line 151]=>INFO: epoch [22/200] batch [160/314] time 0.040 (0.041) data 0.002 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:38:23
[2025-08-10 19:24:47 codetalker.py line 151]=>INFO: epoch [22/200] batch [165/314] time 0.029 (0.041) data 0.000 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:38:21
[2025-08-10 19:24:48 codetalker.py line 151]=>INFO: epoch [22/200] batch [170/314] time 0.036 (0.041) data 0.003 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:38:11
[2025-08-10 19:24:48 codetalker.py line 151]=>INFO: epoch [22/200] batch [175/314] time 0.034 (0.041) data 0.003 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:37:58
[2025-08-10 19:24:48 codetalker.py line 151]=>INFO: epoch [22/200] batch [180/314] time 0.033 (0.040) data 0.001 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:37:46
[2025-08-10 19:24:48 codetalker.py line 151]=>INFO: epoch [22/200] batch [185/314] time 0.033 (0.040) data 0.004 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:37:36
[2025-08-10 19:24:48 codetalker.py line 151]=>INFO: epoch [22/200] batch [190/314] time 0.029 (0.040) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:37:25
[2025-08-10 19:24:48 codetalker.py line 151]=>INFO: epoch [22/200] batch [195/314] time 0.032 (0.040) data 0.002 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:37:14
[2025-08-10 19:24:49 codetalker.py line 151]=>INFO: epoch [22/200] batch [200/314] time 0.032 (0.040) data 0.002 (0.003) loss 0.0011 lr 5.0000e-05 eta 0:37:02
[2025-08-10 19:24:49 codetalker.py line 151]=>INFO: epoch [22/200] batch [205/314] time 0.032 (0.040) data 0.002 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:36:52
[2025-08-10 19:24:49 codetalker.py line 151]=>INFO: epoch [22/200] batch [210/314] time 0.033 (0.039) data 0.002 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:36:45
[2025-08-10 19:24:49 codetalker.py line 151]=>INFO: epoch [22/200] batch [215/314] time 0.033 (0.039) data 0.002 (0.003) loss 0.0012 lr 5.0000e-05 eta 0:36:39
[2025-08-10 19:24:49 codetalker.py line 151]=>INFO: epoch [22/200] batch [220/314] time 0.034 (0.039) data 0.002 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:36:31
[2025-08-10 19:24:50 codetalker.py line 151]=>INFO: epoch [22/200] batch [225/314] time 0.034 (0.039) data 0.000 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:36:23
[2025-08-10 19:24:50 codetalker.py line 151]=>INFO: epoch [22/200] batch [230/314] time 0.027 (0.039) data 0.002 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:36:15
[2025-08-10 19:24:50 codetalker.py line 151]=>INFO: epoch [22/200] batch [235/314] time 0.033 (0.039) data 0.003 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:36:09
[2025-08-10 19:24:50 codetalker.py line 151]=>INFO: epoch [22/200] batch [240/314] time 0.032 (0.039) data 0.003 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:36:03
[2025-08-10 19:24:50 codetalker.py line 151]=>INFO: epoch [22/200] batch [245/314] time 0.034 (0.039) data 0.000 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:35:57
[2025-08-10 19:24:50 codetalker.py line 151]=>INFO: epoch [22/200] batch [250/314] time 0.033 (0.038) data 0.003 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:35:52
[2025-08-10 19:24:51 codetalker.py line 151]=>INFO: epoch [22/200] batch [255/314] time 0.033 (0.038) data 0.002 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:35:47
[2025-08-10 19:24:51 codetalker.py line 151]=>INFO: epoch [22/200] batch [260/314] time 0.036 (0.038) data 0.004 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:35:42
[2025-08-10 19:24:51 codetalker.py line 151]=>INFO: epoch [22/200] batch [265/314] time 0.031 (0.038) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:35:36
[2025-08-10 19:24:51 codetalker.py line 151]=>INFO: epoch [22/200] batch [270/314] time 0.031 (0.038) data 0.002 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:35:33
[2025-08-10 19:24:51 codetalker.py line 151]=>INFO: epoch [22/200] batch [275/314] time 0.034 (0.038) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:35:29
[2025-08-10 19:24:51 codetalker.py line 151]=>INFO: epoch [22/200] batch [280/314] time 0.038 (0.038) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:35:27
[2025-08-10 19:24:52 codetalker.py line 151]=>INFO: epoch [22/200] batch [285/314] time 0.032 (0.038) data 0.002 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:35:23
[2025-08-10 19:24:52 codetalker.py line 151]=>INFO: epoch [22/200] batch [290/314] time 0.038 (0.038) data 0.005 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:35:20
[2025-08-10 19:24:52 codetalker.py line 151]=>INFO: epoch [22/200] batch [295/314] time 0.033 (0.038) data 0.003 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:35:17
[2025-08-10 19:24:52 codetalker.py line 151]=>INFO: epoch [22/200] batch [300/314] time 0.030 (0.038) data 0.003 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:35:12
[2025-08-10 19:24:52 codetalker.py line 151]=>INFO: epoch [22/200] batch [305/314] time 0.033 (0.038) data 0.004 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:35:10
[2025-08-10 19:24:53 codetalker.py line 151]=>INFO: epoch [22/200] batch [310/314] time 0.027 (0.038) data 0.003 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:35:05
[2025-08-10 19:24:53 codetalker.py line 161]=>INFO: epoch: 22 loss_train: 0.0013207434980602117 pp_train: 11.68606550374608 
[2025-08-10 19:24:53 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:24:53 codetalker.py line 234]=>INFO: epoch: 22 loss_val: 0.0011778484185924754 pp_val: 1.0 
[2025-08-10 19:24:55 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:24:56 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-22
[2025-08-10 19:24:56 codetalker.py line 151]=>INFO: epoch [23/200] batch [5/314] time 0.053 (0.053) data 0.002 (0.002) loss 0.0015 lr 5.0000e-05 eta 0:49:25
[2025-08-10 19:24:57 codetalker.py line 151]=>INFO: epoch [23/200] batch [10/314] time 0.046 (0.048) data 0.007 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:44:54
[2025-08-10 19:24:57 codetalker.py line 151]=>INFO: epoch [23/200] batch [15/314] time 0.045 (0.047) data 0.005 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:43:19
[2025-08-10 19:24:57 codetalker.py line 151]=>INFO: epoch [23/200] batch [20/314] time 0.036 (0.046) data 0.004 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:42:33
[2025-08-10 19:24:57 codetalker.py line 151]=>INFO: epoch [23/200] batch [25/314] time 0.042 (0.045) data 0.003 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:41:56
[2025-08-10 19:24:57 codetalker.py line 151]=>INFO: epoch [23/200] batch [30/314] time 0.050 (0.046) data 0.005 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:42:48
[2025-08-10 19:24:58 codetalker.py line 151]=>INFO: epoch [23/200] batch [35/314] time 0.032 (0.044) data 0.002 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:40:59
[2025-08-10 19:24:58 codetalker.py line 151]=>INFO: epoch [23/200] batch [40/314] time 0.036 (0.043) data 0.003 (0.003) loss 0.0013 lr 5.0000e-05 eta 0:39:53
[2025-08-10 19:24:58 codetalker.py line 151]=>INFO: epoch [23/200] batch [45/314] time 0.033 (0.042) data 0.005 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:38:52
[2025-08-10 19:24:58 codetalker.py line 151]=>INFO: epoch [23/200] batch [50/314] time 0.033 (0.041) data 0.000 (0.002) loss 0.0015 lr 5.0000e-05 eta 0:37:51
[2025-08-10 19:24:58 codetalker.py line 151]=>INFO: epoch [23/200] batch [55/314] time 0.034 (0.040) data 0.003 (0.002) loss 0.0015 lr 5.0000e-05 eta 0:37:08
[2025-08-10 19:24:59 codetalker.py line 151]=>INFO: epoch [23/200] batch [60/314] time 0.035 (0.039) data 0.004 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:36:43
[2025-08-10 19:24:59 codetalker.py line 151]=>INFO: epoch [23/200] batch [65/314] time 0.033 (0.039) data 0.004 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:36:22
[2025-08-10 19:24:59 codetalker.py line 151]=>INFO: epoch [23/200] batch [70/314] time 0.041 (0.039) data 0.003 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:36:08
[2025-08-10 19:24:59 codetalker.py line 151]=>INFO: epoch [23/200] batch [75/314] time 0.029 (0.038) data 0.003 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:35:45
[2025-08-10 19:24:59 codetalker.py line 151]=>INFO: epoch [23/200] batch [80/314] time 0.033 (0.038) data 0.002 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:35:24
[2025-08-10 19:24:59 codetalker.py line 151]=>INFO: epoch [23/200] batch [85/314] time 0.032 (0.038) data 0.002 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:35:06
[2025-08-10 19:25:00 codetalker.py line 151]=>INFO: epoch [23/200] batch [90/314] time 0.033 (0.038) data 0.000 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:34:53
[2025-08-10 19:25:00 codetalker.py line 151]=>INFO: epoch [23/200] batch [95/314] time 0.035 (0.037) data 0.003 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:34:43
[2025-08-10 19:25:00 codetalker.py line 151]=>INFO: epoch [23/200] batch [100/314] time 0.032 (0.037) data 0.002 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:34:32
[2025-08-10 19:25:00 codetalker.py line 151]=>INFO: epoch [23/200] batch [105/314] time 0.036 (0.037) data 0.002 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:34:24
[2025-08-10 19:25:00 codetalker.py line 151]=>INFO: epoch [23/200] batch [110/314] time 0.034 (0.037) data 0.004 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:34:15
[2025-08-10 19:25:00 codetalker.py line 151]=>INFO: epoch [23/200] batch [115/314] time 0.040 (0.037) data 0.004 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:34:12
[2025-08-10 19:25:01 codetalker.py line 151]=>INFO: epoch [23/200] batch [120/314] time 0.033 (0.037) data 0.003 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:34:09
[2025-08-10 19:25:01 codetalker.py line 151]=>INFO: epoch [23/200] batch [125/314] time 0.033 (0.037) data 0.002 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:34:04
[2025-08-10 19:25:01 codetalker.py line 151]=>INFO: epoch [23/200] batch [130/314] time 0.035 (0.037) data 0.004 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:33:59
[2025-08-10 19:25:01 codetalker.py line 151]=>INFO: epoch [23/200] batch [135/314] time 0.035 (0.037) data 0.003 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:33:55
[2025-08-10 19:25:01 codetalker.py line 151]=>INFO: epoch [23/200] batch [140/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:33:53
[2025-08-10 19:25:02 codetalker.py line 151]=>INFO: epoch [23/200] batch [145/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:33:48
[2025-08-10 19:25:02 codetalker.py line 151]=>INFO: epoch [23/200] batch [150/314] time 0.034 (0.036) data 0.000 (0.003) loss 0.0014 lr 5.0000e-05 eta 0:33:46
[2025-08-10 19:25:02 codetalker.py line 151]=>INFO: epoch [23/200] batch [155/314] time 0.036 (0.036) data 0.005 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:33:44
[2025-08-10 19:25:02 codetalker.py line 151]=>INFO: epoch [23/200] batch [160/314] time 0.032 (0.036) data 0.003 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:33:39
[2025-08-10 19:25:02 codetalker.py line 151]=>INFO: epoch [23/200] batch [165/314] time 0.036 (0.036) data 0.003 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:33:42
[2025-08-10 19:25:02 codetalker.py line 151]=>INFO: epoch [23/200] batch [170/314] time 0.036 (0.036) data 0.003 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:33:39
[2025-08-10 19:25:03 codetalker.py line 151]=>INFO: epoch [23/200] batch [175/314] time 0.031 (0.036) data 0.002 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:33:35
[2025-08-10 19:25:03 codetalker.py line 151]=>INFO: epoch [23/200] batch [180/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:33:32
[2025-08-10 19:25:03 codetalker.py line 151]=>INFO: epoch [23/200] batch [185/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:33:29
[2025-08-10 19:25:03 codetalker.py line 151]=>INFO: epoch [23/200] batch [190/314] time 0.034 (0.036) data 0.000 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:33:25
[2025-08-10 19:25:03 codetalker.py line 151]=>INFO: epoch [23/200] batch [195/314] time 0.037 (0.036) data 0.003 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:33:24
[2025-08-10 19:25:04 codetalker.py line 151]=>INFO: epoch [23/200] batch [200/314] time 0.035 (0.036) data 0.003 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:33:21
[2025-08-10 19:25:04 codetalker.py line 151]=>INFO: epoch [23/200] batch [205/314] time 0.036 (0.036) data 0.007 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:33:19
[2025-08-10 19:25:04 codetalker.py line 151]=>INFO: epoch [23/200] batch [210/314] time 0.035 (0.036) data 0.005 (0.003) loss 0.0015 lr 5.0000e-05 eta 0:33:16
[2025-08-10 19:25:04 codetalker.py line 151]=>INFO: epoch [23/200] batch [215/314] time 0.035 (0.036) data 0.005 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:33:15
[2025-08-10 19:25:04 codetalker.py line 151]=>INFO: epoch [23/200] batch [220/314] time 0.033 (0.036) data 0.000 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:33:13
[2025-08-10 19:25:04 codetalker.py line 151]=>INFO: epoch [23/200] batch [225/314] time 0.033 (0.036) data 0.001 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:33:10
[2025-08-10 19:25:05 codetalker.py line 151]=>INFO: epoch [23/200] batch [230/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:33:09
[2025-08-10 19:25:05 codetalker.py line 151]=>INFO: epoch [23/200] batch [235/314] time 0.033 (0.036) data 0.001 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:33:06
[2025-08-10 19:25:05 codetalker.py line 151]=>INFO: epoch [23/200] batch [240/314] time 0.036 (0.036) data 0.004 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:33:04
[2025-08-10 19:25:05 codetalker.py line 151]=>INFO: epoch [23/200] batch [245/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:33:02
[2025-08-10 19:25:05 codetalker.py line 151]=>INFO: epoch [23/200] batch [250/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:33:00
[2025-08-10 19:25:06 codetalker.py line 151]=>INFO: epoch [23/200] batch [255/314] time 0.028 (0.036) data 0.002 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:32:59
[2025-08-10 19:25:06 codetalker.py line 151]=>INFO: epoch [23/200] batch [260/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:32:57
[2025-08-10 19:25:06 codetalker.py line 151]=>INFO: epoch [23/200] batch [265/314] time 0.036 (0.036) data 0.003 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:32:58
[2025-08-10 19:25:06 codetalker.py line 151]=>INFO: epoch [23/200] batch [270/314] time 0.036 (0.036) data 0.002 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:33:00
[2025-08-10 19:25:06 codetalker.py line 151]=>INFO: epoch [23/200] batch [275/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:33:00
[2025-08-10 19:25:06 codetalker.py line 151]=>INFO: epoch [23/200] batch [280/314] time 0.034 (0.036) data 0.002 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:32:59
[2025-08-10 19:25:07 codetalker.py line 151]=>INFO: epoch [23/200] batch [285/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:32:58
[2025-08-10 19:25:07 codetalker.py line 151]=>INFO: epoch [23/200] batch [290/314] time 0.036 (0.036) data 0.005 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:32:57
[2025-08-10 19:25:07 codetalker.py line 151]=>INFO: epoch [23/200] batch [295/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0016 lr 5.0000e-05 eta 0:32:54
[2025-08-10 19:25:07 codetalker.py line 151]=>INFO: epoch [23/200] batch [300/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:32:52
[2025-08-10 19:25:07 codetalker.py line 151]=>INFO: epoch [23/200] batch [305/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:32:50
[2025-08-10 19:25:08 codetalker.py line 151]=>INFO: epoch [23/200] batch [310/314] time 0.039 (0.035) data 0.007 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:32:50
[2025-08-10 19:25:08 codetalker.py line 161]=>INFO: epoch: 23 loss_train: 0.0015915366591126392 pp_train: 11.680546793968055 
[2025-08-10 19:25:08 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:25:08 codetalker.py line 234]=>INFO: epoch: 23 loss_val: 0.0014357375504914672 pp_val: 1.0 
[2025-08-10 19:25:10 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:25:11 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-23
[2025-08-10 19:25:11 codetalker.py line 151]=>INFO: epoch [24/200] batch [5/314] time 0.043 (0.045) data 0.004 (0.002) loss 0.0017 lr 5.0000e-05 eta 0:41:57
[2025-08-10 19:25:11 codetalker.py line 151]=>INFO: epoch [24/200] batch [10/314] time 0.040 (0.043) data 0.000 (0.002) loss 0.0018 lr 5.0000e-05 eta 0:40:03
[2025-08-10 19:25:12 codetalker.py line 151]=>INFO: epoch [24/200] batch [15/314] time 0.036 (0.042) data 0.002 (0.002) loss 0.0017 lr 5.0000e-05 eta 0:38:59
[2025-08-10 19:25:12 codetalker.py line 151]=>INFO: epoch [24/200] batch [20/314] time 0.035 (0.041) data 0.003 (0.002) loss 0.0017 lr 5.0000e-05 eta 0:38:00
[2025-08-10 19:25:12 codetalker.py line 151]=>INFO: epoch [24/200] batch [25/314] time 0.045 (0.041) data 0.002 (0.002) loss 0.0018 lr 5.0000e-05 eta 0:37:55
[2025-08-10 19:25:12 codetalker.py line 151]=>INFO: epoch [24/200] batch [30/314] time 0.047 (0.041) data 0.002 (0.002) loss 0.0019 lr 5.0000e-05 eta 0:37:33
[2025-08-10 19:25:12 codetalker.py line 151]=>INFO: epoch [24/200] batch [35/314] time 0.036 (0.040) data 0.000 (0.002) loss 0.0018 lr 5.0000e-05 eta 0:37:19
[2025-08-10 19:25:13 codetalker.py line 151]=>INFO: epoch [24/200] batch [40/314] time 0.044 (0.040) data 0.003 (0.002) loss 0.0018 lr 5.0000e-05 eta 0:37:14
[2025-08-10 19:25:13 codetalker.py line 151]=>INFO: epoch [24/200] batch [45/314] time 0.036 (0.040) data 0.004 (0.002) loss 0.0019 lr 5.0000e-05 eta 0:37:11
[2025-08-10 19:25:13 codetalker.py line 151]=>INFO: epoch [24/200] batch [50/314] time 0.037 (0.040) data 0.002 (0.002) loss 0.0019 lr 5.0000e-05 eta 0:36:54
[2025-08-10 19:25:13 codetalker.py line 151]=>INFO: epoch [24/200] batch [55/314] time 0.039 (0.040) data 0.004 (0.002) loss 0.0018 lr 5.0000e-05 eta 0:36:50
[2025-08-10 19:25:13 codetalker.py line 151]=>INFO: epoch [24/200] batch [60/314] time 0.038 (0.040) data 0.002 (0.002) loss 0.0018 lr 5.0000e-05 eta 0:36:48
[2025-08-10 19:25:14 codetalker.py line 151]=>INFO: epoch [24/200] batch [65/314] time 0.037 (0.040) data 0.005 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:36:55
[2025-08-10 19:25:14 codetalker.py line 151]=>INFO: epoch [24/200] batch [70/314] time 0.039 (0.040) data 0.006 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:36:53
[2025-08-10 19:25:14 codetalker.py line 151]=>INFO: epoch [24/200] batch [75/314] time 0.033 (0.040) data 0.002 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:36:56
[2025-08-10 19:25:14 codetalker.py line 151]=>INFO: epoch [24/200] batch [80/314] time 0.038 (0.040) data 0.004 (0.003) loss 0.0019 lr 5.0000e-05 eta 0:37:07
[2025-08-10 19:25:15 codetalker.py line 151]=>INFO: epoch [24/200] batch [85/314] time 0.044 (0.040) data 0.000 (0.003) loss 0.0019 lr 5.0000e-05 eta 0:37:01
[2025-08-10 19:25:15 codetalker.py line 151]=>INFO: epoch [24/200] batch [90/314] time 0.044 (0.040) data 0.003 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:36:56
[2025-08-10 19:25:15 codetalker.py line 151]=>INFO: epoch [24/200] batch [95/314] time 0.036 (0.040) data 0.005 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:36:49
[2025-08-10 19:25:15 codetalker.py line 151]=>INFO: epoch [24/200] batch [100/314] time 0.037 (0.040) data 0.005 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:36:42
[2025-08-10 19:25:15 codetalker.py line 151]=>INFO: epoch [24/200] batch [105/314] time 0.035 (0.039) data 0.005 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:36:26
[2025-08-10 19:25:15 codetalker.py line 151]=>INFO: epoch [24/200] batch [110/314] time 0.036 (0.039) data 0.003 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:36:14
[2025-08-10 19:25:16 codetalker.py line 151]=>INFO: epoch [24/200] batch [115/314] time 0.033 (0.039) data 0.002 (0.003) loss 0.0017 lr 5.0000e-05 eta 0:35:59
[2025-08-10 19:25:16 codetalker.py line 151]=>INFO: epoch [24/200] batch [120/314] time 0.034 (0.039) data 0.004 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:35:47
[2025-08-10 19:25:16 codetalker.py line 151]=>INFO: epoch [24/200] batch [125/314] time 0.033 (0.039) data 0.003 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:35:38
[2025-08-10 19:25:16 codetalker.py line 151]=>INFO: epoch [24/200] batch [130/314] time 0.035 (0.038) data 0.003 (0.003) loss 0.0019 lr 5.0000e-05 eta 0:35:30
[2025-08-10 19:25:16 codetalker.py line 151]=>INFO: epoch [24/200] batch [135/314] time 0.037 (0.038) data 0.004 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:35:20
[2025-08-10 19:25:17 codetalker.py line 151]=>INFO: epoch [24/200] batch [140/314] time 0.029 (0.038) data 0.003 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:35:13
[2025-08-10 19:25:17 codetalker.py line 151]=>INFO: epoch [24/200] batch [145/314] time 0.035 (0.038) data 0.005 (0.003) loss 0.0019 lr 5.0000e-05 eta 0:35:04
[2025-08-10 19:25:17 codetalker.py line 151]=>INFO: epoch [24/200] batch [150/314] time 0.032 (0.038) data 0.003 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:34:54
[2025-08-10 19:25:17 codetalker.py line 151]=>INFO: epoch [24/200] batch [155/314] time 0.036 (0.038) data 0.005 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:34:47
[2025-08-10 19:25:17 codetalker.py line 151]=>INFO: epoch [24/200] batch [160/314] time 0.033 (0.038) data 0.000 (0.003) loss 0.0019 lr 5.0000e-05 eta 0:34:42
[2025-08-10 19:25:17 codetalker.py line 151]=>INFO: epoch [24/200] batch [165/314] time 0.034 (0.037) data 0.005 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:34:33
[2025-08-10 19:25:18 codetalker.py line 151]=>INFO: epoch [24/200] batch [170/314] time 0.034 (0.037) data 0.002 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:34:27
[2025-08-10 19:25:18 codetalker.py line 151]=>INFO: epoch [24/200] batch [175/314] time 0.033 (0.037) data 0.002 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:34:20
[2025-08-10 19:25:18 codetalker.py line 151]=>INFO: epoch [24/200] batch [180/314] time 0.032 (0.037) data 0.005 (0.003) loss 0.0019 lr 5.0000e-05 eta 0:34:16
[2025-08-10 19:25:18 codetalker.py line 151]=>INFO: epoch [24/200] batch [185/314] time 0.033 (0.037) data 0.002 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:34:12
[2025-08-10 19:25:18 codetalker.py line 151]=>INFO: epoch [24/200] batch [190/314] time 0.032 (0.037) data 0.002 (0.003) loss 0.0018 lr 5.0000e-05 eta 0:34:07
[2025-08-10 19:25:18 codetalker.py line 151]=>INFO: epoch [24/200] batch [195/314] time 0.032 (0.037) data 0.003 (0.003) loss 0.0019 lr 5.0000e-05 eta 0:34:01
[2025-08-10 19:25:19 codetalker.py line 151]=>INFO: epoch [24/200] batch [200/314] time 0.031 (0.037) data 0.001 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:33:56
[2025-08-10 19:25:19 codetalker.py line 151]=>INFO: epoch [24/200] batch [205/314] time 0.036 (0.037) data 0.002 (0.003) loss 0.0019 lr 5.0000e-05 eta 0:33:52
[2025-08-10 19:25:19 codetalker.py line 151]=>INFO: epoch [24/200] batch [210/314] time 0.035 (0.037) data 0.003 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:33:51
[2025-08-10 19:25:19 codetalker.py line 151]=>INFO: epoch [24/200] batch [215/314] time 0.033 (0.037) data 0.002 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:33:48
[2025-08-10 19:25:19 codetalker.py line 151]=>INFO: epoch [24/200] batch [220/314] time 0.031 (0.037) data 0.002 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:33:44
[2025-08-10 19:25:20 codetalker.py line 151]=>INFO: epoch [24/200] batch [225/314] time 0.034 (0.036) data 0.002 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:33:39
[2025-08-10 19:25:20 codetalker.py line 151]=>INFO: epoch [24/200] batch [230/314] time 0.034 (0.036) data 0.005 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:33:36
[2025-08-10 19:25:20 codetalker.py line 151]=>INFO: epoch [24/200] batch [235/314] time 0.030 (0.036) data 0.002 (0.003) loss 0.0019 lr 5.0000e-05 eta 0:33:31
[2025-08-10 19:25:20 codetalker.py line 151]=>INFO: epoch [24/200] batch [240/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0019 lr 5.0000e-05 eta 0:33:28
[2025-08-10 19:25:20 codetalker.py line 151]=>INFO: epoch [24/200] batch [245/314] time 0.029 (0.036) data 0.003 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:33:22
[2025-08-10 19:25:20 codetalker.py line 151]=>INFO: epoch [24/200] batch [250/314] time 0.031 (0.036) data 0.002 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:33:17
[2025-08-10 19:25:21 codetalker.py line 151]=>INFO: epoch [24/200] batch [255/314] time 0.033 (0.036) data 0.002 (0.003) loss 0.0020 lr 5.0000e-05 eta 0:33:13
[2025-08-10 19:25:21 codetalker.py line 151]=>INFO: epoch [24/200] batch [260/314] time 0.036 (0.036) data 0.002 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:33:10
[2025-08-10 19:25:21 codetalker.py line 151]=>INFO: epoch [24/200] batch [265/314] time 0.036 (0.036) data 0.005 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:33:08
[2025-08-10 19:25:21 codetalker.py line 151]=>INFO: epoch [24/200] batch [270/314] time 0.037 (0.036) data 0.004 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:33:06
[2025-08-10 19:25:21 codetalker.py line 151]=>INFO: epoch [24/200] batch [275/314] time 0.032 (0.036) data 0.003 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:33:02
[2025-08-10 19:25:21 codetalker.py line 151]=>INFO: epoch [24/200] batch [280/314] time 0.033 (0.036) data 0.002 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:32:59
[2025-08-10 19:25:22 codetalker.py line 151]=>INFO: epoch [24/200] batch [285/314] time 0.035 (0.036) data 0.000 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:32:56
[2025-08-10 19:25:22 codetalker.py line 151]=>INFO: epoch [24/200] batch [290/314] time 0.044 (0.036) data 0.003 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:32:57
[2025-08-10 19:25:22 codetalker.py line 151]=>INFO: epoch [24/200] batch [295/314] time 0.031 (0.036) data 0.002 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:32:54
[2025-08-10 19:25:22 codetalker.py line 151]=>INFO: epoch [24/200] batch [300/314] time 0.033 (0.036) data 0.002 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:32:53
[2025-08-10 19:25:22 codetalker.py line 151]=>INFO: epoch [24/200] batch [305/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:32:51
[2025-08-10 19:25:23 codetalker.py line 151]=>INFO: epoch [24/200] batch [310/314] time 0.030 (0.036) data 0.001 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:32:47
[2025-08-10 19:25:23 codetalker.py line 161]=>INFO: epoch: 24 loss_train: 0.0019191926783454977 pp_train: 11.67456977990023 
[2025-08-10 19:25:23 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:25:23 codetalker.py line 234]=>INFO: epoch: 24 loss_val: 0.0018622632924234495 pp_val: 1.0 
[2025-08-10 19:25:25 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:25:26 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-24
[2025-08-10 19:25:26 codetalker.py line 151]=>INFO: epoch [25/200] batch [5/314] time 0.036 (0.050) data 0.003 (0.004) loss 0.0021 lr 5.0000e-05 eta 0:46:16
[2025-08-10 19:25:27 codetalker.py line 151]=>INFO: epoch [25/200] batch [10/314] time 0.034 (0.044) data 0.000 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:40:21
[2025-08-10 19:25:27 codetalker.py line 151]=>INFO: epoch [25/200] batch [15/314] time 0.039 (0.041) data 0.003 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:38:01
[2025-08-10 19:25:27 codetalker.py line 151]=>INFO: epoch [25/200] batch [20/314] time 0.033 (0.040) data 0.002 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:36:40
[2025-08-10 19:25:27 codetalker.py line 151]=>INFO: epoch [25/200] batch [25/314] time 0.031 (0.039) data 0.003 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:35:36
[2025-08-10 19:25:27 codetalker.py line 151]=>INFO: epoch [25/200] batch [30/314] time 0.033 (0.038) data 0.000 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:34:42
[2025-08-10 19:25:27 codetalker.py line 151]=>INFO: epoch [25/200] batch [35/314] time 0.032 (0.037) data 0.002 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:34:01
[2025-08-10 19:25:28 codetalker.py line 151]=>INFO: epoch [25/200] batch [40/314] time 0.034 (0.036) data 0.006 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:33:30
[2025-08-10 19:25:28 codetalker.py line 151]=>INFO: epoch [25/200] batch [45/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:33:08
[2025-08-10 19:25:28 codetalker.py line 151]=>INFO: epoch [25/200] batch [50/314] time 0.031 (0.036) data 0.002 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:32:55
[2025-08-10 19:25:28 codetalker.py line 151]=>INFO: epoch [25/200] batch [55/314] time 0.033 (0.036) data 0.000 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:32:49
[2025-08-10 19:25:28 codetalker.py line 151]=>INFO: epoch [25/200] batch [60/314] time 0.036 (0.036) data 0.007 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:32:40
[2025-08-10 19:25:28 codetalker.py line 151]=>INFO: epoch [25/200] batch [65/314] time 0.035 (0.035) data 0.003 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:32:30
[2025-08-10 19:25:29 codetalker.py line 151]=>INFO: epoch [25/200] batch [70/314] time 0.029 (0.035) data 0.000 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:32:27
[2025-08-10 19:25:29 codetalker.py line 151]=>INFO: epoch [25/200] batch [75/314] time 0.036 (0.035) data 0.002 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:32:23
[2025-08-10 19:25:29 codetalker.py line 151]=>INFO: epoch [25/200] batch [80/314] time 0.035 (0.035) data 0.002 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:32:18
[2025-08-10 19:25:29 codetalker.py line 151]=>INFO: epoch [25/200] batch [85/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0021 lr 5.0000e-05 eta 0:32:13
[2025-08-10 19:25:29 codetalker.py line 151]=>INFO: epoch [25/200] batch [90/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:32:13
[2025-08-10 19:25:30 codetalker.py line 151]=>INFO: epoch [25/200] batch [95/314] time 0.038 (0.035) data 0.005 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:32:09
[2025-08-10 19:25:30 codetalker.py line 151]=>INFO: epoch [25/200] batch [100/314] time 0.033 (0.035) data 0.002 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:32:07
[2025-08-10 19:25:30 codetalker.py line 151]=>INFO: epoch [25/200] batch [105/314] time 0.029 (0.035) data 0.002 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:32:01
[2025-08-10 19:25:30 codetalker.py line 151]=>INFO: epoch [25/200] batch [110/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:31:58
[2025-08-10 19:25:30 codetalker.py line 151]=>INFO: epoch [25/200] batch [115/314] time 0.032 (0.035) data 0.001 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:31:53
[2025-08-10 19:25:30 codetalker.py line 151]=>INFO: epoch [25/200] batch [120/314] time 0.034 (0.035) data 0.006 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:50
[2025-08-10 19:25:31 codetalker.py line 151]=>INFO: epoch [25/200] batch [125/314] time 0.033 (0.035) data 0.000 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:43
[2025-08-10 19:25:31 codetalker.py line 151]=>INFO: epoch [25/200] batch [130/314] time 0.035 (0.034) data 0.000 (0.003) loss 0.0022 lr 5.0000e-05 eta 0:31:41
[2025-08-10 19:25:31 codetalker.py line 151]=>INFO: epoch [25/200] batch [135/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:38
[2025-08-10 19:25:31 codetalker.py line 151]=>INFO: epoch [25/200] batch [140/314] time 0.028 (0.034) data 0.002 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:31:34
[2025-08-10 19:25:31 codetalker.py line 151]=>INFO: epoch [25/200] batch [145/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:31
[2025-08-10 19:25:31 codetalker.py line 151]=>INFO: epoch [25/200] batch [150/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:31:29
[2025-08-10 19:25:32 codetalker.py line 151]=>INFO: epoch [25/200] batch [155/314] time 0.029 (0.034) data 0.003 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:28
[2025-08-10 19:25:32 codetalker.py line 151]=>INFO: epoch [25/200] batch [160/314] time 0.038 (0.034) data 0.005 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:31:27
[2025-08-10 19:25:32 codetalker.py line 151]=>INFO: epoch [25/200] batch [165/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:22
[2025-08-10 19:25:32 codetalker.py line 151]=>INFO: epoch [25/200] batch [170/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:23
[2025-08-10 19:25:32 codetalker.py line 151]=>INFO: epoch [25/200] batch [175/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:31:22
[2025-08-10 19:25:32 codetalker.py line 151]=>INFO: epoch [25/200] batch [180/314] time 0.034 (0.034) data 0.003 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:31:20
[2025-08-10 19:25:33 codetalker.py line 151]=>INFO: epoch [25/200] batch [185/314] time 0.035 (0.034) data 0.004 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:19
[2025-08-10 19:25:33 codetalker.py line 151]=>INFO: epoch [25/200] batch [190/314] time 0.031 (0.034) data 0.001 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:18
[2025-08-10 19:25:33 codetalker.py line 151]=>INFO: epoch [25/200] batch [195/314] time 0.033 (0.034) data 0.000 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:15
[2025-08-10 19:25:33 codetalker.py line 151]=>INFO: epoch [25/200] batch [200/314] time 0.034 (0.034) data 0.000 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:14
[2025-08-10 19:25:33 codetalker.py line 151]=>INFO: epoch [25/200] batch [205/314] time 0.031 (0.034) data 0.000 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:10
[2025-08-10 19:25:34 codetalker.py line 151]=>INFO: epoch [25/200] batch [210/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0025 lr 5.0000e-05 eta 0:31:08
[2025-08-10 19:25:34 codetalker.py line 151]=>INFO: epoch [25/200] batch [215/314] time 0.031 (0.034) data 0.001 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:31:06
[2025-08-10 19:25:34 codetalker.py line 151]=>INFO: epoch [25/200] batch [220/314] time 0.030 (0.034) data 0.000 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:31:04
[2025-08-10 19:25:34 codetalker.py line 151]=>INFO: epoch [25/200] batch [225/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:31:02
[2025-08-10 19:25:34 codetalker.py line 151]=>INFO: epoch [25/200] batch [230/314] time 0.038 (0.034) data 0.006 (0.003) loss 0.0025 lr 5.0000e-05 eta 0:31:00
[2025-08-10 19:25:34 codetalker.py line 151]=>INFO: epoch [25/200] batch [235/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:30:59
[2025-08-10 19:25:35 codetalker.py line 151]=>INFO: epoch [25/200] batch [240/314] time 0.038 (0.034) data 0.005 (0.003) loss 0.0025 lr 5.0000e-05 eta 0:31:01
[2025-08-10 19:25:35 codetalker.py line 151]=>INFO: epoch [25/200] batch [245/314] time 0.033 (0.034) data 0.000 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:31:00
[2025-08-10 19:25:35 codetalker.py line 151]=>INFO: epoch [25/200] batch [250/314] time 0.033 (0.034) data 0.000 (0.003) loss 0.0023 lr 5.0000e-05 eta 0:30:58
[2025-08-10 19:25:35 codetalker.py line 151]=>INFO: epoch [25/200] batch [255/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0025 lr 5.0000e-05 eta 0:30:59
[2025-08-10 19:25:35 codetalker.py line 151]=>INFO: epoch [25/200] batch [260/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:30:58
[2025-08-10 19:25:35 codetalker.py line 151]=>INFO: epoch [25/200] batch [265/314] time 0.034 (0.034) data 0.003 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:30:57
[2025-08-10 19:25:36 codetalker.py line 151]=>INFO: epoch [25/200] batch [270/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:30:55
[2025-08-10 19:25:36 codetalker.py line 151]=>INFO: epoch [25/200] batch [275/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:30:55
[2025-08-10 19:25:36 codetalker.py line 151]=>INFO: epoch [25/200] batch [280/314] time 0.034 (0.034) data 0.004 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:30:54
[2025-08-10 19:25:36 codetalker.py line 151]=>INFO: epoch [25/200] batch [285/314] time 0.035 (0.034) data 0.005 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:30:55
[2025-08-10 19:25:36 codetalker.py line 151]=>INFO: epoch [25/200] batch [290/314] time 0.034 (0.034) data 0.005 (0.003) loss 0.0025 lr 5.0000e-05 eta 0:30:54
[2025-08-10 19:25:36 codetalker.py line 151]=>INFO: epoch [25/200] batch [295/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0024 lr 5.0000e-05 eta 0:30:53
[2025-08-10 19:25:37 codetalker.py line 151]=>INFO: epoch [25/200] batch [300/314] time 0.031 (0.034) data 0.001 (0.003) loss 0.0025 lr 5.0000e-05 eta 0:30:51
[2025-08-10 19:25:37 codetalker.py line 151]=>INFO: epoch [25/200] batch [305/314] time 0.034 (0.034) data 0.003 (0.003) loss 0.0025 lr 5.0000e-05 eta 0:30:50
[2025-08-10 19:25:37 codetalker.py line 151]=>INFO: epoch [25/200] batch [310/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:30:50
[2025-08-10 19:25:37 codetalker.py line 161]=>INFO: epoch: 25 loss_train: 0.00231575393963273 pp_train: 11.672690437098218 
[2025-08-10 19:25:37 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:25:37 codetalker.py line 234]=>INFO: epoch: 25 loss_val: 0.0024499148363247513 pp_val: 1.0 
[2025-08-10 19:25:39 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:25:40 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-25
[2025-08-10 19:25:41 codetalker.py line 151]=>INFO: epoch [26/200] batch [5/314] time 0.034 (0.049) data 0.004 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:44:35
[2025-08-10 19:25:41 codetalker.py line 151]=>INFO: epoch [26/200] batch [10/314] time 0.051 (0.050) data 0.005 (0.004) loss 0.0025 lr 5.0000e-05 eta 0:45:26
[2025-08-10 19:25:41 codetalker.py line 151]=>INFO: epoch [26/200] batch [15/314] time 0.042 (0.046) data 0.002 (0.003) loss 0.0025 lr 5.0000e-05 eta 0:42:33
[2025-08-10 19:25:41 codetalker.py line 151]=>INFO: epoch [26/200] batch [20/314] time 0.058 (0.047) data 0.004 (0.003) loss 0.0027 lr 5.0000e-05 eta 0:43:03
[2025-08-10 19:25:42 codetalker.py line 151]=>INFO: epoch [26/200] batch [25/314] time 0.052 (0.047) data 0.007 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:43:15
[2025-08-10 19:25:42 codetalker.py line 151]=>INFO: epoch [26/200] batch [30/314] time 0.040 (0.047) data 0.005 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:42:39
[2025-08-10 19:25:42 codetalker.py line 151]=>INFO: epoch [26/200] batch [35/314] time 0.052 (0.046) data 0.002 (0.003) loss 0.0025 lr 5.0000e-05 eta 0:42:26
[2025-08-10 19:25:42 codetalker.py line 151]=>INFO: epoch [26/200] batch [40/314] time 0.056 (0.047) data 0.003 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:42:34
[2025-08-10 19:25:43 codetalker.py line 151]=>INFO: epoch [26/200] batch [45/314] time 0.044 (0.047) data 0.003 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:42:44
[2025-08-10 19:25:43 codetalker.py line 151]=>INFO: epoch [26/200] batch [50/314] time 0.032 (0.046) data 0.003 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:42:07
[2025-08-10 19:25:43 codetalker.py line 151]=>INFO: epoch [26/200] batch [55/314] time 0.034 (0.045) data 0.003 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:41:08
[2025-08-10 19:25:43 codetalker.py line 151]=>INFO: epoch [26/200] batch [60/314] time 0.034 (0.044) data 0.004 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:40:18
[2025-08-10 19:25:43 codetalker.py line 151]=>INFO: epoch [26/200] batch [65/314] time 0.034 (0.043) data 0.000 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:39:30
[2025-08-10 19:25:43 codetalker.py line 151]=>INFO: epoch [26/200] batch [70/314] time 0.034 (0.043) data 0.003 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:39:03
[2025-08-10 19:25:44 codetalker.py line 151]=>INFO: epoch [26/200] batch [75/314] time 0.033 (0.042) data 0.002 (0.003) loss 0.0027 lr 5.0000e-05 eta 0:38:28
[2025-08-10 19:25:44 codetalker.py line 151]=>INFO: epoch [26/200] batch [80/314] time 0.035 (0.042) data 0.004 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:37:57
[2025-08-10 19:25:44 codetalker.py line 151]=>INFO: epoch [26/200] batch [85/314] time 0.031 (0.041) data 0.000 (0.003) loss 0.0027 lr 5.0000e-05 eta 0:37:30
[2025-08-10 19:25:44 codetalker.py line 151]=>INFO: epoch [26/200] batch [90/314] time 0.033 (0.041) data 0.003 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:37:12
[2025-08-10 19:25:44 codetalker.py line 151]=>INFO: epoch [26/200] batch [95/314] time 0.033 (0.040) data 0.005 (0.003) loss 0.0026 lr 5.0000e-05 eta 0:36:55
[2025-08-10 19:25:45 codetalker.py line 151]=>INFO: epoch [26/200] batch [100/314] time 0.035 (0.040) data 0.005 (0.003) loss 0.0027 lr 5.0000e-05 eta 0:36:37
[2025-08-10 19:25:45 codetalker.py line 151]=>INFO: epoch [26/200] batch [105/314] time 0.033 (0.040) data 0.002 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:36:20
[2025-08-10 19:25:45 codetalker.py line 151]=>INFO: epoch [26/200] batch [110/314] time 0.037 (0.040) data 0.003 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:36:06
[2025-08-10 19:25:45 codetalker.py line 151]=>INFO: epoch [26/200] batch [115/314] time 0.035 (0.039) data 0.005 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:35:55
[2025-08-10 19:25:45 codetalker.py line 151]=>INFO: epoch [26/200] batch [120/314] time 0.033 (0.039) data 0.003 (0.003) loss 0.0027 lr 5.0000e-05 eta 0:35:43
[2025-08-10 19:25:45 codetalker.py line 151]=>INFO: epoch [26/200] batch [125/314] time 0.034 (0.039) data 0.002 (0.003) loss 0.0027 lr 5.0000e-05 eta 0:35:31
[2025-08-10 19:25:46 codetalker.py line 151]=>INFO: epoch [26/200] batch [130/314] time 0.033 (0.039) data 0.000 (0.003) loss 0.0027 lr 5.0000e-05 eta 0:35:18
[2025-08-10 19:25:46 codetalker.py line 151]=>INFO: epoch [26/200] batch [135/314] time 0.035 (0.038) data 0.005 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:35:07
[2025-08-10 19:25:46 codetalker.py line 151]=>INFO: epoch [26/200] batch [140/314] time 0.034 (0.038) data 0.003 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:35:01
[2025-08-10 19:25:46 codetalker.py line 151]=>INFO: epoch [26/200] batch [145/314] time 0.034 (0.038) data 0.004 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:34:54
[2025-08-10 19:25:46 codetalker.py line 151]=>INFO: epoch [26/200] batch [150/314] time 0.041 (0.038) data 0.007 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:34:51
[2025-08-10 19:25:47 codetalker.py line 151]=>INFO: epoch [26/200] batch [155/314] time 0.035 (0.038) data 0.002 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:34:44
[2025-08-10 19:25:47 codetalker.py line 151]=>INFO: epoch [26/200] batch [160/314] time 0.032 (0.038) data 0.002 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:34:37
[2025-08-10 19:25:47 codetalker.py line 151]=>INFO: epoch [26/200] batch [165/314] time 0.034 (0.038) data 0.002 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:34:30
[2025-08-10 19:25:47 codetalker.py line 151]=>INFO: epoch [26/200] batch [170/314] time 0.033 (0.038) data 0.003 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:34:22
[2025-08-10 19:25:47 codetalker.py line 151]=>INFO: epoch [26/200] batch [175/314] time 0.036 (0.038) data 0.003 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:34:15
[2025-08-10 19:25:47 codetalker.py line 151]=>INFO: epoch [26/200] batch [180/314] time 0.034 (0.037) data 0.002 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:34:10
[2025-08-10 19:25:48 codetalker.py line 151]=>INFO: epoch [26/200] batch [185/314] time 0.033 (0.037) data 0.003 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:34:06
[2025-08-10 19:25:48 codetalker.py line 151]=>INFO: epoch [26/200] batch [190/314] time 0.032 (0.037) data 0.004 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:34:00
[2025-08-10 19:25:48 codetalker.py line 151]=>INFO: epoch [26/200] batch [195/314] time 0.032 (0.037) data 0.003 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:33:56
[2025-08-10 19:25:48 codetalker.py line 151]=>INFO: epoch [26/200] batch [200/314] time 0.034 (0.037) data 0.006 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:33:53
[2025-08-10 19:25:48 codetalker.py line 151]=>INFO: epoch [26/200] batch [205/314] time 0.027 (0.037) data 0.002 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:33:46
[2025-08-10 19:25:48 codetalker.py line 151]=>INFO: epoch [26/200] batch [210/314] time 0.032 (0.037) data 0.000 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:33:43
[2025-08-10 19:25:49 codetalker.py line 151]=>INFO: epoch [26/200] batch [215/314] time 0.034 (0.037) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:33:42
[2025-08-10 19:25:49 codetalker.py line 151]=>INFO: epoch [26/200] batch [220/314] time 0.034 (0.037) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:33:38
[2025-08-10 19:25:49 codetalker.py line 151]=>INFO: epoch [26/200] batch [225/314] time 0.040 (0.037) data 0.005 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:33:34
[2025-08-10 19:25:49 codetalker.py line 151]=>INFO: epoch [26/200] batch [230/314] time 0.035 (0.037) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:33:31
[2025-08-10 19:25:49 codetalker.py line 151]=>INFO: epoch [26/200] batch [235/314] time 0.033 (0.037) data 0.003 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:33:27
[2025-08-10 19:25:50 codetalker.py line 151]=>INFO: epoch [26/200] batch [240/314] time 0.034 (0.037) data 0.005 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:33:24
[2025-08-10 19:25:50 codetalker.py line 151]=>INFO: epoch [26/200] batch [245/314] time 0.033 (0.037) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:33:21
[2025-08-10 19:25:50 codetalker.py line 151]=>INFO: epoch [26/200] batch [250/314] time 0.039 (0.037) data 0.005 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:33:20
[2025-08-10 19:25:50 codetalker.py line 151]=>INFO: epoch [26/200] batch [255/314] time 0.034 (0.037) data 0.001 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:33:17
[2025-08-10 19:25:50 codetalker.py line 151]=>INFO: epoch [26/200] batch [260/314] time 0.034 (0.036) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:33:14
[2025-08-10 19:25:50 codetalker.py line 151]=>INFO: epoch [26/200] batch [265/314] time 0.032 (0.036) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:33:13
[2025-08-10 19:25:51 codetalker.py line 151]=>INFO: epoch [26/200] batch [270/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:33:10
[2025-08-10 19:25:51 codetalker.py line 151]=>INFO: epoch [26/200] batch [275/314] time 0.038 (0.036) data 0.006 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:33:08
[2025-08-10 19:25:51 codetalker.py line 151]=>INFO: epoch [26/200] batch [280/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:33:06
[2025-08-10 19:25:51 codetalker.py line 151]=>INFO: epoch [26/200] batch [285/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:33:04
[2025-08-10 19:25:51 codetalker.py line 151]=>INFO: epoch [26/200] batch [290/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:33:02
[2025-08-10 19:25:51 codetalker.py line 151]=>INFO: epoch [26/200] batch [295/314] time 0.032 (0.036) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:32:59
[2025-08-10 19:25:52 codetalker.py line 151]=>INFO: epoch [26/200] batch [300/314] time 0.029 (0.036) data 0.003 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:32:55
[2025-08-10 19:25:52 codetalker.py line 151]=>INFO: epoch [26/200] batch [305/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:32:51
[2025-08-10 19:25:52 codetalker.py line 151]=>INFO: epoch [26/200] batch [310/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:32:49
[2025-08-10 19:25:52 codetalker.py line 161]=>INFO: epoch: 26 loss_train: 0.002795037323353919 pp_train: 11.682064001727255 
[2025-08-10 19:25:52 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:25:53 codetalker.py line 234]=>INFO: epoch: 26 loss_val: 0.0028559444181155413 pp_val: 1.0 
[2025-08-10 19:25:54 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:25:56 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-26
[2025-08-10 19:25:56 codetalker.py line 151]=>INFO: epoch [27/200] batch [5/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:46
[2025-08-10 19:25:56 codetalker.py line 151]=>INFO: epoch [27/200] batch [10/314] time 0.041 (0.037) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:33:44
[2025-08-10 19:25:56 codetalker.py line 151]=>INFO: epoch [27/200] batch [15/314] time 0.040 (0.038) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:34:26
[2025-08-10 19:25:56 codetalker.py line 151]=>INFO: epoch [27/200] batch [20/314] time 0.039 (0.038) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:34:26
[2025-08-10 19:25:57 codetalker.py line 151]=>INFO: epoch [27/200] batch [25/314] time 0.044 (0.038) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:34:47
[2025-08-10 19:25:57 codetalker.py line 151]=>INFO: epoch [27/200] batch [30/314] time 0.036 (0.038) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:34:33
[2025-08-10 19:25:57 codetalker.py line 151]=>INFO: epoch [27/200] batch [35/314] time 0.041 (0.038) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:34:27
[2025-08-10 19:25:57 codetalker.py line 151]=>INFO: epoch [27/200] batch [40/314] time 0.038 (0.038) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:34:22
[2025-08-10 19:25:57 codetalker.py line 151]=>INFO: epoch [27/200] batch [45/314] time 0.036 (0.038) data 0.006 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:34:20
[2025-08-10 19:25:58 codetalker.py line 151]=>INFO: epoch [27/200] batch [50/314] time 0.033 (0.038) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:34:13
[2025-08-10 19:25:58 codetalker.py line 151]=>INFO: epoch [27/200] batch [55/314] time 0.037 (0.038) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:34:14
[2025-08-10 19:25:58 codetalker.py line 151]=>INFO: epoch [27/200] batch [60/314] time 0.033 (0.038) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:34:20
[2025-08-10 19:25:58 codetalker.py line 151]=>INFO: epoch [27/200] batch [65/314] time 0.036 (0.038) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:34:10
[2025-08-10 19:25:58 codetalker.py line 151]=>INFO: epoch [27/200] batch [70/314] time 0.040 (0.038) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:34:08
[2025-08-10 19:25:59 codetalker.py line 151]=>INFO: epoch [27/200] batch [75/314] time 0.030 (0.037) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:33:48
[2025-08-10 19:25:59 codetalker.py line 151]=>INFO: epoch [27/200] batch [80/314] time 0.034 (0.037) data 0.005 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:33:36
[2025-08-10 19:25:59 codetalker.py line 151]=>INFO: epoch [27/200] batch [85/314] time 0.038 (0.037) data 0.006 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:33:29
[2025-08-10 19:25:59 codetalker.py line 151]=>INFO: epoch [27/200] batch [90/314] time 0.034 (0.037) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:33:22
[2025-08-10 19:25:59 codetalker.py line 151]=>INFO: epoch [27/200] batch [95/314] time 0.034 (0.037) data 0.003 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:33:14
[2025-08-10 19:25:59 codetalker.py line 151]=>INFO: epoch [27/200] batch [100/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:33:05
[2025-08-10 19:26:00 codetalker.py line 151]=>INFO: epoch [27/200] batch [105/314] time 0.031 (0.036) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:33:00
[2025-08-10 19:26:00 codetalker.py line 151]=>INFO: epoch [27/200] batch [110/314] time 0.031 (0.036) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:32:48
[2025-08-10 19:26:00 codetalker.py line 151]=>INFO: epoch [27/200] batch [115/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:32:42
[2025-08-10 19:26:00 codetalker.py line 151]=>INFO: epoch [27/200] batch [120/314] time 0.039 (0.036) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:32:37
[2025-08-10 19:26:00 codetalker.py line 151]=>INFO: epoch [27/200] batch [125/314] time 0.042 (0.036) data 0.006 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:35
[2025-08-10 19:26:00 codetalker.py line 151]=>INFO: epoch [27/200] batch [130/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:32:32
[2025-08-10 19:26:01 codetalker.py line 151]=>INFO: epoch [27/200] batch [135/314] time 0.032 (0.036) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:32:27
[2025-08-10 19:26:01 codetalker.py line 151]=>INFO: epoch [27/200] batch [140/314] time 0.031 (0.036) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:32:23
[2025-08-10 19:26:01 codetalker.py line 151]=>INFO: epoch [27/200] batch [145/314] time 0.041 (0.036) data 0.008 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:32:20
[2025-08-10 19:26:01 codetalker.py line 151]=>INFO: epoch [27/200] batch [150/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:17
[2025-08-10 19:26:01 codetalker.py line 151]=>INFO: epoch [27/200] batch [155/314] time 0.033 (0.035) data 0.001 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:32:12
[2025-08-10 19:26:02 codetalker.py line 151]=>INFO: epoch [27/200] batch [160/314] time 0.034 (0.035) data 0.005 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:08
[2025-08-10 19:26:02 codetalker.py line 151]=>INFO: epoch [27/200] batch [165/314] time 0.039 (0.035) data 0.004 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:10
[2025-08-10 19:26:02 codetalker.py line 151]=>INFO: epoch [27/200] batch [170/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:32:08
[2025-08-10 19:26:02 codetalker.py line 151]=>INFO: epoch [27/200] batch [175/314] time 0.035 (0.035) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:32:06
[2025-08-10 19:26:02 codetalker.py line 151]=>INFO: epoch [27/200] batch [180/314] time 0.032 (0.035) data 0.001 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:07
[2025-08-10 19:26:02 codetalker.py line 151]=>INFO: epoch [27/200] batch [185/314] time 0.032 (0.035) data 0.000 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:04
[2025-08-10 19:26:03 codetalker.py line 151]=>INFO: epoch [27/200] batch [190/314] time 0.030 (0.035) data 0.004 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:01
[2025-08-10 19:26:03 codetalker.py line 151]=>INFO: epoch [27/200] batch [195/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:59
[2025-08-10 19:26:03 codetalker.py line 151]=>INFO: epoch [27/200] batch [200/314] time 0.039 (0.035) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:31:56
[2025-08-10 19:26:03 codetalker.py line 151]=>INFO: epoch [27/200] batch [205/314] time 0.031 (0.035) data 0.000 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:53
[2025-08-10 19:26:03 codetalker.py line 151]=>INFO: epoch [27/200] batch [210/314] time 0.033 (0.035) data 0.002 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:51
[2025-08-10 19:26:03 codetalker.py line 151]=>INFO: epoch [27/200] batch [215/314] time 0.034 (0.035) data 0.005 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:47
[2025-08-10 19:26:04 codetalker.py line 151]=>INFO: epoch [27/200] batch [220/314] time 0.037 (0.035) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:47
[2025-08-10 19:26:04 codetalker.py line 151]=>INFO: epoch [27/200] batch [225/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:45
[2025-08-10 19:26:04 codetalker.py line 151]=>INFO: epoch [27/200] batch [230/314] time 0.034 (0.035) data 0.004 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:43
[2025-08-10 19:26:04 codetalker.py line 151]=>INFO: epoch [27/200] batch [235/314] time 0.037 (0.035) data 0.007 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:43
[2025-08-10 19:26:04 codetalker.py line 151]=>INFO: epoch [27/200] batch [240/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:43
[2025-08-10 19:26:05 codetalker.py line 151]=>INFO: epoch [27/200] batch [245/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:41
[2025-08-10 19:26:05 codetalker.py line 151]=>INFO: epoch [27/200] batch [250/314] time 0.038 (0.035) data 0.003 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:40
[2025-08-10 19:26:05 codetalker.py line 151]=>INFO: epoch [27/200] batch [255/314] time 0.029 (0.035) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:38
[2025-08-10 19:26:05 codetalker.py line 151]=>INFO: epoch [27/200] batch [260/314] time 0.039 (0.035) data 0.004 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:37
[2025-08-10 19:26:05 codetalker.py line 151]=>INFO: epoch [27/200] batch [265/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:36
[2025-08-10 19:26:05 codetalker.py line 151]=>INFO: epoch [27/200] batch [270/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:35
[2025-08-10 19:26:06 codetalker.py line 151]=>INFO: epoch [27/200] batch [275/314] time 0.036 (0.035) data 0.005 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:34
[2025-08-10 19:26:06 codetalker.py line 151]=>INFO: epoch [27/200] batch [280/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:32
[2025-08-10 19:26:06 codetalker.py line 151]=>INFO: epoch [27/200] batch [285/314] time 0.034 (0.035) data 0.001 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:32
[2025-08-10 19:26:06 codetalker.py line 151]=>INFO: epoch [27/200] batch [290/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:31
[2025-08-10 19:26:06 codetalker.py line 151]=>INFO: epoch [27/200] batch [295/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:29
[2025-08-10 19:26:06 codetalker.py line 151]=>INFO: epoch [27/200] batch [300/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:31:28
[2025-08-10 19:26:07 codetalker.py line 151]=>INFO: epoch [27/200] batch [305/314] time 0.029 (0.035) data 0.000 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:27
[2025-08-10 19:26:07 codetalker.py line 151]=>INFO: epoch [27/200] batch [310/314] time 0.028 (0.035) data 0.003 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:25
[2025-08-10 19:26:07 codetalker.py line 161]=>INFO: epoch: 27 loss_train: 0.0033372960492351633 pp_train: 11.68164647764461 
[2025-08-10 19:26:07 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:26:07 codetalker.py line 234]=>INFO: epoch: 27 loss_val: 0.003459010674851015 pp_val: 1.0 
[2025-08-10 19:26:09 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:26:10 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-27
[2025-08-10 19:26:11 codetalker.py line 151]=>INFO: epoch [28/200] batch [5/314] time 0.047 (0.051) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:45:58
[2025-08-10 19:26:11 codetalker.py line 151]=>INFO: epoch [28/200] batch [10/314] time 0.032 (0.044) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:39:28
[2025-08-10 19:26:11 codetalker.py line 151]=>INFO: epoch [28/200] batch [15/314] time 0.039 (0.042) data 0.004 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:38:20
[2025-08-10 19:26:11 codetalker.py line 151]=>INFO: epoch [28/200] batch [20/314] time 0.032 (0.041) data 0.006 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:37:27
[2025-08-10 19:26:11 codetalker.py line 151]=>INFO: epoch [28/200] batch [25/314] time 0.035 (0.041) data 0.000 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:36:49
[2025-08-10 19:26:12 codetalker.py line 151]=>INFO: epoch [28/200] batch [30/314] time 0.034 (0.040) data 0.005 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:35:58
[2025-08-10 19:26:12 codetalker.py line 151]=>INFO: epoch [28/200] batch [35/314] time 0.032 (0.040) data 0.000 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:35:52
[2025-08-10 19:26:12 codetalker.py line 151]=>INFO: epoch [28/200] batch [40/314] time 0.038 (0.040) data 0.006 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:35:46
[2025-08-10 19:26:12 codetalker.py line 151]=>INFO: epoch [28/200] batch [45/314] time 0.035 (0.039) data 0.004 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:35:29
[2025-08-10 19:26:12 codetalker.py line 151]=>INFO: epoch [28/200] batch [50/314] time 0.046 (0.039) data 0.006 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:35:34
[2025-08-10 19:26:13 codetalker.py line 151]=>INFO: epoch [28/200] batch [55/314] time 0.035 (0.039) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:35:23
[2025-08-10 19:26:13 codetalker.py line 151]=>INFO: epoch [28/200] batch [60/314] time 0.047 (0.039) data 0.005 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:35:18
[2025-08-10 19:26:13 codetalker.py line 151]=>INFO: epoch [28/200] batch [65/314] time 0.040 (0.039) data 0.004 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:35:12
[2025-08-10 19:26:13 codetalker.py line 151]=>INFO: epoch [28/200] batch [70/314] time 0.036 (0.039) data 0.004 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:35:09
[2025-08-10 19:26:13 codetalker.py line 151]=>INFO: epoch [28/200] batch [75/314] time 0.041 (0.039) data 0.004 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:35:07
[2025-08-10 19:26:14 codetalker.py line 151]=>INFO: epoch [28/200] batch [80/314] time 0.033 (0.039) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:34:54
[2025-08-10 19:26:14 codetalker.py line 151]=>INFO: epoch [28/200] batch [85/314] time 0.042 (0.039) data 0.004 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:34:56
[2025-08-10 19:26:14 codetalker.py line 151]=>INFO: epoch [28/200] batch [90/314] time 0.038 (0.039) data 0.000 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:34:53
[2025-08-10 19:26:14 codetalker.py line 151]=>INFO: epoch [28/200] batch [95/314] time 0.035 (0.039) data 0.000 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:34:49
[2025-08-10 19:26:14 codetalker.py line 151]=>INFO: epoch [28/200] batch [100/314] time 0.032 (0.038) data 0.000 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:34:42
[2025-08-10 19:26:15 codetalker.py line 151]=>INFO: epoch [28/200] batch [105/314] time 0.039 (0.038) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:34:40
[2025-08-10 19:26:15 codetalker.py line 151]=>INFO: epoch [28/200] batch [110/314] time 0.036 (0.038) data 0.003 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:34:41
[2025-08-10 19:26:15 codetalker.py line 151]=>INFO: epoch [28/200] batch [115/314] time 0.046 (0.039) data 0.002 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:34:49
[2025-08-10 19:26:15 codetalker.py line 151]=>INFO: epoch [28/200] batch [120/314] time 0.038 (0.039) data 0.003 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:34:52
[2025-08-10 19:26:15 codetalker.py line 151]=>INFO: epoch [28/200] batch [125/314] time 0.036 (0.039) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:35:01
[2025-08-10 19:26:16 codetalker.py line 151]=>INFO: epoch [28/200] batch [130/314] time 0.043 (0.039) data 0.005 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:35:04
[2025-08-10 19:26:16 codetalker.py line 151]=>INFO: epoch [28/200] batch [135/314] time 0.043 (0.039) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:35:13
[2025-08-10 19:26:16 codetalker.py line 151]=>INFO: epoch [28/200] batch [140/314] time 0.046 (0.039) data 0.002 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:35:13
[2025-08-10 19:26:16 codetalker.py line 151]=>INFO: epoch [28/200] batch [145/314] time 0.044 (0.039) data 0.007 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:35:18
[2025-08-10 19:26:16 codetalker.py line 151]=>INFO: epoch [28/200] batch [150/314] time 0.043 (0.039) data 0.003 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:35:19
[2025-08-10 19:26:17 codetalker.py line 151]=>INFO: epoch [28/200] batch [155/314] time 0.047 (0.039) data 0.006 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:35:26
[2025-08-10 19:26:17 codetalker.py line 151]=>INFO: epoch [28/200] batch [160/314] time 0.044 (0.039) data 0.002 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:35:28
[2025-08-10 19:26:17 codetalker.py line 151]=>INFO: epoch [28/200] batch [165/314] time 0.042 (0.039) data 0.002 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:35:32
[2025-08-10 19:26:17 codetalker.py line 151]=>INFO: epoch [28/200] batch [170/314] time 0.041 (0.039) data 0.002 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:35:37
[2025-08-10 19:26:18 codetalker.py line 151]=>INFO: epoch [28/200] batch [175/314] time 0.029 (0.039) data 0.000 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:35:32
[2025-08-10 19:26:18 codetalker.py line 151]=>INFO: epoch [28/200] batch [180/314] time 0.044 (0.040) data 0.004 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:35:40
[2025-08-10 19:26:18 codetalker.py line 151]=>INFO: epoch [28/200] batch [185/314] time 0.045 (0.040) data 0.007 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:35:45
[2025-08-10 19:26:18 codetalker.py line 151]=>INFO: epoch [28/200] batch [190/314] time 0.036 (0.040) data 0.004 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:35:48
[2025-08-10 19:26:18 codetalker.py line 151]=>INFO: epoch [28/200] batch [195/314] time 0.037 (0.040) data 0.003 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:35:46
[2025-08-10 19:26:19 codetalker.py line 151]=>INFO: epoch [28/200] batch [200/314] time 0.047 (0.040) data 0.005 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:35:48
[2025-08-10 19:26:19 codetalker.py line 151]=>INFO: epoch [28/200] batch [205/314] time 0.046 (0.040) data 0.004 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:35:49
[2025-08-10 19:26:19 codetalker.py line 151]=>INFO: epoch [28/200] batch [210/314] time 0.033 (0.040) data 0.000 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:35:48
[2025-08-10 19:26:19 codetalker.py line 151]=>INFO: epoch [28/200] batch [215/314] time 0.038 (0.040) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:35:50
[2025-08-10 19:26:19 codetalker.py line 151]=>INFO: epoch [28/200] batch [220/314] time 0.033 (0.040) data 0.005 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:35:44
[2025-08-10 19:26:20 codetalker.py line 151]=>INFO: epoch [28/200] batch [225/314] time 0.034 (0.040) data 0.004 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:35:39
[2025-08-10 19:26:20 codetalker.py line 151]=>INFO: epoch [28/200] batch [230/314] time 0.039 (0.039) data 0.003 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:35:32
[2025-08-10 19:26:20 codetalker.py line 151]=>INFO: epoch [28/200] batch [235/314] time 0.034 (0.039) data 0.005 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:35:31
[2025-08-10 19:26:20 codetalker.py line 151]=>INFO: epoch [28/200] batch [240/314] time 0.030 (0.039) data 0.006 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:35:25
[2025-08-10 19:26:20 codetalker.py line 151]=>INFO: epoch [28/200] batch [245/314] time 0.035 (0.039) data 0.005 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:35:19
[2025-08-10 19:26:20 codetalker.py line 151]=>INFO: epoch [28/200] batch [250/314] time 0.033 (0.039) data 0.004 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:35:12
[2025-08-10 19:26:21 codetalker.py line 151]=>INFO: epoch [28/200] batch [255/314] time 0.031 (0.039) data 0.004 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:35:05
[2025-08-10 19:26:21 codetalker.py line 151]=>INFO: epoch [28/200] batch [260/314] time 0.035 (0.039) data 0.002 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:35:00
[2025-08-10 19:26:21 codetalker.py line 151]=>INFO: epoch [28/200] batch [265/314] time 0.032 (0.039) data 0.002 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:34:55
[2025-08-10 19:26:21 codetalker.py line 151]=>INFO: epoch [28/200] batch [270/314] time 0.033 (0.039) data 0.004 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:34:52
[2025-08-10 19:26:21 codetalker.py line 151]=>INFO: epoch [28/200] batch [275/314] time 0.029 (0.039) data 0.002 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:34:46
[2025-08-10 19:26:22 codetalker.py line 151]=>INFO: epoch [28/200] batch [280/314] time 0.034 (0.039) data 0.004 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:34:43
[2025-08-10 19:26:22 codetalker.py line 151]=>INFO: epoch [28/200] batch [285/314] time 0.031 (0.038) data 0.002 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:34:37
[2025-08-10 19:26:22 codetalker.py line 151]=>INFO: epoch [28/200] batch [290/314] time 0.033 (0.038) data 0.002 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:34:32
[2025-08-10 19:26:22 codetalker.py line 151]=>INFO: epoch [28/200] batch [295/314] time 0.042 (0.038) data 0.005 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:34:28
[2025-08-10 19:26:22 codetalker.py line 151]=>INFO: epoch [28/200] batch [300/314] time 0.032 (0.038) data 0.003 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:34:26
[2025-08-10 19:26:22 codetalker.py line 151]=>INFO: epoch [28/200] batch [305/314] time 0.035 (0.038) data 0.003 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:34:21
[2025-08-10 19:26:23 codetalker.py line 151]=>INFO: epoch [28/200] batch [310/314] time 0.035 (0.038) data 0.003 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:34:18
[2025-08-10 19:26:23 codetalker.py line 161]=>INFO: epoch: 28 loss_train: 0.0037763353406042336 pp_train: 11.675583423322932 
[2025-08-10 19:26:23 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:26:23 codetalker.py line 234]=>INFO: epoch: 28 loss_val: 0.0039489334914833306 pp_val: 1.0 
[2025-08-10 19:26:25 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:26:26 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-28
[2025-08-10 19:26:26 codetalker.py line 151]=>INFO: epoch [29/200] batch [5/314] time 0.034 (0.056) data 0.003 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:50:27
[2025-08-10 19:26:27 codetalker.py line 151]=>INFO: epoch [29/200] batch [10/314] time 0.037 (0.046) data 0.000 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:41:41
[2025-08-10 19:26:27 codetalker.py line 151]=>INFO: epoch [29/200] batch [15/314] time 0.031 (0.044) data 0.002 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:39:41
[2025-08-10 19:26:27 codetalker.py line 151]=>INFO: epoch [29/200] batch [20/314] time 0.033 (0.042) data 0.007 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:37:21
[2025-08-10 19:26:27 codetalker.py line 151]=>INFO: epoch [29/200] batch [25/314] time 0.031 (0.040) data 0.003 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:35:47
[2025-08-10 19:26:27 codetalker.py line 151]=>INFO: epoch [29/200] batch [30/314] time 0.033 (0.039) data 0.004 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:35:03
[2025-08-10 19:26:28 codetalker.py line 151]=>INFO: epoch [29/200] batch [35/314] time 0.032 (0.038) data 0.004 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:34:12
[2025-08-10 19:26:28 codetalker.py line 151]=>INFO: epoch [29/200] batch [40/314] time 0.034 (0.038) data 0.005 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:33:44
[2025-08-10 19:26:28 codetalker.py line 151]=>INFO: epoch [29/200] batch [45/314] time 0.031 (0.037) data 0.000 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:33:19
[2025-08-10 19:26:28 codetalker.py line 151]=>INFO: epoch [29/200] batch [50/314] time 0.034 (0.037) data 0.000 (0.003) loss 0.0041 lr 5.0000e-05 eta 0:33:14
[2025-08-10 19:26:28 codetalker.py line 151]=>INFO: epoch [29/200] batch [55/314] time 0.033 (0.037) data 0.003 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:33:00
[2025-08-10 19:26:28 codetalker.py line 151]=>INFO: epoch [29/200] batch [60/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:32:48
[2025-08-10 19:26:29 codetalker.py line 151]=>INFO: epoch [29/200] batch [65/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:32:31
[2025-08-10 19:26:29 codetalker.py line 151]=>INFO: epoch [29/200] batch [70/314] time 0.033 (0.036) data 0.002 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:32:20
[2025-08-10 19:26:29 codetalker.py line 151]=>INFO: epoch [29/200] batch [75/314] time 0.031 (0.036) data 0.002 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:32:09
[2025-08-10 19:26:29 codetalker.py line 151]=>INFO: epoch [29/200] batch [80/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:32:09
[2025-08-10 19:26:29 codetalker.py line 151]=>INFO: epoch [29/200] batch [85/314] time 0.040 (0.036) data 0.005 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:32:08
[2025-08-10 19:26:29 codetalker.py line 151]=>INFO: epoch [29/200] batch [90/314] time 0.035 (0.036) data 0.002 (0.003) loss 0.0041 lr 5.0000e-05 eta 0:32:04
[2025-08-10 19:26:30 codetalker.py line 151]=>INFO: epoch [29/200] batch [95/314] time 0.035 (0.036) data 0.003 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:31:57
[2025-08-10 19:26:30 codetalker.py line 151]=>INFO: epoch [29/200] batch [100/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:31:56
[2025-08-10 19:26:30 codetalker.py line 151]=>INFO: epoch [29/200] batch [105/314] time 0.035 (0.035) data 0.003 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:31:49
[2025-08-10 19:26:30 codetalker.py line 151]=>INFO: epoch [29/200] batch [110/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:31:44
[2025-08-10 19:26:30 codetalker.py line 151]=>INFO: epoch [29/200] batch [115/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0041 lr 5.0000e-05 eta 0:31:37
[2025-08-10 19:26:31 codetalker.py line 151]=>INFO: epoch [29/200] batch [120/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:31:31
[2025-08-10 19:26:31 codetalker.py line 151]=>INFO: epoch [29/200] batch [125/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:28
[2025-08-10 19:26:31 codetalker.py line 151]=>INFO: epoch [29/200] batch [130/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:31:25
[2025-08-10 19:26:31 codetalker.py line 151]=>INFO: epoch [29/200] batch [135/314] time 0.033 (0.035) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:20
[2025-08-10 19:26:31 codetalker.py line 151]=>INFO: epoch [29/200] batch [140/314] time 0.030 (0.035) data 0.002 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:31:17
[2025-08-10 19:26:31 codetalker.py line 151]=>INFO: epoch [29/200] batch [145/314] time 0.035 (0.035) data 0.002 (0.003) loss 0.0041 lr 5.0000e-05 eta 0:31:17
[2025-08-10 19:26:32 codetalker.py line 151]=>INFO: epoch [29/200] batch [150/314] time 0.034 (0.035) data 0.002 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:31:21
[2025-08-10 19:26:32 codetalker.py line 151]=>INFO: epoch [29/200] batch [155/314] time 0.033 (0.035) data 0.007 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:31:17
[2025-08-10 19:26:32 codetalker.py line 151]=>INFO: epoch [29/200] batch [160/314] time 0.035 (0.035) data 0.004 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:15
[2025-08-10 19:26:32 codetalker.py line 151]=>INFO: epoch [29/200] batch [165/314] time 0.033 (0.035) data 0.001 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:13
[2025-08-10 19:26:32 codetalker.py line 151]=>INFO: epoch [29/200] batch [170/314] time 0.034 (0.035) data 0.006 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:31:14
[2025-08-10 19:26:32 codetalker.py line 151]=>INFO: epoch [29/200] batch [175/314] time 0.033 (0.035) data 0.002 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:31:15
[2025-08-10 19:26:33 codetalker.py line 151]=>INFO: epoch [29/200] batch [180/314] time 0.034 (0.035) data 0.000 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:31:13
[2025-08-10 19:26:33 codetalker.py line 151]=>INFO: epoch [29/200] batch [185/314] time 0.032 (0.035) data 0.004 (0.003) loss 0.0041 lr 5.0000e-05 eta 0:31:09
[2025-08-10 19:26:33 codetalker.py line 151]=>INFO: epoch [29/200] batch [190/314] time 0.036 (0.035) data 0.000 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:10
[2025-08-10 19:26:33 codetalker.py line 151]=>INFO: epoch [29/200] batch [195/314] time 0.035 (0.035) data 0.005 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:31:09
[2025-08-10 19:26:33 codetalker.py line 151]=>INFO: epoch [29/200] batch [200/314] time 0.043 (0.035) data 0.000 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:31:12
[2025-08-10 19:26:34 codetalker.py line 151]=>INFO: epoch [29/200] batch [205/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:09
[2025-08-10 19:26:34 codetalker.py line 151]=>INFO: epoch [29/200] batch [210/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:31:10
[2025-08-10 19:26:34 codetalker.py line 151]=>INFO: epoch [29/200] batch [215/314] time 0.034 (0.035) data 0.004 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:07
[2025-08-10 19:26:34 codetalker.py line 151]=>INFO: epoch [29/200] batch [220/314] time 0.032 (0.035) data 0.005 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:05
[2025-08-10 19:26:34 codetalker.py line 151]=>INFO: epoch [29/200] batch [225/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:31:05
[2025-08-10 19:26:34 codetalker.py line 151]=>INFO: epoch [29/200] batch [230/314] time 0.035 (0.035) data 0.005 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:06
[2025-08-10 19:26:35 codetalker.py line 151]=>INFO: epoch [29/200] batch [235/314] time 0.034 (0.035) data 0.004 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:31:05
[2025-08-10 19:26:35 codetalker.py line 151]=>INFO: epoch [29/200] batch [240/314] time 0.031 (0.035) data 0.001 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:31:05
[2025-08-10 19:26:35 codetalker.py line 151]=>INFO: epoch [29/200] batch [245/314] time 0.034 (0.035) data 0.006 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:04
[2025-08-10 19:26:35 codetalker.py line 151]=>INFO: epoch [29/200] batch [250/314] time 0.034 (0.035) data 0.005 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:31:03
[2025-08-10 19:26:35 codetalker.py line 151]=>INFO: epoch [29/200] batch [255/314] time 0.028 (0.035) data 0.000 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:02
[2025-08-10 19:26:36 codetalker.py line 151]=>INFO: epoch [29/200] batch [260/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:59
[2025-08-10 19:26:36 codetalker.py line 151]=>INFO: epoch [29/200] batch [265/314] time 0.036 (0.035) data 0.002 (0.003) loss 0.0041 lr 5.0000e-05 eta 0:31:00
[2025-08-10 19:26:36 codetalker.py line 151]=>INFO: epoch [29/200] batch [270/314] time 0.033 (0.035) data 0.005 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:58
[2025-08-10 19:26:36 codetalker.py line 151]=>INFO: epoch [29/200] batch [275/314] time 0.034 (0.035) data 0.004 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:30:59
[2025-08-10 19:26:36 codetalker.py line 151]=>INFO: epoch [29/200] batch [280/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:57
[2025-08-10 19:26:36 codetalker.py line 151]=>INFO: epoch [29/200] batch [285/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:56
[2025-08-10 19:26:37 codetalker.py line 151]=>INFO: epoch [29/200] batch [290/314] time 0.039 (0.035) data 0.008 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:30:56
[2025-08-10 19:26:37 codetalker.py line 151]=>INFO: epoch [29/200] batch [295/314] time 0.038 (0.035) data 0.007 (0.003) loss 0.0040 lr 5.0000e-05 eta 0:30:58
[2025-08-10 19:26:37 codetalker.py line 151]=>INFO: epoch [29/200] batch [300/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:59
[2025-08-10 19:26:37 codetalker.py line 151]=>INFO: epoch [29/200] batch [305/314] time 0.034 (0.035) data 0.000 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:57
[2025-08-10 19:26:37 codetalker.py line 151]=>INFO: epoch [29/200] batch [310/314] time 0.033 (0.035) data 0.000 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:55
[2025-08-10 19:26:37 codetalker.py line 161]=>INFO: epoch: 29 loss_train: 0.003820507975508738 pp_train: 11.683393988639686 
[2025-08-10 19:26:37 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:26:38 codetalker.py line 234]=>INFO: epoch: 29 loss_val: 0.00381084784748964 pp_val: 1.0 
[2025-08-10 19:26:39 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:26:41 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-29
[2025-08-10 19:26:41 codetalker.py line 151]=>INFO: epoch [30/200] batch [5/314] time 0.038 (0.048) data 0.000 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:43:07
[2025-08-10 19:26:41 codetalker.py line 151]=>INFO: epoch [30/200] batch [10/314] time 0.038 (0.046) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:41:09
[2025-08-10 19:26:42 codetalker.py line 151]=>INFO: epoch [30/200] batch [15/314] time 0.044 (0.044) data 0.006 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:39:08
[2025-08-10 19:26:42 codetalker.py line 151]=>INFO: epoch [30/200] batch [20/314] time 0.043 (0.043) data 0.005 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:38:03
[2025-08-10 19:26:42 codetalker.py line 151]=>INFO: epoch [30/200] batch [25/314] time 0.030 (0.040) data 0.002 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:35:51
[2025-08-10 19:26:42 codetalker.py line 151]=>INFO: epoch [30/200] batch [30/314] time 0.040 (0.039) data 0.004 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:35:04
[2025-08-10 19:26:42 codetalker.py line 151]=>INFO: epoch [30/200] batch [35/314] time 0.030 (0.038) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:34:07
[2025-08-10 19:26:42 codetalker.py line 151]=>INFO: epoch [30/200] batch [40/314] time 0.031 (0.038) data 0.003 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:33:55
[2025-08-10 19:26:43 codetalker.py line 151]=>INFO: epoch [30/200] batch [45/314] time 0.032 (0.037) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:33:19
[2025-08-10 19:26:43 codetalker.py line 151]=>INFO: epoch [30/200] batch [50/314] time 0.035 (0.037) data 0.000 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:32:59
[2025-08-10 19:26:43 codetalker.py line 151]=>INFO: epoch [30/200] batch [55/314] time 0.034 (0.037) data 0.000 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:32:39
[2025-08-10 19:26:43 codetalker.py line 151]=>INFO: epoch [30/200] batch [60/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:32:30
[2025-08-10 19:26:43 codetalker.py line 151]=>INFO: epoch [30/200] batch [65/314] time 0.032 (0.036) data 0.001 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:32:23
[2025-08-10 19:26:44 codetalker.py line 151]=>INFO: epoch [30/200] batch [70/314] time 0.033 (0.036) data 0.002 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:32:16
[2025-08-10 19:26:44 codetalker.py line 151]=>INFO: epoch [30/200] batch [75/314] time 0.034 (0.036) data 0.005 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:06
[2025-08-10 19:26:44 codetalker.py line 151]=>INFO: epoch [30/200] batch [80/314] time 0.033 (0.036) data 0.002 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:32:06
[2025-08-10 19:26:44 codetalker.py line 151]=>INFO: epoch [30/200] batch [85/314] time 0.032 (0.036) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:32:01
[2025-08-10 19:26:44 codetalker.py line 151]=>INFO: epoch [30/200] batch [90/314] time 0.034 (0.036) data 0.004 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:32:01
[2025-08-10 19:26:44 codetalker.py line 151]=>INFO: epoch [30/200] batch [95/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0039 lr 5.0000e-05 eta 0:31:53
[2025-08-10 19:26:45 codetalker.py line 151]=>INFO: epoch [30/200] batch [100/314] time 0.034 (0.036) data 0.000 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:49
[2025-08-10 19:26:45 codetalker.py line 151]=>INFO: epoch [30/200] batch [105/314] time 0.042 (0.036) data 0.000 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:44
[2025-08-10 19:26:45 codetalker.py line 151]=>INFO: epoch [30/200] batch [110/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:38
[2025-08-10 19:26:45 codetalker.py line 151]=>INFO: epoch [30/200] batch [115/314] time 0.030 (0.035) data 0.000 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:36
[2025-08-10 19:26:45 codetalker.py line 151]=>INFO: epoch [30/200] batch [120/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:36
[2025-08-10 19:26:45 codetalker.py line 151]=>INFO: epoch [30/200] batch [125/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:32
[2025-08-10 19:26:46 codetalker.py line 151]=>INFO: epoch [30/200] batch [130/314] time 0.030 (0.035) data 0.001 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:26
[2025-08-10 19:26:46 codetalker.py line 151]=>INFO: epoch [30/200] batch [135/314] time 0.034 (0.035) data 0.006 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:23
[2025-08-10 19:26:46 codetalker.py line 151]=>INFO: epoch [30/200] batch [140/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:21
[2025-08-10 19:26:46 codetalker.py line 151]=>INFO: epoch [30/200] batch [145/314] time 0.034 (0.035) data 0.000 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:17
[2025-08-10 19:26:46 codetalker.py line 151]=>INFO: epoch [30/200] batch [150/314] time 0.031 (0.035) data 0.006 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:16
[2025-08-10 19:26:47 codetalker.py line 151]=>INFO: epoch [30/200] batch [155/314] time 0.032 (0.035) data 0.004 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:12
[2025-08-10 19:26:47 codetalker.py line 151]=>INFO: epoch [30/200] batch [160/314] time 0.030 (0.035) data 0.001 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:31:10
[2025-08-10 19:26:47 codetalker.py line 151]=>INFO: epoch [30/200] batch [165/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:08
[2025-08-10 19:26:47 codetalker.py line 151]=>INFO: epoch [30/200] batch [170/314] time 0.028 (0.035) data 0.002 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:02
[2025-08-10 19:26:47 codetalker.py line 151]=>INFO: epoch [30/200] batch [175/314] time 0.029 (0.035) data 0.000 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:58
[2025-08-10 19:26:47 codetalker.py line 151]=>INFO: epoch [30/200] batch [180/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:58
[2025-08-10 19:26:48 codetalker.py line 151]=>INFO: epoch [30/200] batch [185/314] time 0.033 (0.035) data 0.005 (0.003) loss 0.0038 lr 5.0000e-05 eta 0:30:56
[2025-08-10 19:26:48 codetalker.py line 151]=>INFO: epoch [30/200] batch [190/314] time 0.036 (0.035) data 0.004 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:57
[2025-08-10 19:26:48 codetalker.py line 151]=>INFO: epoch [30/200] batch [195/314] time 0.038 (0.035) data 0.002 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:58
[2025-08-10 19:26:48 codetalker.py line 151]=>INFO: epoch [30/200] batch [200/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:55
[2025-08-10 19:26:48 codetalker.py line 151]=>INFO: epoch [30/200] batch [205/314] time 0.039 (0.035) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:56
[2025-08-10 19:26:48 codetalker.py line 151]=>INFO: epoch [30/200] batch [210/314] time 0.035 (0.035) data 0.003 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:56
[2025-08-10 19:26:49 codetalker.py line 151]=>INFO: epoch [30/200] batch [215/314] time 0.038 (0.035) data 0.005 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:56
[2025-08-10 19:26:49 codetalker.py line 151]=>INFO: epoch [30/200] batch [220/314] time 0.041 (0.035) data 0.003 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:57
[2025-08-10 19:26:49 codetalker.py line 151]=>INFO: epoch [30/200] batch [225/314] time 0.035 (0.035) data 0.005 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:56
[2025-08-10 19:26:49 codetalker.py line 151]=>INFO: epoch [30/200] batch [230/314] time 0.035 (0.035) data 0.005 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:55
[2025-08-10 19:26:49 codetalker.py line 151]=>INFO: epoch [30/200] batch [235/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:53
[2025-08-10 19:26:50 codetalker.py line 151]=>INFO: epoch [30/200] batch [240/314] time 0.033 (0.035) data 0.000 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:50
[2025-08-10 19:26:50 codetalker.py line 151]=>INFO: epoch [30/200] batch [245/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:51
[2025-08-10 19:26:50 codetalker.py line 151]=>INFO: epoch [30/200] batch [250/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:50
[2025-08-10 19:26:50 codetalker.py line 151]=>INFO: epoch [30/200] batch [255/314] time 0.034 (0.035) data 0.005 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:49
[2025-08-10 19:26:50 codetalker.py line 151]=>INFO: epoch [30/200] batch [260/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:49
[2025-08-10 19:26:50 codetalker.py line 151]=>INFO: epoch [30/200] batch [265/314] time 0.030 (0.035) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:47
[2025-08-10 19:26:51 codetalker.py line 151]=>INFO: epoch [30/200] batch [270/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:47
[2025-08-10 19:26:51 codetalker.py line 151]=>INFO: epoch [30/200] batch [275/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:46
[2025-08-10 19:26:51 codetalker.py line 151]=>INFO: epoch [30/200] batch [280/314] time 0.033 (0.035) data 0.000 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:46
[2025-08-10 19:26:51 codetalker.py line 151]=>INFO: epoch [30/200] batch [285/314] time 0.033 (0.035) data 0.001 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:46
[2025-08-10 19:26:51 codetalker.py line 151]=>INFO: epoch [30/200] batch [290/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:45
[2025-08-10 19:26:51 codetalker.py line 151]=>INFO: epoch [30/200] batch [295/314] time 0.033 (0.035) data 0.000 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:43
[2025-08-10 19:26:52 codetalker.py line 151]=>INFO: epoch [30/200] batch [300/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:42
[2025-08-10 19:26:52 codetalker.py line 151]=>INFO: epoch [30/200] batch [305/314] time 0.035 (0.034) data 0.003 (0.003) loss 0.0037 lr 5.0000e-05 eta 0:30:41
[2025-08-10 19:26:52 codetalker.py line 151]=>INFO: epoch [30/200] batch [310/314] time 0.032 (0.034) data 0.000 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:41
[2025-08-10 19:26:52 codetalker.py line 161]=>INFO: epoch: 30 loss_train: 0.0035911743799046537 pp_train: 11.683705992000117 
[2025-08-10 19:26:52 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:26:53 codetalker.py line 234]=>INFO: epoch: 30 loss_val: 0.003358891193056479 pp_val: 1.0 
[2025-08-10 19:26:54 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:26:55 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-30
[2025-08-10 19:26:56 codetalker.py line 151]=>INFO: epoch [31/200] batch [5/314] time 0.052 (0.050) data 0.000 (0.002) loss 0.0035 lr 5.0000e-05 eta 0:44:48
[2025-08-10 19:26:56 codetalker.py line 151]=>INFO: epoch [31/200] batch [10/314] time 0.034 (0.042) data 0.003 (0.002) loss 0.0033 lr 5.0000e-05 eta 0:37:22
[2025-08-10 19:26:56 codetalker.py line 151]=>INFO: epoch [31/200] batch [15/314] time 0.032 (0.038) data 0.003 (0.002) loss 0.0037 lr 5.0000e-05 eta 0:34:09
[2025-08-10 19:26:56 codetalker.py line 151]=>INFO: epoch [31/200] batch [20/314] time 0.029 (0.038) data 0.002 (0.002) loss 0.0036 lr 5.0000e-05 eta 0:33:21
[2025-08-10 19:26:56 codetalker.py line 151]=>INFO: epoch [31/200] batch [25/314] time 0.035 (0.037) data 0.001 (0.002) loss 0.0033 lr 5.0000e-05 eta 0:33:05
[2025-08-10 19:26:57 codetalker.py line 151]=>INFO: epoch [31/200] batch [30/314] time 0.034 (0.037) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:33:04
[2025-08-10 19:26:57 codetalker.py line 151]=>INFO: epoch [31/200] batch [35/314] time 0.033 (0.037) data 0.002 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:27
[2025-08-10 19:26:57 codetalker.py line 151]=>INFO: epoch [31/200] batch [40/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:59
[2025-08-10 19:26:57 codetalker.py line 151]=>INFO: epoch [31/200] batch [45/314] time 0.036 (0.036) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:56
[2025-08-10 19:26:57 codetalker.py line 151]=>INFO: epoch [31/200] batch [50/314] time 0.033 (0.036) data 0.004 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:46
[2025-08-10 19:26:58 codetalker.py line 151]=>INFO: epoch [31/200] batch [55/314] time 0.032 (0.036) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:31:38
[2025-08-10 19:26:58 codetalker.py line 151]=>INFO: epoch [31/200] batch [60/314] time 0.031 (0.036) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:31:33
[2025-08-10 19:26:58 codetalker.py line 151]=>INFO: epoch [31/200] batch [65/314] time 0.029 (0.035) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:31:22
[2025-08-10 19:26:58 codetalker.py line 151]=>INFO: epoch [31/200] batch [70/314] time 0.030 (0.035) data 0.000 (0.002) loss 0.0035 lr 5.0000e-05 eta 0:31:11
[2025-08-10 19:26:58 codetalker.py line 151]=>INFO: epoch [31/200] batch [75/314] time 0.036 (0.035) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:13
[2025-08-10 19:26:58 codetalker.py line 151]=>INFO: epoch [31/200] batch [80/314] time 0.037 (0.035) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:12
[2025-08-10 19:26:59 codetalker.py line 151]=>INFO: epoch [31/200] batch [85/314] time 0.035 (0.035) data 0.005 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:03
[2025-08-10 19:26:59 codetalker.py line 151]=>INFO: epoch [31/200] batch [90/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:57
[2025-08-10 19:26:59 codetalker.py line 151]=>INFO: epoch [31/200] batch [95/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:52
[2025-08-10 19:26:59 codetalker.py line 151]=>INFO: epoch [31/200] batch [100/314] time 0.032 (0.035) data 0.000 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:51
[2025-08-10 19:26:59 codetalker.py line 151]=>INFO: epoch [31/200] batch [105/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:49
[2025-08-10 19:27:00 codetalker.py line 151]=>INFO: epoch [31/200] batch [110/314] time 0.033 (0.035) data 0.005 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:51
[2025-08-10 19:27:00 codetalker.py line 151]=>INFO: epoch [31/200] batch [115/314] time 0.039 (0.035) data 0.005 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:49
[2025-08-10 19:27:00 codetalker.py line 151]=>INFO: epoch [31/200] batch [120/314] time 0.032 (0.035) data 0.001 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:47
[2025-08-10 19:27:00 codetalker.py line 151]=>INFO: epoch [31/200] batch [125/314] time 0.035 (0.035) data 0.005 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:45
[2025-08-10 19:27:00 codetalker.py line 151]=>INFO: epoch [31/200] batch [130/314] time 0.035 (0.035) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:46
[2025-08-10 19:27:00 codetalker.py line 151]=>INFO: epoch [31/200] batch [135/314] time 0.034 (0.035) data 0.002 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:41
[2025-08-10 19:27:01 codetalker.py line 151]=>INFO: epoch [31/200] batch [140/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:36
[2025-08-10 19:27:01 codetalker.py line 151]=>INFO: epoch [31/200] batch [145/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:33
[2025-08-10 19:27:01 codetalker.py line 151]=>INFO: epoch [31/200] batch [150/314] time 0.033 (0.034) data 0.000 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:30
[2025-08-10 19:27:01 codetalker.py line 151]=>INFO: epoch [31/200] batch [155/314] time 0.030 (0.034) data 0.000 (0.002) loss 0.0033 lr 5.0000e-05 eta 0:30:25
[2025-08-10 19:27:01 codetalker.py line 151]=>INFO: epoch [31/200] batch [160/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:25
[2025-08-10 19:27:01 codetalker.py line 151]=>INFO: epoch [31/200] batch [165/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:26
[2025-08-10 19:27:02 codetalker.py line 151]=>INFO: epoch [31/200] batch [170/314] time 0.038 (0.034) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:25
[2025-08-10 19:27:02 codetalker.py line 151]=>INFO: epoch [31/200] batch [175/314] time 0.033 (0.034) data 0.005 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:24
[2025-08-10 19:27:02 codetalker.py line 151]=>INFO: epoch [31/200] batch [180/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:24
[2025-08-10 19:27:02 codetalker.py line 151]=>INFO: epoch [31/200] batch [185/314] time 0.033 (0.034) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:22
[2025-08-10 19:27:02 codetalker.py line 151]=>INFO: epoch [31/200] batch [190/314] time 0.030 (0.034) data 0.001 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:21
[2025-08-10 19:27:03 codetalker.py line 151]=>INFO: epoch [31/200] batch [195/314] time 0.036 (0.034) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:20
[2025-08-10 19:27:03 codetalker.py line 151]=>INFO: epoch [31/200] batch [200/314] time 0.032 (0.034) data 0.000 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:18
[2025-08-10 19:27:03 codetalker.py line 151]=>INFO: epoch [31/200] batch [205/314] time 0.038 (0.034) data 0.006 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:19
[2025-08-10 19:27:03 codetalker.py line 151]=>INFO: epoch [31/200] batch [210/314] time 0.035 (0.034) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:18
[2025-08-10 19:27:03 codetalker.py line 151]=>INFO: epoch [31/200] batch [215/314] time 0.030 (0.034) data 0.001 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:17
[2025-08-10 19:27:03 codetalker.py line 151]=>INFO: epoch [31/200] batch [220/314] time 0.036 (0.034) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:17
[2025-08-10 19:27:04 codetalker.py line 151]=>INFO: epoch [31/200] batch [225/314] time 0.031 (0.034) data 0.003 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:15
[2025-08-10 19:27:04 codetalker.py line 151]=>INFO: epoch [31/200] batch [230/314] time 0.034 (0.034) data 0.008 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:14
[2025-08-10 19:27:04 codetalker.py line 151]=>INFO: epoch [31/200] batch [235/314] time 0.033 (0.034) data 0.005 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:14
[2025-08-10 19:27:04 codetalker.py line 151]=>INFO: epoch [31/200] batch [240/314] time 0.035 (0.034) data 0.005 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:13
[2025-08-10 19:27:04 codetalker.py line 151]=>INFO: epoch [31/200] batch [245/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:13
[2025-08-10 19:27:04 codetalker.py line 151]=>INFO: epoch [31/200] batch [250/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:12
[2025-08-10 19:27:05 codetalker.py line 151]=>INFO: epoch [31/200] batch [255/314] time 0.034 (0.034) data 0.003 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:13
[2025-08-10 19:27:05 codetalker.py line 151]=>INFO: epoch [31/200] batch [260/314] time 0.030 (0.034) data 0.001 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:14
[2025-08-10 19:27:05 codetalker.py line 151]=>INFO: epoch [31/200] batch [265/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:12
[2025-08-10 19:27:05 codetalker.py line 151]=>INFO: epoch [31/200] batch [270/314] time 0.036 (0.034) data 0.006 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:11
[2025-08-10 19:27:05 codetalker.py line 151]=>INFO: epoch [31/200] batch [275/314] time 0.042 (0.034) data 0.005 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:11
[2025-08-10 19:27:05 codetalker.py line 151]=>INFO: epoch [31/200] batch [280/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:11
[2025-08-10 19:27:06 codetalker.py line 151]=>INFO: epoch [31/200] batch [285/314] time 0.033 (0.034) data 0.004 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:30:11
[2025-08-10 19:27:06 codetalker.py line 151]=>INFO: epoch [31/200] batch [290/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:10
[2025-08-10 19:27:06 codetalker.py line 151]=>INFO: epoch [31/200] batch [295/314] time 0.035 (0.034) data 0.003 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:10
[2025-08-10 19:27:06 codetalker.py line 151]=>INFO: epoch [31/200] batch [300/314] time 0.033 (0.034) data 0.005 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:09
[2025-08-10 19:27:06 codetalker.py line 151]=>INFO: epoch [31/200] batch [305/314] time 0.034 (0.034) data 0.004 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:09
[2025-08-10 19:27:07 codetalker.py line 151]=>INFO: epoch [31/200] batch [310/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0036 lr 5.0000e-05 eta 0:30:09
[2025-08-10 19:27:07 codetalker.py line 161]=>INFO: epoch: 31 loss_train: 0.003386817244474723 pp_train: 11.679603127157613 
[2025-08-10 19:27:07 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:27:07 codetalker.py line 234]=>INFO: epoch: 31 loss_val: 0.0033452839124947786 pp_val: 1.0 
[2025-08-10 19:27:09 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:27:10 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-31
[2025-08-10 19:27:10 codetalker.py line 151]=>INFO: epoch [32/200] batch [5/314] time 0.049 (0.047) data 0.005 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:41:11
[2025-08-10 19:27:11 codetalker.py line 151]=>INFO: epoch [32/200] batch [10/314] time 0.034 (0.041) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:36:22
[2025-08-10 19:27:11 codetalker.py line 151]=>INFO: epoch [32/200] batch [15/314] time 0.032 (0.039) data 0.006 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:34:46
[2025-08-10 19:27:11 codetalker.py line 151]=>INFO: epoch [32/200] batch [20/314] time 0.031 (0.038) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:33:28
[2025-08-10 19:27:11 codetalker.py line 151]=>INFO: epoch [32/200] batch [25/314] time 0.032 (0.037) data 0.001 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:32:44
[2025-08-10 19:27:11 codetalker.py line 151]=>INFO: epoch [32/200] batch [30/314] time 0.040 (0.037) data 0.004 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:20
[2025-08-10 19:27:11 codetalker.py line 151]=>INFO: epoch [32/200] batch [35/314] time 0.041 (0.036) data 0.005 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:32:09
[2025-08-10 19:27:12 codetalker.py line 151]=>INFO: epoch [32/200] batch [40/314] time 0.031 (0.036) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:45
[2025-08-10 19:27:12 codetalker.py line 151]=>INFO: epoch [32/200] batch [45/314] time 0.035 (0.036) data 0.005 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:43
[2025-08-10 19:27:12 codetalker.py line 151]=>INFO: epoch [32/200] batch [50/314] time 0.031 (0.036) data 0.002 (0.003) loss 0.0035 lr 5.0000e-05 eta 0:31:31
[2025-08-10 19:27:12 codetalker.py line 151]=>INFO: epoch [32/200] batch [55/314] time 0.035 (0.036) data 0.000 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:23
[2025-08-10 19:27:12 codetalker.py line 151]=>INFO: epoch [32/200] batch [60/314] time 0.031 (0.035) data 0.000 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:31:11
[2025-08-10 19:27:12 codetalker.py line 151]=>INFO: epoch [32/200] batch [65/314] time 0.035 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:05
[2025-08-10 19:27:13 codetalker.py line 151]=>INFO: epoch [32/200] batch [70/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:55
[2025-08-10 19:27:13 codetalker.py line 151]=>INFO: epoch [32/200] batch [75/314] time 0.030 (0.035) data 0.000 (0.002) loss 0.0033 lr 5.0000e-05 eta 0:30:52
[2025-08-10 19:27:13 codetalker.py line 151]=>INFO: epoch [32/200] batch [80/314] time 0.034 (0.035) data 0.006 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:44
[2025-08-10 19:27:13 codetalker.py line 151]=>INFO: epoch [32/200] batch [85/314] time 0.033 (0.035) data 0.007 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:39
[2025-08-10 19:27:13 codetalker.py line 151]=>INFO: epoch [32/200] batch [90/314] time 0.031 (0.035) data 0.001 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:35
[2025-08-10 19:27:13 codetalker.py line 151]=>INFO: epoch [32/200] batch [95/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:30
[2025-08-10 19:27:14 codetalker.py line 151]=>INFO: epoch [32/200] batch [100/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:28
[2025-08-10 19:27:14 codetalker.py line 151]=>INFO: epoch [32/200] batch [105/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:27
[2025-08-10 19:27:14 codetalker.py line 151]=>INFO: epoch [32/200] batch [110/314] time 0.034 (0.034) data 0.002 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:26
[2025-08-10 19:27:14 codetalker.py line 151]=>INFO: epoch [32/200] batch [115/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:22
[2025-08-10 19:27:14 codetalker.py line 151]=>INFO: epoch [32/200] batch [120/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:18
[2025-08-10 19:27:15 codetalker.py line 151]=>INFO: epoch [32/200] batch [125/314] time 0.031 (0.034) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:19
[2025-08-10 19:27:15 codetalker.py line 151]=>INFO: epoch [32/200] batch [130/314] time 0.032 (0.034) data 0.006 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:16
[2025-08-10 19:27:15 codetalker.py line 151]=>INFO: epoch [32/200] batch [135/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:15
[2025-08-10 19:27:15 codetalker.py line 151]=>INFO: epoch [32/200] batch [140/314] time 0.038 (0.034) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:15
[2025-08-10 19:27:15 codetalker.py line 151]=>INFO: epoch [32/200] batch [145/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:15
[2025-08-10 19:27:15 codetalker.py line 151]=>INFO: epoch [32/200] batch [150/314] time 0.033 (0.034) data 0.006 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:30:14
[2025-08-10 19:27:16 codetalker.py line 151]=>INFO: epoch [32/200] batch [155/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:17
[2025-08-10 19:27:16 codetalker.py line 151]=>INFO: epoch [32/200] batch [160/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:14
[2025-08-10 19:27:16 codetalker.py line 151]=>INFO: epoch [32/200] batch [165/314] time 0.035 (0.034) data 0.000 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:11
[2025-08-10 19:27:16 codetalker.py line 151]=>INFO: epoch [32/200] batch [170/314] time 0.034 (0.034) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:10
[2025-08-10 19:27:16 codetalker.py line 151]=>INFO: epoch [32/200] batch [175/314] time 0.034 (0.034) data 0.007 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:08
[2025-08-10 19:27:16 codetalker.py line 151]=>INFO: epoch [32/200] batch [180/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:08
[2025-08-10 19:27:17 codetalker.py line 151]=>INFO: epoch [32/200] batch [185/314] time 0.038 (0.034) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:09
[2025-08-10 19:27:17 codetalker.py line 151]=>INFO: epoch [32/200] batch [190/314] time 0.038 (0.034) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:10
[2025-08-10 19:27:17 codetalker.py line 151]=>INFO: epoch [32/200] batch [195/314] time 0.033 (0.034) data 0.006 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:11
[2025-08-10 19:27:17 codetalker.py line 151]=>INFO: epoch [32/200] batch [200/314] time 0.039 (0.034) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:12
[2025-08-10 19:27:17 codetalker.py line 151]=>INFO: epoch [32/200] batch [205/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:11
[2025-08-10 19:27:18 codetalker.py line 151]=>INFO: epoch [32/200] batch [210/314] time 0.034 (0.034) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:11
[2025-08-10 19:27:18 codetalker.py line 151]=>INFO: epoch [32/200] batch [215/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:10
[2025-08-10 19:27:18 codetalker.py line 151]=>INFO: epoch [32/200] batch [220/314] time 0.034 (0.034) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:10
[2025-08-10 19:27:18 codetalker.py line 151]=>INFO: epoch [32/200] batch [225/314] time 0.034 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:09
[2025-08-10 19:27:18 codetalker.py line 151]=>INFO: epoch [32/200] batch [230/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:08
[2025-08-10 19:27:18 codetalker.py line 151]=>INFO: epoch [32/200] batch [235/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:08
[2025-08-10 19:27:19 codetalker.py line 151]=>INFO: epoch [32/200] batch [240/314] time 0.033 (0.034) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:07
[2025-08-10 19:27:19 codetalker.py line 151]=>INFO: epoch [32/200] batch [245/314] time 0.037 (0.034) data 0.005 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:08
[2025-08-10 19:27:19 codetalker.py line 151]=>INFO: epoch [32/200] batch [250/314] time 0.039 (0.034) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:07
[2025-08-10 19:27:19 codetalker.py line 151]=>INFO: epoch [32/200] batch [255/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:06
[2025-08-10 19:27:19 codetalker.py line 151]=>INFO: epoch [32/200] batch [260/314] time 0.033 (0.034) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:05
[2025-08-10 19:27:19 codetalker.py line 151]=>INFO: epoch [32/200] batch [265/314] time 0.034 (0.034) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:06
[2025-08-10 19:27:20 codetalker.py line 151]=>INFO: epoch [32/200] batch [270/314] time 0.053 (0.034) data 0.005 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:11
[2025-08-10 19:27:20 codetalker.py line 151]=>INFO: epoch [32/200] batch [275/314] time 0.043 (0.034) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:20
[2025-08-10 19:27:20 codetalker.py line 151]=>INFO: epoch [32/200] batch [280/314] time 0.056 (0.035) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:29
[2025-08-10 19:27:20 codetalker.py line 151]=>INFO: epoch [32/200] batch [285/314] time 0.036 (0.035) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:34
[2025-08-10 19:27:21 codetalker.py line 151]=>INFO: epoch [32/200] batch [290/314] time 0.048 (0.035) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:38
[2025-08-10 19:27:21 codetalker.py line 151]=>INFO: epoch [32/200] batch [295/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:40
[2025-08-10 19:27:21 codetalker.py line 151]=>INFO: epoch [32/200] batch [300/314] time 0.039 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:43
[2025-08-10 19:27:21 codetalker.py line 151]=>INFO: epoch [32/200] batch [305/314] time 0.048 (0.035) data 0.003 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:30:50
[2025-08-10 19:27:21 codetalker.py line 151]=>INFO: epoch [32/200] batch [310/314] time 0.039 (0.035) data 0.006 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:59
[2025-08-10 19:27:22 codetalker.py line 161]=>INFO: epoch: 32 loss_train: 0.0032499739225467393 pp_train: 11.679292369040715 
[2025-08-10 19:27:22 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:27:22 codetalker.py line 234]=>INFO: epoch: 32 loss_val: 0.0032827107061166316 pp_val: 1.0 
[2025-08-10 19:27:23 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:27:25 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-32
[2025-08-10 19:27:25 codetalker.py line 151]=>INFO: epoch [33/200] batch [5/314] time 0.050 (0.053) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:46:49
[2025-08-10 19:27:25 codetalker.py line 151]=>INFO: epoch [33/200] batch [10/314] time 0.034 (0.044) data 0.005 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:38:41
[2025-08-10 19:27:26 codetalker.py line 151]=>INFO: epoch [33/200] batch [15/314] time 0.041 (0.041) data 0.006 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:35:53
[2025-08-10 19:27:26 codetalker.py line 151]=>INFO: epoch [33/200] batch [20/314] time 0.033 (0.039) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:34:08
[2025-08-10 19:27:26 codetalker.py line 151]=>INFO: epoch [33/200] batch [25/314] time 0.039 (0.038) data 0.000 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:33:28
[2025-08-10 19:27:26 codetalker.py line 151]=>INFO: epoch [33/200] batch [30/314] time 0.044 (0.039) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:34:31
[2025-08-10 19:27:26 codetalker.py line 151]=>INFO: epoch [33/200] batch [35/314] time 0.032 (0.039) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:34:21
[2025-08-10 19:27:27 codetalker.py line 151]=>INFO: epoch [33/200] batch [40/314] time 0.028 (0.038) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:33:48
[2025-08-10 19:27:27 codetalker.py line 151]=>INFO: epoch [33/200] batch [45/314] time 0.031 (0.038) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:33:10
[2025-08-10 19:27:27 codetalker.py line 151]=>INFO: epoch [33/200] batch [50/314] time 0.032 (0.037) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:32:41
[2025-08-10 19:27:27 codetalker.py line 151]=>INFO: epoch [33/200] batch [55/314] time 0.033 (0.037) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:32:33
[2025-08-10 19:27:27 codetalker.py line 151]=>INFO: epoch [33/200] batch [60/314] time 0.028 (0.037) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:32:19
[2025-08-10 19:27:27 codetalker.py line 151]=>INFO: epoch [33/200] batch [65/314] time 0.032 (0.036) data 0.003 (0.003) loss 0.0034 lr 5.0000e-05 eta 0:32:02
[2025-08-10 19:27:28 codetalker.py line 151]=>INFO: epoch [33/200] batch [70/314] time 0.037 (0.036) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:31:54
[2025-08-10 19:27:28 codetalker.py line 151]=>INFO: epoch [33/200] batch [75/314] time 0.032 (0.036) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:31:53
[2025-08-10 19:27:28 codetalker.py line 151]=>INFO: epoch [33/200] batch [80/314] time 0.039 (0.036) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:31:50
[2025-08-10 19:27:28 codetalker.py line 151]=>INFO: epoch [33/200] batch [85/314] time 0.033 (0.036) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:47
[2025-08-10 19:27:28 codetalker.py line 151]=>INFO: epoch [33/200] batch [90/314] time 0.033 (0.036) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:31:41
[2025-08-10 19:27:29 codetalker.py line 151]=>INFO: epoch [33/200] batch [95/314] time 0.033 (0.036) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:31:30
[2025-08-10 19:27:29 codetalker.py line 151]=>INFO: epoch [33/200] batch [100/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:31:28
[2025-08-10 19:27:29 codetalker.py line 151]=>INFO: epoch [33/200] batch [105/314] time 0.036 (0.036) data 0.001 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:31:26
[2025-08-10 19:27:29 codetalker.py line 151]=>INFO: epoch [33/200] batch [110/314] time 0.031 (0.036) data 0.002 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:31:15
[2025-08-10 19:27:29 codetalker.py line 151]=>INFO: epoch [33/200] batch [115/314] time 0.034 (0.036) data 0.006 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:16
[2025-08-10 19:27:29 codetalker.py line 151]=>INFO: epoch [33/200] batch [120/314] time 0.031 (0.036) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:31:08
[2025-08-10 19:27:30 codetalker.py line 151]=>INFO: epoch [33/200] batch [125/314] time 0.033 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:06
[2025-08-10 19:27:30 codetalker.py line 151]=>INFO: epoch [33/200] batch [130/314] time 0.031 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:31:04
[2025-08-10 19:27:30 codetalker.py line 151]=>INFO: epoch [33/200] batch [135/314] time 0.032 (0.035) data 0.001 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:31:03
[2025-08-10 19:27:30 codetalker.py line 151]=>INFO: epoch [33/200] batch [140/314] time 0.034 (0.035) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:58
[2025-08-10 19:27:30 codetalker.py line 151]=>INFO: epoch [33/200] batch [145/314] time 0.035 (0.035) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:59
[2025-08-10 19:27:30 codetalker.py line 151]=>INFO: epoch [33/200] batch [150/314] time 0.036 (0.035) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:59
[2025-08-10 19:27:31 codetalker.py line 151]=>INFO: epoch [33/200] batch [155/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:59
[2025-08-10 19:27:31 codetalker.py line 151]=>INFO: epoch [33/200] batch [160/314] time 0.045 (0.035) data 0.005 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:31:04
[2025-08-10 19:27:31 codetalker.py line 151]=>INFO: epoch [33/200] batch [165/314] time 0.043 (0.036) data 0.006 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:20
[2025-08-10 19:27:31 codetalker.py line 151]=>INFO: epoch [33/200] batch [170/314] time 0.036 (0.036) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:24
[2025-08-10 19:27:31 codetalker.py line 151]=>INFO: epoch [33/200] batch [175/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:21
[2025-08-10 19:27:32 codetalker.py line 151]=>INFO: epoch [33/200] batch [180/314] time 0.032 (0.036) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:31:16
[2025-08-10 19:27:32 codetalker.py line 151]=>INFO: epoch [33/200] batch [185/314] time 0.033 (0.036) data 0.005 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:31:13
[2025-08-10 19:27:32 codetalker.py line 151]=>INFO: epoch [33/200] batch [190/314] time 0.034 (0.036) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:10
[2025-08-10 19:27:32 codetalker.py line 151]=>INFO: epoch [33/200] batch [195/314] time 0.030 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:05
[2025-08-10 19:27:32 codetalker.py line 151]=>INFO: epoch [33/200] batch [200/314] time 0.031 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:31:03
[2025-08-10 19:27:33 codetalker.py line 151]=>INFO: epoch [33/200] batch [205/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:01
[2025-08-10 19:27:33 codetalker.py line 151]=>INFO: epoch [33/200] batch [210/314] time 0.027 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:58
[2025-08-10 19:27:33 codetalker.py line 151]=>INFO: epoch [33/200] batch [215/314] time 0.038 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:57
[2025-08-10 19:27:33 codetalker.py line 151]=>INFO: epoch [33/200] batch [220/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:54
[2025-08-10 19:27:33 codetalker.py line 151]=>INFO: epoch [33/200] batch [225/314] time 0.031 (0.035) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:51
[2025-08-10 19:27:33 codetalker.py line 151]=>INFO: epoch [33/200] batch [230/314] time 0.031 (0.035) data 0.001 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:50
[2025-08-10 19:27:34 codetalker.py line 151]=>INFO: epoch [33/200] batch [235/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:47
[2025-08-10 19:27:34 codetalker.py line 151]=>INFO: epoch [33/200] batch [240/314] time 0.029 (0.035) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:44
[2025-08-10 19:27:34 codetalker.py line 151]=>INFO: epoch [33/200] batch [245/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:41
[2025-08-10 19:27:34 codetalker.py line 151]=>INFO: epoch [33/200] batch [250/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:37
[2025-08-10 19:27:34 codetalker.py line 151]=>INFO: epoch [33/200] batch [255/314] time 0.034 (0.035) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:36
[2025-08-10 19:27:34 codetalker.py line 151]=>INFO: epoch [33/200] batch [260/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:33
[2025-08-10 19:27:35 codetalker.py line 151]=>INFO: epoch [33/200] batch [265/314] time 0.036 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:35
[2025-08-10 19:27:35 codetalker.py line 151]=>INFO: epoch [33/200] batch [270/314] time 0.034 (0.035) data 0.006 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:36
[2025-08-10 19:27:35 codetalker.py line 151]=>INFO: epoch [33/200] batch [275/314] time 0.026 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:32
[2025-08-10 19:27:35 codetalker.py line 151]=>INFO: epoch [33/200] batch [280/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:39
[2025-08-10 19:27:35 codetalker.py line 151]=>INFO: epoch [33/200] batch [285/314] time 0.031 (0.035) data 0.001 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:40
[2025-08-10 19:27:36 codetalker.py line 151]=>INFO: epoch [33/200] batch [290/314] time 0.033 (0.035) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:39
[2025-08-10 19:27:36 codetalker.py line 151]=>INFO: epoch [33/200] batch [295/314] time 0.029 (0.035) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:36
[2025-08-10 19:27:36 codetalker.py line 151]=>INFO: epoch [33/200] batch [300/314] time 0.028 (0.035) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:33
[2025-08-10 19:27:36 codetalker.py line 151]=>INFO: epoch [33/200] batch [305/314] time 0.036 (0.035) data 0.006 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:31
[2025-08-10 19:27:36 codetalker.py line 151]=>INFO: epoch [33/200] batch [310/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:28
[2025-08-10 19:27:36 codetalker.py line 161]=>INFO: epoch: 33 loss_train: 0.0031477579221153144 pp_train: 11.679291904352272 
[2025-08-10 19:27:36 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:27:37 codetalker.py line 234]=>INFO: epoch: 33 loss_val: 0.003086648287717253 pp_val: 1.0 
[2025-08-10 19:27:38 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:27:40 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-33
[2025-08-10 19:27:40 codetalker.py line 151]=>INFO: epoch [34/200] batch [5/314] time 0.033 (0.046) data 0.002 (0.001) loss 0.0031 lr 5.0000e-05 eta 0:40:17
[2025-08-10 19:27:40 codetalker.py line 151]=>INFO: epoch [34/200] batch [10/314] time 0.033 (0.040) data 0.000 (0.002) loss 0.0033 lr 5.0000e-05 eta 0:34:49
[2025-08-10 19:27:40 codetalker.py line 151]=>INFO: epoch [34/200] batch [15/314] time 0.033 (0.039) data 0.002 (0.002) loss 0.0033 lr 5.0000e-05 eta 0:33:51
[2025-08-10 19:27:41 codetalker.py line 151]=>INFO: epoch [34/200] batch [20/314] time 0.036 (0.038) data 0.002 (0.002) loss 0.0030 lr 5.0000e-05 eta 0:32:57
[2025-08-10 19:27:41 codetalker.py line 151]=>INFO: epoch [34/200] batch [25/314] time 0.033 (0.037) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:32:26
[2025-08-10 19:27:41 codetalker.py line 151]=>INFO: epoch [34/200] batch [30/314] time 0.037 (0.037) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:32:18
[2025-08-10 19:27:41 codetalker.py line 151]=>INFO: epoch [34/200] batch [35/314] time 0.034 (0.037) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:32:00
[2025-08-10 19:27:41 codetalker.py line 151]=>INFO: epoch [34/200] batch [40/314] time 0.039 (0.036) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:46
[2025-08-10 19:27:41 codetalker.py line 151]=>INFO: epoch [34/200] batch [45/314] time 0.028 (0.036) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:22
[2025-08-10 19:27:42 codetalker.py line 151]=>INFO: epoch [34/200] batch [50/314] time 0.037 (0.036) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:31:15
[2025-08-10 19:27:42 codetalker.py line 151]=>INFO: epoch [34/200] batch [55/314] time 0.037 (0.036) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:12
[2025-08-10 19:27:42 codetalker.py line 151]=>INFO: epoch [34/200] batch [60/314] time 0.039 (0.036) data 0.007 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:31:00
[2025-08-10 19:27:42 codetalker.py line 151]=>INFO: epoch [34/200] batch [65/314] time 0.035 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:46
[2025-08-10 19:27:42 codetalker.py line 151]=>INFO: epoch [34/200] batch [70/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:37
[2025-08-10 19:27:43 codetalker.py line 151]=>INFO: epoch [34/200] batch [75/314] time 0.035 (0.035) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:37
[2025-08-10 19:27:43 codetalker.py line 151]=>INFO: epoch [34/200] batch [80/314] time 0.032 (0.035) data 0.001 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:40
[2025-08-10 19:27:43 codetalker.py line 151]=>INFO: epoch [34/200] batch [85/314] time 0.037 (0.035) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:45
[2025-08-10 19:27:43 codetalker.py line 151]=>INFO: epoch [34/200] batch [90/314] time 0.030 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:45
[2025-08-10 19:27:43 codetalker.py line 151]=>INFO: epoch [34/200] batch [95/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:34
[2025-08-10 19:27:43 codetalker.py line 151]=>INFO: epoch [34/200] batch [100/314] time 0.031 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:36
[2025-08-10 19:27:44 codetalker.py line 151]=>INFO: epoch [34/200] batch [105/314] time 0.040 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:40
[2025-08-10 19:27:44 codetalker.py line 151]=>INFO: epoch [34/200] batch [110/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:43
[2025-08-10 19:27:44 codetalker.py line 151]=>INFO: epoch [34/200] batch [115/314] time 0.033 (0.035) data 0.006 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:46
[2025-08-10 19:27:44 codetalker.py line 151]=>INFO: epoch [34/200] batch [120/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:48
[2025-08-10 19:27:44 codetalker.py line 151]=>INFO: epoch [34/200] batch [125/314] time 0.041 (0.035) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:45
[2025-08-10 19:27:45 codetalker.py line 151]=>INFO: epoch [34/200] batch [130/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:44
[2025-08-10 19:27:45 codetalker.py line 151]=>INFO: epoch [34/200] batch [135/314] time 0.042 (0.035) data 0.010 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:44
[2025-08-10 19:27:45 codetalker.py line 151]=>INFO: epoch [34/200] batch [140/314] time 0.033 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:43
[2025-08-10 19:27:45 codetalker.py line 151]=>INFO: epoch [34/200] batch [145/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:41
[2025-08-10 19:27:45 codetalker.py line 151]=>INFO: epoch [34/200] batch [150/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:39
[2025-08-10 19:27:45 codetalker.py line 151]=>INFO: epoch [34/200] batch [155/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:35
[2025-08-10 19:27:46 codetalker.py line 151]=>INFO: epoch [34/200] batch [160/314] time 0.026 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:31
[2025-08-10 19:27:46 codetalker.py line 151]=>INFO: epoch [34/200] batch [165/314] time 0.034 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:30
[2025-08-10 19:27:46 codetalker.py line 151]=>INFO: epoch [34/200] batch [170/314] time 0.030 (0.035) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:26
[2025-08-10 19:27:46 codetalker.py line 151]=>INFO: epoch [34/200] batch [175/314] time 0.028 (0.035) data 0.001 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:25
[2025-08-10 19:27:46 codetalker.py line 151]=>INFO: epoch [34/200] batch [180/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:23
[2025-08-10 19:27:47 codetalker.py line 151]=>INFO: epoch [34/200] batch [185/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:20
[2025-08-10 19:27:47 codetalker.py line 151]=>INFO: epoch [34/200] batch [190/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:18
[2025-08-10 19:27:47 codetalker.py line 151]=>INFO: epoch [34/200] batch [195/314] time 0.036 (0.035) data 0.006 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:17
[2025-08-10 19:27:47 codetalker.py line 151]=>INFO: epoch [34/200] batch [200/314] time 0.032 (0.035) data 0.006 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:15
[2025-08-10 19:27:47 codetalker.py line 151]=>INFO: epoch [34/200] batch [205/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:16
[2025-08-10 19:27:47 codetalker.py line 151]=>INFO: epoch [34/200] batch [210/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:14
[2025-08-10 19:27:48 codetalker.py line 151]=>INFO: epoch [34/200] batch [215/314] time 0.038 (0.035) data 0.008 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:12
[2025-08-10 19:27:48 codetalker.py line 151]=>INFO: epoch [34/200] batch [220/314] time 0.035 (0.035) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:10
[2025-08-10 19:27:48 codetalker.py line 151]=>INFO: epoch [34/200] batch [225/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:11
[2025-08-10 19:27:48 codetalker.py line 151]=>INFO: epoch [34/200] batch [230/314] time 0.030 (0.035) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:09
[2025-08-10 19:27:48 codetalker.py line 151]=>INFO: epoch [34/200] batch [235/314] time 0.034 (0.035) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:07
[2025-08-10 19:27:48 codetalker.py line 151]=>INFO: epoch [34/200] batch [240/314] time 0.027 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:01
[2025-08-10 19:27:49 codetalker.py line 151]=>INFO: epoch [34/200] batch [245/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:59
[2025-08-10 19:27:49 codetalker.py line 151]=>INFO: epoch [34/200] batch [250/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:58
[2025-08-10 19:27:49 codetalker.py line 151]=>INFO: epoch [34/200] batch [255/314] time 0.036 (0.034) data 0.009 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:57
[2025-08-10 19:27:49 codetalker.py line 151]=>INFO: epoch [34/200] batch [260/314] time 0.037 (0.034) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:58
[2025-08-10 19:27:49 codetalker.py line 151]=>INFO: epoch [34/200] batch [265/314] time 0.034 (0.034) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:59
[2025-08-10 19:27:50 codetalker.py line 151]=>INFO: epoch [34/200] batch [270/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:00
[2025-08-10 19:27:50 codetalker.py line 151]=>INFO: epoch [34/200] batch [275/314] time 0.034 (0.034) data 0.009 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:58
[2025-08-10 19:27:50 codetalker.py line 151]=>INFO: epoch [34/200] batch [280/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:57
[2025-08-10 19:27:50 codetalker.py line 151]=>INFO: epoch [34/200] batch [285/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:57
[2025-08-10 19:27:50 codetalker.py line 151]=>INFO: epoch [34/200] batch [290/314] time 0.035 (0.034) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:57
[2025-08-10 19:27:50 codetalker.py line 151]=>INFO: epoch [34/200] batch [295/314] time 0.036 (0.035) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:59
[2025-08-10 19:27:51 codetalker.py line 151]=>INFO: epoch [34/200] batch [300/314] time 0.034 (0.035) data 0.001 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:59
[2025-08-10 19:27:51 codetalker.py line 151]=>INFO: epoch [34/200] batch [305/314] time 0.036 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:00
[2025-08-10 19:27:51 codetalker.py line 151]=>INFO: epoch [34/200] batch [310/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:00
[2025-08-10 19:27:51 codetalker.py line 161]=>INFO: epoch: 34 loss_train: 0.003102260665481637 pp_train: 11.681936962589337 
[2025-08-10 19:27:51 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:27:52 codetalker.py line 234]=>INFO: epoch: 34 loss_val: 0.003087364858947694 pp_val: 1.0 
[2025-08-10 19:27:53 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:27:54 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-34
[2025-08-10 19:27:55 codetalker.py line 151]=>INFO: epoch [35/200] batch [5/314] time 0.056 (0.056) data 0.007 (0.004) loss 0.0031 lr 5.0000e-05 eta 0:48:40
[2025-08-10 19:27:55 codetalker.py line 151]=>INFO: epoch [35/200] batch [10/314] time 0.035 (0.045) data 0.003 (0.004) loss 0.0030 lr 5.0000e-05 eta 0:38:55
[2025-08-10 19:27:55 codetalker.py line 151]=>INFO: epoch [35/200] batch [15/314] time 0.035 (0.041) data 0.006 (0.004) loss 0.0031 lr 5.0000e-05 eta 0:35:30
[2025-08-10 19:27:55 codetalker.py line 151]=>INFO: epoch [35/200] batch [20/314] time 0.033 (0.039) data 0.007 (0.004) loss 0.0032 lr 5.0000e-05 eta 0:33:44
[2025-08-10 19:27:55 codetalker.py line 151]=>INFO: epoch [35/200] batch [25/314] time 0.042 (0.038) data 0.007 (0.004) loss 0.0030 lr 5.0000e-05 eta 0:32:55
[2025-08-10 19:27:56 codetalker.py line 151]=>INFO: epoch [35/200] batch [30/314] time 0.034 (0.037) data 0.000 (0.004) loss 0.0031 lr 5.0000e-05 eta 0:32:32
[2025-08-10 19:27:56 codetalker.py line 151]=>INFO: epoch [35/200] batch [35/314] time 0.038 (0.037) data 0.009 (0.004) loss 0.0030 lr 5.0000e-05 eta 0:32:06
[2025-08-10 19:27:56 codetalker.py line 151]=>INFO: epoch [35/200] batch [40/314] time 0.033 (0.037) data 0.002 (0.004) loss 0.0031 lr 5.0000e-05 eta 0:31:46
[2025-08-10 19:27:56 codetalker.py line 151]=>INFO: epoch [35/200] batch [45/314] time 0.033 (0.036) data 0.003 (0.004) loss 0.0031 lr 5.0000e-05 eta 0:31:24
[2025-08-10 19:27:56 codetalker.py line 151]=>INFO: epoch [35/200] batch [50/314] time 0.033 (0.036) data 0.002 (0.004) loss 0.0031 lr 5.0000e-05 eta 0:31:20
[2025-08-10 19:27:57 codetalker.py line 151]=>INFO: epoch [35/200] batch [55/314] time 0.037 (0.036) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:31:07
[2025-08-10 19:27:57 codetalker.py line 151]=>INFO: epoch [35/200] batch [60/314] time 0.032 (0.036) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:57
[2025-08-10 19:27:57 codetalker.py line 151]=>INFO: epoch [35/200] batch [65/314] time 0.035 (0.036) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:59
[2025-08-10 19:27:57 codetalker.py line 151]=>INFO: epoch [35/200] batch [70/314] time 0.033 (0.036) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:52
[2025-08-10 19:27:57 codetalker.py line 151]=>INFO: epoch [35/200] batch [75/314] time 0.036 (0.036) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:47
[2025-08-10 19:27:57 codetalker.py line 151]=>INFO: epoch [35/200] batch [80/314] time 0.040 (0.035) data 0.010 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:42
[2025-08-10 19:27:58 codetalker.py line 151]=>INFO: epoch [35/200] batch [85/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:41
[2025-08-10 19:27:58 codetalker.py line 151]=>INFO: epoch [35/200] batch [90/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:30:34
[2025-08-10 19:27:58 codetalker.py line 151]=>INFO: epoch [35/200] batch [95/314] time 0.043 (0.035) data 0.012 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:36
[2025-08-10 19:27:58 codetalker.py line 151]=>INFO: epoch [35/200] batch [100/314] time 0.038 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:35
[2025-08-10 19:27:58 codetalker.py line 151]=>INFO: epoch [35/200] batch [105/314] time 0.033 (0.035) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:35
[2025-08-10 19:27:58 codetalker.py line 151]=>INFO: epoch [35/200] batch [110/314] time 0.036 (0.035) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:41
[2025-08-10 19:27:59 codetalker.py line 151]=>INFO: epoch [35/200] batch [115/314] time 0.040 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:42
[2025-08-10 19:27:59 codetalker.py line 151]=>INFO: epoch [35/200] batch [120/314] time 0.040 (0.035) data 0.008 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:43
[2025-08-10 19:27:59 codetalker.py line 151]=>INFO: epoch [35/200] batch [125/314] time 0.034 (0.035) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:42
[2025-08-10 19:27:59 codetalker.py line 151]=>INFO: epoch [35/200] batch [130/314] time 0.033 (0.035) data 0.005 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:30:39
[2025-08-10 19:27:59 codetalker.py line 151]=>INFO: epoch [35/200] batch [135/314] time 0.040 (0.035) data 0.007 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:41
[2025-08-10 19:28:00 codetalker.py line 151]=>INFO: epoch [35/200] batch [140/314] time 0.033 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:40
[2025-08-10 19:28:00 codetalker.py line 151]=>INFO: epoch [35/200] batch [145/314] time 0.034 (0.035) data 0.009 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:36
[2025-08-10 19:28:00 codetalker.py line 151]=>INFO: epoch [35/200] batch [150/314] time 0.037 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:41
[2025-08-10 19:28:00 codetalker.py line 151]=>INFO: epoch [35/200] batch [155/314] time 0.035 (0.035) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:40
[2025-08-10 19:28:00 codetalker.py line 151]=>INFO: epoch [35/200] batch [160/314] time 0.040 (0.035) data 0.010 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:40
[2025-08-10 19:28:00 codetalker.py line 151]=>INFO: epoch [35/200] batch [165/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:36
[2025-08-10 19:28:01 codetalker.py line 151]=>INFO: epoch [35/200] batch [170/314] time 0.030 (0.035) data 0.007 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:34
[2025-08-10 19:28:01 codetalker.py line 151]=>INFO: epoch [35/200] batch [175/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:36
[2025-08-10 19:28:01 codetalker.py line 151]=>INFO: epoch [35/200] batch [180/314] time 0.034 (0.035) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:32
[2025-08-10 19:28:01 codetalker.py line 151]=>INFO: epoch [35/200] batch [185/314] time 0.034 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:29
[2025-08-10 19:28:01 codetalker.py line 151]=>INFO: epoch [35/200] batch [190/314] time 0.035 (0.035) data 0.008 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:30:27
[2025-08-10 19:28:02 codetalker.py line 151]=>INFO: epoch [35/200] batch [195/314] time 0.033 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:28
[2025-08-10 19:28:02 codetalker.py line 151]=>INFO: epoch [35/200] batch [200/314] time 0.031 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:25
[2025-08-10 19:28:02 codetalker.py line 151]=>INFO: epoch [35/200] batch [205/314] time 0.034 (0.035) data 0.007 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:23
[2025-08-10 19:28:02 codetalker.py line 151]=>INFO: epoch [35/200] batch [210/314] time 0.032 (0.035) data 0.004 (0.004) loss 0.0031 lr 5.0000e-05 eta 0:30:25
[2025-08-10 19:28:02 codetalker.py line 151]=>INFO: epoch [35/200] batch [215/314] time 0.035 (0.035) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:25
[2025-08-10 19:28:02 codetalker.py line 151]=>INFO: epoch [35/200] batch [220/314] time 0.035 (0.035) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:21
[2025-08-10 19:28:03 codetalker.py line 151]=>INFO: epoch [35/200] batch [225/314] time 0.035 (0.035) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:20
[2025-08-10 19:28:03 codetalker.py line 151]=>INFO: epoch [35/200] batch [230/314] time 0.024 (0.035) data 0.001 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:15
[2025-08-10 19:28:03 codetalker.py line 151]=>INFO: epoch [35/200] batch [235/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:16
[2025-08-10 19:28:03 codetalker.py line 151]=>INFO: epoch [35/200] batch [240/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:13
[2025-08-10 19:28:03 codetalker.py line 151]=>INFO: epoch [35/200] batch [245/314] time 0.036 (0.035) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:15
[2025-08-10 19:28:03 codetalker.py line 151]=>INFO: epoch [35/200] batch [250/314] time 0.031 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:12
[2025-08-10 19:28:04 codetalker.py line 151]=>INFO: epoch [35/200] batch [255/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:10
[2025-08-10 19:28:04 codetalker.py line 151]=>INFO: epoch [35/200] batch [260/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:08
[2025-08-10 19:28:04 codetalker.py line 151]=>INFO: epoch [35/200] batch [265/314] time 0.039 (0.035) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:08
[2025-08-10 19:28:04 codetalker.py line 151]=>INFO: epoch [35/200] batch [270/314] time 0.028 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:05
[2025-08-10 19:28:04 codetalker.py line 151]=>INFO: epoch [35/200] batch [275/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:04
[2025-08-10 19:28:05 codetalker.py line 151]=>INFO: epoch [35/200] batch [280/314] time 0.041 (0.035) data 0.000 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:30:04
[2025-08-10 19:28:05 codetalker.py line 151]=>INFO: epoch [35/200] batch [285/314] time 0.040 (0.035) data 0.008 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:03
[2025-08-10 19:28:05 codetalker.py line 151]=>INFO: epoch [35/200] batch [290/314] time 0.033 (0.035) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:01
[2025-08-10 19:28:05 codetalker.py line 151]=>INFO: epoch [35/200] batch [295/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:01
[2025-08-10 19:28:05 codetalker.py line 151]=>INFO: epoch [35/200] batch [300/314] time 0.034 (0.035) data 0.004 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:30:00
[2025-08-10 19:28:05 codetalker.py line 151]=>INFO: epoch [35/200] batch [305/314] time 0.028 (0.035) data 0.002 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:29:59
[2025-08-10 19:28:06 codetalker.py line 151]=>INFO: epoch [35/200] batch [310/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:29:59
[2025-08-10 19:28:06 codetalker.py line 161]=>INFO: epoch: 35 loss_train: 0.003068786551197101 pp_train: 11.67901391132622 
[2025-08-10 19:28:06 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:28:06 codetalker.py line 234]=>INFO: epoch: 35 loss_val: 0.0031064769311342387 pp_val: 1.4575693249702453 
[2025-08-10 19:28:08 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:28:09 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-35
[2025-08-10 19:28:09 codetalker.py line 151]=>INFO: epoch [36/200] batch [5/314] time 0.045 (0.056) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:48:45
[2025-08-10 19:28:10 codetalker.py line 151]=>INFO: epoch [36/200] batch [10/314] time 0.035 (0.045) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:38:51
[2025-08-10 19:28:10 codetalker.py line 151]=>INFO: epoch [36/200] batch [15/314] time 0.028 (0.041) data 0.000 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:35:06
[2025-08-10 19:28:10 codetalker.py line 151]=>INFO: epoch [36/200] batch [20/314] time 0.033 (0.039) data 0.003 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:33:27
[2025-08-10 19:28:10 codetalker.py line 151]=>INFO: epoch [36/200] batch [25/314] time 0.032 (0.038) data 0.004 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:32:30
[2025-08-10 19:28:10 codetalker.py line 151]=>INFO: epoch [36/200] batch [30/314] time 0.038 (0.037) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:31:47
[2025-08-10 19:28:11 codetalker.py line 151]=>INFO: epoch [36/200] batch [35/314] time 0.033 (0.036) data 0.007 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:31:18
[2025-08-10 19:28:11 codetalker.py line 151]=>INFO: epoch [36/200] batch [40/314] time 0.034 (0.036) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:58
[2025-08-10 19:28:11 codetalker.py line 151]=>INFO: epoch [36/200] batch [45/314] time 0.035 (0.036) data 0.004 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:30:43
[2025-08-10 19:28:11 codetalker.py line 151]=>INFO: epoch [36/200] batch [50/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:28
[2025-08-10 19:28:11 codetalker.py line 151]=>INFO: epoch [36/200] batch [55/314] time 0.033 (0.035) data 0.005 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:30:16
[2025-08-10 19:28:11 codetalker.py line 151]=>INFO: epoch [36/200] batch [60/314] time 0.034 (0.035) data 0.007 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:10
[2025-08-10 19:28:12 codetalker.py line 151]=>INFO: epoch [36/200] batch [65/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:04
[2025-08-10 19:28:12 codetalker.py line 151]=>INFO: epoch [36/200] batch [70/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:54
[2025-08-10 19:28:12 codetalker.py line 151]=>INFO: epoch [36/200] batch [75/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:45
[2025-08-10 19:28:12 codetalker.py line 151]=>INFO: epoch [36/200] batch [80/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:29:45
[2025-08-10 19:28:12 codetalker.py line 151]=>INFO: epoch [36/200] batch [85/314] time 0.035 (0.035) data 0.005 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:29:44
[2025-08-10 19:28:12 codetalker.py line 151]=>INFO: epoch [36/200] batch [90/314] time 0.031 (0.035) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:44
[2025-08-10 19:28:13 codetalker.py line 151]=>INFO: epoch [36/200] batch [95/314] time 0.034 (0.034) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:43
[2025-08-10 19:28:13 codetalker.py line 151]=>INFO: epoch [36/200] batch [100/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:40
[2025-08-10 19:28:13 codetalker.py line 151]=>INFO: epoch [36/200] batch [105/314] time 0.035 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:38
[2025-08-10 19:28:13 codetalker.py line 151]=>INFO: epoch [36/200] batch [110/314] time 0.033 (0.034) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:35
[2025-08-10 19:28:13 codetalker.py line 151]=>INFO: epoch [36/200] batch [115/314] time 0.041 (0.034) data 0.007 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:37
[2025-08-10 19:28:13 codetalker.py line 151]=>INFO: epoch [36/200] batch [120/314] time 0.034 (0.034) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:36
[2025-08-10 19:28:14 codetalker.py line 151]=>INFO: epoch [36/200] batch [125/314] time 0.033 (0.034) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:35
[2025-08-10 19:28:14 codetalker.py line 151]=>INFO: epoch [36/200] batch [130/314] time 0.033 (0.034) data 0.005 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:34
[2025-08-10 19:28:14 codetalker.py line 151]=>INFO: epoch [36/200] batch [135/314] time 0.036 (0.034) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:32
[2025-08-10 19:28:14 codetalker.py line 151]=>INFO: epoch [36/200] batch [140/314] time 0.035 (0.034) data 0.004 (0.003) loss 0.0028 lr 5.0000e-05 eta 0:29:32
[2025-08-10 19:28:14 codetalker.py line 151]=>INFO: epoch [36/200] batch [145/314] time 0.034 (0.034) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:28
[2025-08-10 19:28:15 codetalker.py line 151]=>INFO: epoch [36/200] batch [150/314] time 0.034 (0.034) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:26
[2025-08-10 19:28:15 codetalker.py line 151]=>INFO: epoch [36/200] batch [155/314] time 0.034 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:25
[2025-08-10 19:28:15 codetalker.py line 151]=>INFO: epoch [36/200] batch [160/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:23
[2025-08-10 19:28:15 codetalker.py line 151]=>INFO: epoch [36/200] batch [165/314] time 0.029 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:19
[2025-08-10 19:28:15 codetalker.py line 151]=>INFO: epoch [36/200] batch [170/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:17
[2025-08-10 19:28:15 codetalker.py line 151]=>INFO: epoch [36/200] batch [175/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:16 codetalker.py line 151]=>INFO: epoch [36/200] batch [180/314] time 0.043 (0.034) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:29
[2025-08-10 19:28:16 codetalker.py line 151]=>INFO: epoch [36/200] batch [185/314] time 0.035 (0.034) data 0.000 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:29:30
[2025-08-10 19:28:16 codetalker.py line 151]=>INFO: epoch [36/200] batch [190/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:30
[2025-08-10 19:28:16 codetalker.py line 151]=>INFO: epoch [36/200] batch [195/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:27
[2025-08-10 19:28:16 codetalker.py line 151]=>INFO: epoch [36/200] batch [200/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:25
[2025-08-10 19:28:16 codetalker.py line 151]=>INFO: epoch [36/200] batch [205/314] time 0.036 (0.034) data 0.003 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:29:25
[2025-08-10 19:28:17 codetalker.py line 151]=>INFO: epoch [36/200] batch [210/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:22
[2025-08-10 19:28:17 codetalker.py line 151]=>INFO: epoch [36/200] batch [215/314] time 0.030 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:23
[2025-08-10 19:28:17 codetalker.py line 151]=>INFO: epoch [36/200] batch [220/314] time 0.038 (0.034) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:22
[2025-08-10 19:28:17 codetalker.py line 151]=>INFO: epoch [36/200] batch [225/314] time 0.030 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:18
[2025-08-10 19:28:17 codetalker.py line 151]=>INFO: epoch [36/200] batch [230/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:18
[2025-08-10 19:28:18 codetalker.py line 151]=>INFO: epoch [36/200] batch [235/314] time 0.033 (0.034) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:17
[2025-08-10 19:28:18 codetalker.py line 151]=>INFO: epoch [36/200] batch [240/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:16
[2025-08-10 19:28:18 codetalker.py line 151]=>INFO: epoch [36/200] batch [245/314] time 0.033 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:18 codetalker.py line 151]=>INFO: epoch [36/200] batch [250/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:14
[2025-08-10 19:28:18 codetalker.py line 151]=>INFO: epoch [36/200] batch [255/314] time 0.033 (0.034) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:18 codetalker.py line 151]=>INFO: epoch [36/200] batch [260/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:19 codetalker.py line 151]=>INFO: epoch [36/200] batch [265/314] time 0.034 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:19 codetalker.py line 151]=>INFO: epoch [36/200] batch [270/314] time 0.034 (0.034) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:19 codetalker.py line 151]=>INFO: epoch [36/200] batch [275/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:14
[2025-08-10 19:28:19 codetalker.py line 151]=>INFO: epoch [36/200] batch [280/314] time 0.034 (0.034) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:13
[2025-08-10 19:28:19 codetalker.py line 151]=>INFO: epoch [36/200] batch [285/314] time 0.033 (0.034) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:13
[2025-08-10 19:28:19 codetalker.py line 151]=>INFO: epoch [36/200] batch [290/314] time 0.029 (0.034) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:13
[2025-08-10 19:28:20 codetalker.py line 151]=>INFO: epoch [36/200] batch [295/314] time 0.031 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:12
[2025-08-10 19:28:20 codetalker.py line 151]=>INFO: epoch [36/200] batch [300/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:11
[2025-08-10 19:28:20 codetalker.py line 151]=>INFO: epoch [36/200] batch [305/314] time 0.031 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:09
[2025-08-10 19:28:20 codetalker.py line 151]=>INFO: epoch [36/200] batch [310/314] time 0.035 (0.034) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:10
[2025-08-10 19:28:20 codetalker.py line 161]=>INFO: epoch: 36 loss_train: 0.0030437211704790403 pp_train: 11.68180907000402 
[2025-08-10 19:28:20 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:28:21 codetalker.py line 234]=>INFO: epoch: 36 loss_val: 0.003031574480701238 pp_val: 1.0 
[2025-08-10 19:28:22 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:28:24 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-36
[2025-08-10 19:28:24 codetalker.py line 151]=>INFO: epoch [37/200] batch [5/314] time 0.035 (0.049) data 0.005 (0.004) loss 0.0030 lr 5.0000e-05 eta 0:42:12
[2025-08-10 19:28:24 codetalker.py line 151]=>INFO: epoch [37/200] batch [10/314] time 0.032 (0.041) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:34:57
[2025-08-10 19:28:24 codetalker.py line 151]=>INFO: epoch [37/200] batch [15/314] time 0.034 (0.038) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:32:53
[2025-08-10 19:28:25 codetalker.py line 151]=>INFO: epoch [37/200] batch [20/314] time 0.031 (0.037) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:31:58
[2025-08-10 19:28:25 codetalker.py line 151]=>INFO: epoch [37/200] batch [25/314] time 0.033 (0.036) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:31:16
[2025-08-10 19:28:25 codetalker.py line 151]=>INFO: epoch [37/200] batch [30/314] time 0.032 (0.036) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:50
[2025-08-10 19:28:25 codetalker.py line 151]=>INFO: epoch [37/200] batch [35/314] time 0.032 (0.035) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:20
[2025-08-10 19:28:25 codetalker.py line 151]=>INFO: epoch [37/200] batch [40/314] time 0.033 (0.035) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:16
[2025-08-10 19:28:25 codetalker.py line 151]=>INFO: epoch [37/200] batch [45/314] time 0.033 (0.035) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:04
[2025-08-10 19:28:26 codetalker.py line 151]=>INFO: epoch [37/200] batch [50/314] time 0.033 (0.035) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:54
[2025-08-10 19:28:26 codetalker.py line 151]=>INFO: epoch [37/200] batch [55/314] time 0.033 (0.035) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:45
[2025-08-10 19:28:26 codetalker.py line 151]=>INFO: epoch [37/200] batch [60/314] time 0.035 (0.035) data 0.005 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:41
[2025-08-10 19:28:26 codetalker.py line 151]=>INFO: epoch [37/200] batch [65/314] time 0.033 (0.034) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:33
[2025-08-10 19:28:26 codetalker.py line 151]=>INFO: epoch [37/200] batch [70/314] time 0.033 (0.034) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:26
[2025-08-10 19:28:26 codetalker.py line 151]=>INFO: epoch [37/200] batch [75/314] time 0.037 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:39
[2025-08-10 19:28:27 codetalker.py line 151]=>INFO: epoch [37/200] batch [80/314] time 0.033 (0.035) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:34
[2025-08-10 19:28:27 codetalker.py line 151]=>INFO: epoch [37/200] batch [85/314] time 0.032 (0.034) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:32
[2025-08-10 19:28:27 codetalker.py line 151]=>INFO: epoch [37/200] batch [90/314] time 0.031 (0.034) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:30
[2025-08-10 19:28:27 codetalker.py line 151]=>INFO: epoch [37/200] batch [95/314] time 0.029 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:20
[2025-08-10 19:28:27 codetalker.py line 151]=>INFO: epoch [37/200] batch [100/314] time 0.030 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:13
[2025-08-10 19:28:27 codetalker.py line 151]=>INFO: epoch [37/200] batch [105/314] time 0.028 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:09
[2025-08-10 19:28:28 codetalker.py line 151]=>INFO: epoch [37/200] batch [110/314] time 0.034 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:09
[2025-08-10 19:28:28 codetalker.py line 151]=>INFO: epoch [37/200] batch [115/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:06
[2025-08-10 19:28:28 codetalker.py line 151]=>INFO: epoch [37/200] batch [120/314] time 0.034 (0.034) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:05
[2025-08-10 19:28:28 codetalker.py line 151]=>INFO: epoch [37/200] batch [125/314] time 0.029 (0.034) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:01
[2025-08-10 19:28:28 codetalker.py line 151]=>INFO: epoch [37/200] batch [130/314] time 0.034 (0.034) data 0.005 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:28:59
[2025-08-10 19:28:28 codetalker.py line 151]=>INFO: epoch [37/200] batch [135/314] time 0.033 (0.034) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:54
[2025-08-10 19:28:29 codetalker.py line 151]=>INFO: epoch [37/200] batch [140/314] time 0.033 (0.034) data 0.007 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:52
[2025-08-10 19:28:29 codetalker.py line 151]=>INFO: epoch [37/200] batch [145/314] time 0.030 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:50
[2025-08-10 19:28:29 codetalker.py line 151]=>INFO: epoch [37/200] batch [150/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:28:47
[2025-08-10 19:28:29 codetalker.py line 151]=>INFO: epoch [37/200] batch [155/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:28:47
[2025-08-10 19:28:29 codetalker.py line 151]=>INFO: epoch [37/200] batch [160/314] time 0.031 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:47
[2025-08-10 19:28:30 codetalker.py line 151]=>INFO: epoch [37/200] batch [165/314] time 0.032 (0.034) data 0.006 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:47
[2025-08-10 19:28:30 codetalker.py line 151]=>INFO: epoch [37/200] batch [170/314] time 0.032 (0.034) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:45
[2025-08-10 19:28:30 codetalker.py line 151]=>INFO: epoch [37/200] batch [175/314] time 0.029 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:42
[2025-08-10 19:28:30 codetalker.py line 151]=>INFO: epoch [37/200] batch [180/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:41
[2025-08-10 19:28:30 codetalker.py line 151]=>INFO: epoch [37/200] batch [185/314] time 0.035 (0.034) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:40
[2025-08-10 19:28:30 codetalker.py line 151]=>INFO: epoch [37/200] batch [190/314] time 0.031 (0.033) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:37
[2025-08-10 19:28:31 codetalker.py line 151]=>INFO: epoch [37/200] batch [195/314] time 0.034 (0.033) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:38
[2025-08-10 19:28:31 codetalker.py line 151]=>INFO: epoch [37/200] batch [200/314] time 0.030 (0.033) data 0.001 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:35
[2025-08-10 19:28:31 codetalker.py line 151]=>INFO: epoch [37/200] batch [205/314] time 0.034 (0.033) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:36
[2025-08-10 19:28:31 codetalker.py line 151]=>INFO: epoch [37/200] batch [210/314] time 0.032 (0.033) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:34
[2025-08-10 19:28:31 codetalker.py line 151]=>INFO: epoch [37/200] batch [215/314] time 0.036 (0.033) data 0.004 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:35
[2025-08-10 19:28:31 codetalker.py line 151]=>INFO: epoch [37/200] batch [220/314] time 0.035 (0.033) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:34
[2025-08-10 19:28:32 codetalker.py line 151]=>INFO: epoch [37/200] batch [225/314] time 0.034 (0.033) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:34
[2025-08-10 19:28:32 codetalker.py line 151]=>INFO: epoch [37/200] batch [230/314] time 0.032 (0.033) data 0.003 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:28:32
[2025-08-10 19:28:32 codetalker.py line 151]=>INFO: epoch [37/200] batch [235/314] time 0.032 (0.033) data 0.001 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:32
[2025-08-10 19:28:32 codetalker.py line 151]=>INFO: epoch [37/200] batch [240/314] time 0.036 (0.033) data 0.006 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:32
[2025-08-10 19:28:32 codetalker.py line 151]=>INFO: epoch [37/200] batch [245/314] time 0.034 (0.033) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:28:32
[2025-08-10 19:28:32 codetalker.py line 151]=>INFO: epoch [37/200] batch [250/314] time 0.034 (0.033) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:30
[2025-08-10 19:28:33 codetalker.py line 151]=>INFO: epoch [37/200] batch [255/314] time 0.032 (0.033) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:29
[2025-08-10 19:28:33 codetalker.py line 151]=>INFO: epoch [37/200] batch [260/314] time 0.031 (0.033) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:27
[2025-08-10 19:28:33 codetalker.py line 151]=>INFO: epoch [37/200] batch [265/314] time 0.032 (0.033) data 0.006 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:25
[2025-08-10 19:28:33 codetalker.py line 151]=>INFO: epoch [37/200] batch [270/314] time 0.033 (0.033) data 0.003 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:28:25
[2025-08-10 19:28:33 codetalker.py line 151]=>INFO: epoch [37/200] batch [275/314] time 0.033 (0.033) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:24
[2025-08-10 19:28:33 codetalker.py line 151]=>INFO: epoch [37/200] batch [280/314] time 0.038 (0.033) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:26
[2025-08-10 19:28:34 codetalker.py line 151]=>INFO: epoch [37/200] batch [285/314] time 0.031 (0.033) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:28:24
[2025-08-10 19:28:34 codetalker.py line 151]=>INFO: epoch [37/200] batch [290/314] time 0.032 (0.033) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:24
[2025-08-10 19:28:34 codetalker.py line 151]=>INFO: epoch [37/200] batch [295/314] time 0.033 (0.033) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:28:25
[2025-08-10 19:28:34 codetalker.py line 151]=>INFO: epoch [37/200] batch [300/314] time 0.041 (0.033) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:26
[2025-08-10 19:28:34 codetalker.py line 151]=>INFO: epoch [37/200] batch [305/314] time 0.030 (0.033) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:25
[2025-08-10 19:28:34 codetalker.py line 151]=>INFO: epoch [37/200] batch [310/314] time 0.034 (0.033) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:28:25
[2025-08-10 19:28:35 codetalker.py line 161]=>INFO: epoch: 37 loss_train: 0.0030448805032131875 pp_train: 11.683466224913385 
[2025-08-10 19:28:35 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:28:35 codetalker.py line 234]=>INFO: epoch: 37 loss_val: 0.003019274480175227 pp_val: 1.0 
[2025-08-10 19:28:37 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model-best.pth.tar
[2025-08-10 19:28:38 base_trainer.py line 498]=>INFO: Checkpoint saved to ./output\model\model.pth.tar-37
[2025-08-10 19:28:38 codetalker.py line 151]=>INFO: epoch [38/200] batch [5/314] time 0.037 (0.051) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:43:50
[2025-08-10 19:28:38 codetalker.py line 151]=>INFO: epoch [38/200] batch [10/314] time 0.031 (0.043) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:36:34
[2025-08-10 19:28:39 codetalker.py line 151]=>INFO: epoch [38/200] batch [15/314] time 0.031 (0.040) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:34:10
[2025-08-10 19:28:39 codetalker.py line 151]=>INFO: epoch [38/200] batch [20/314] time 0.032 (0.038) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:32:44
[2025-08-10 19:28:39 codetalker.py line 151]=>INFO: epoch [38/200] batch [25/314] time 0.032 (0.038) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:32:08
[2025-08-10 19:28:39 codetalker.py line 151]=>INFO: epoch [38/200] batch [30/314] time 0.034 (0.037) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:31:52
[2025-08-10 19:28:39 codetalker.py line 151]=>INFO: epoch [38/200] batch [35/314] time 0.033 (0.037) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:31:20
[2025-08-10 19:28:39 codetalker.py line 151]=>INFO: epoch [38/200] batch [40/314] time 0.033 (0.036) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:57
[2025-08-10 19:28:40 codetalker.py line 151]=>INFO: epoch [38/200] batch [45/314] time 0.034 (0.036) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:51
[2025-08-10 19:28:40 codetalker.py line 151]=>INFO: epoch [38/200] batch [50/314] time 0.033 (0.036) data 0.003 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:37
[2025-08-10 19:28:40 codetalker.py line 151]=>INFO: epoch [38/200] batch [55/314] time 0.033 (0.036) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:29
[2025-08-10 19:28:40 codetalker.py line 151]=>INFO: epoch [38/200] batch [60/314] time 0.030 (0.036) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:16
[2025-08-10 19:28:40 codetalker.py line 151]=>INFO: epoch [38/200] batch [65/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:30:07
[2025-08-10 19:28:41 codetalker.py line 151]=>INFO: epoch [38/200] batch [70/314] time 0.033 (0.035) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:30:02
[2025-08-10 19:28:41 codetalker.py line 151]=>INFO: epoch [38/200] batch [75/314] time 0.032 (0.035) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:30:02
[2025-08-10 19:28:41 codetalker.py line 151]=>INFO: epoch [38/200] batch [80/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:57
[2025-08-10 19:28:41 codetalker.py line 151]=>INFO: epoch [38/200] batch [85/314] time 0.034 (0.035) data 0.005 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:52
[2025-08-10 19:28:41 codetalker.py line 151]=>INFO: epoch [38/200] batch [90/314] time 0.033 (0.035) data 0.007 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:49
[2025-08-10 19:28:41 codetalker.py line 151]=>INFO: epoch [38/200] batch [95/314] time 0.037 (0.035) data 0.001 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:49
[2025-08-10 19:28:42 codetalker.py line 151]=>INFO: epoch [38/200] batch [100/314] time 0.037 (0.035) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:47
[2025-08-10 19:28:42 codetalker.py line 151]=>INFO: epoch [38/200] batch [105/314] time 0.033 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:39
[2025-08-10 19:28:42 codetalker.py line 151]=>INFO: epoch [38/200] batch [110/314] time 0.034 (0.035) data 0.004 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:32
[2025-08-10 19:28:42 codetalker.py line 151]=>INFO: epoch [38/200] batch [115/314] time 0.034 (0.035) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:30
[2025-08-10 19:28:42 codetalker.py line 151]=>INFO: epoch [38/200] batch [120/314] time 0.032 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:29
[2025-08-10 19:28:42 codetalker.py line 151]=>INFO: epoch [38/200] batch [125/314] time 0.034 (0.035) data 0.009 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:25
[2025-08-10 19:28:43 codetalker.py line 151]=>INFO: epoch [38/200] batch [130/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0033 lr 5.0000e-05 eta 0:29:23
[2025-08-10 19:28:43 codetalker.py line 151]=>INFO: epoch [38/200] batch [135/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:21
[2025-08-10 19:28:43 codetalker.py line 151]=>INFO: epoch [38/200] batch [140/314] time 0.032 (0.034) data 0.000 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:19
[2025-08-10 19:28:43 codetalker.py line 151]=>INFO: epoch [38/200] batch [145/314] time 0.027 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:21
[2025-08-10 19:28:43 codetalker.py line 151]=>INFO: epoch [38/200] batch [150/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:20
[2025-08-10 19:28:44 codetalker.py line 151]=>INFO: epoch [38/200] batch [155/314] time 0.034 (0.034) data 0.001 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:17
[2025-08-10 19:28:44 codetalker.py line 151]=>INFO: epoch [38/200] batch [160/314] time 0.032 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:19
[2025-08-10 19:28:44 codetalker.py line 151]=>INFO: epoch [38/200] batch [165/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:17
[2025-08-10 19:28:44 codetalker.py line 151]=>INFO: epoch [38/200] batch [170/314] time 0.032 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:44 codetalker.py line 151]=>INFO: epoch [38/200] batch [175/314] time 0.034 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:44 codetalker.py line 151]=>INFO: epoch [38/200] batch [180/314] time 0.038 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:16
[2025-08-10 19:28:45 codetalker.py line 151]=>INFO: epoch [38/200] batch [185/314] time 0.039 (0.034) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:17
[2025-08-10 19:28:45 codetalker.py line 151]=>INFO: epoch [38/200] batch [190/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:18
[2025-08-10 19:28:45 codetalker.py line 151]=>INFO: epoch [38/200] batch [195/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:16
[2025-08-10 19:28:45 codetalker.py line 151]=>INFO: epoch [38/200] batch [200/314] time 0.033 (0.034) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:18
[2025-08-10 19:28:45 codetalker.py line 151]=>INFO: epoch [38/200] batch [205/314] time 0.035 (0.034) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:17
[2025-08-10 19:28:45 codetalker.py line 151]=>INFO: epoch [38/200] batch [210/314] time 0.037 (0.034) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:17
[2025-08-10 19:28:46 codetalker.py line 151]=>INFO: epoch [38/200] batch [215/314] time 0.034 (0.034) data 0.000 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:16
[2025-08-10 19:28:46 codetalker.py line 151]=>INFO: epoch [38/200] batch [220/314] time 0.040 (0.034) data 0.010 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:13
[2025-08-10 19:28:46 codetalker.py line 151]=>INFO: epoch [38/200] batch [225/314] time 0.030 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:11
[2025-08-10 19:28:46 codetalker.py line 151]=>INFO: epoch [38/200] batch [230/314] time 0.038 (0.034) data 0.008 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:11
[2025-08-10 19:28:46 codetalker.py line 151]=>INFO: epoch [38/200] batch [235/314] time 0.040 (0.034) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:14
[2025-08-10 19:28:47 codetalker.py line 151]=>INFO: epoch [38/200] batch [240/314] time 0.036 (0.035) data 0.004 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:29:17
[2025-08-10 19:28:47 codetalker.py line 151]=>INFO: epoch [38/200] batch [245/314] time 0.028 (0.034) data 0.002 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:16
[2025-08-10 19:28:47 codetalker.py line 151]=>INFO: epoch [38/200] batch [250/314] time 0.035 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:16
[2025-08-10 19:28:47 codetalker.py line 151]=>INFO: epoch [38/200] batch [255/314] time 0.034 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:14
[2025-08-10 19:28:47 codetalker.py line 151]=>INFO: epoch [38/200] batch [260/314] time 0.036 (0.034) data 0.005 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:16
[2025-08-10 19:28:47 codetalker.py line 151]=>INFO: epoch [38/200] batch [265/314] time 0.034 (0.034) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:48 codetalker.py line 151]=>INFO: epoch [38/200] batch [270/314] time 0.035 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:48 codetalker.py line 151]=>INFO: epoch [38/200] batch [275/314] time 0.034 (0.035) data 0.003 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:16
[2025-08-10 19:28:48 codetalker.py line 151]=>INFO: epoch [38/200] batch [280/314] time 0.037 (0.035) data 0.000 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:16
[2025-08-10 19:28:48 codetalker.py line 151]=>INFO: epoch [38/200] batch [285/314] time 0.037 (0.035) data 0.003 (0.003) loss 0.0031 lr 5.0000e-05 eta 0:29:16
[2025-08-10 19:28:48 codetalker.py line 151]=>INFO: epoch [38/200] batch [290/314] time 0.033 (0.034) data 0.002 (0.003) loss 0.0032 lr 5.0000e-05 eta 0:29:15
[2025-08-10 19:28:49 codetalker.py line 151]=>INFO: epoch [38/200] batch [295/314] time 0.054 (0.035) data 0.009 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:17
[2025-08-10 19:28:49 codetalker.py line 151]=>INFO: epoch [38/200] batch [300/314] time 0.026 (0.034) data 0.002 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:14
[2025-08-10 19:28:49 codetalker.py line 151]=>INFO: epoch [38/200] batch [305/314] time 0.031 (0.034) data 0.010 (0.003) loss 0.0030 lr 5.0000e-05 eta 0:29:12
[2025-08-10 19:28:49 codetalker.py line 151]=>INFO: epoch [38/200] batch [310/314] time 0.035 (0.034) data 0.000 (0.003) loss 0.0029 lr 5.0000e-05 eta 0:29:11
[2025-08-10 19:28:49 codetalker.py line 161]=>INFO: epoch: 38 loss_train: 0.003049170594680224 pp_train: 11.680387715625155 
[2025-08-10 19:28:49 codetalker.py line 216]=>INFO: Evaluate on the *val* set
[2025-08-10 19:28:50 codetalker.py line 234]=>INFO: epoch: 38 loss_val: 0.0030402673583012074 pp_val: 1.0 
Traceback (most recent call last):
  File "D:\00MyWorkplace\01anaconda\envs\pytorch3d\lib\runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "D:\00MyWorkplace\01anaconda\envs\pytorch3d\lib\runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "D:\Projects\Explore\TalkingHeadCodebase\main\train.py", line 41, in <module>
    main(args)
  File "D:\Projects\Explore\TalkingHeadCodebase\main\train.py", line 27, in main
    trainer.train()
  File "D:\Projects\Explore\TalkingHeadCodebase\trainers\codetalker.py", line 72, in train
    super().train(self.start_epoch, self.max_epoch)
  File "D:\Projects\Explore\TalkingHeadCodebase\base\base_trainer.py", line 134, in train
    self.after_epoch()
  File "D:\Projects\Explore\TalkingHeadCodebase\trainers\codetalker.py", line 192, in after_epoch
    self.save_model(
  File "D:\Projects\Explore\TalkingHeadCodebase\base\base_trainer.py", line 448, in save_model
    self.save_checkpoint(
  File "D:\Projects\Explore\TalkingHeadCodebase\base\base_trainer.py", line 497, in save_checkpoint
    torch.save(state, fpath)
  File "D:\00MyWorkplace\01anaconda\envs\pytorch3d\lib\site-packages\torch\serialization.py", line 376, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "D:\00MyWorkplace\01anaconda\envs\pytorch3d\lib\site-packages\torch\serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "D:\00MyWorkplace\01anaconda\envs\pytorch3d\lib\site-packages\torch\serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
OSError: [Errno 22] Invalid argument: './output\\model\\model-best.pth.tar'
